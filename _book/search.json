[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "",
    "text": "Preface\nThis Quarto book collects my personal notes, trials and exercises of the Bayesian Statistics the Fun Way: Understanding Statistics and Probability With Star Wars, LEGO, and Rubber Ducks by Will Kurt (kurt2019?).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "00-intro.html",
    "href": "00-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Frequentist statistics is founded on the idea that probability represents the frequency with which something happens.\n\n\nFrequentist statistics also known as frequentist interference, is a type of statistical approach where conclusions are made based on the frequency of an event. This statistical approach determines the probability of a long-term experiment, meaning the experiment is repeated under the same set of conditions to obtain an outcome. In frequentist statistics the population parameters are fixed, but unknown, and the data observed in experiments are random. (deepai.org)\nBayesian statistics on the other hand, is concerned with how probabilities represent how uncertain we are about a piece of information.\n\n\n\n\n\n\n\nBayesian statistics uses Bayesian reasoning is the formal process that we use to update our beliefs about the world once we’ve observed some data. Ba",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html",
    "href": "01-everyday-reasoning.html",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "",
    "text": "1.1 Reasoning About Strange Experiences\nBayesian reasoning procedure:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "02-measuring-uncertainty.html",
    "href": "02-measuring-uncertainty.html",
    "title": "\n2  Measuring Uncertainty\n",
    "section": "",
    "text": "2.1 What is Probability?\nProbability is a measurement of how strongly we believe things about the world. We can consider probability an extension of logic. Probability allows us to extend logic not only to work with absolute beliefs (true and false) but also to work with uncertain values (values between true and false).\nAn important part of logic is negation. When we say “not true” we mean false. Likewise, saying “not false” means true. We want probability to work the same way, so we make sure that the probability of X and the negation of the probability of X sum to 1 (in other words, values are either X, or not X).\n\\[P(X) + \\neg{P(X)} = 1 \\tag{2.1}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measuring Uncertainty</span>"
    ]
  },
  {
    "objectID": "03-logic-uncertainty.html",
    "href": "03-logic-uncertainty.html",
    "title": "3  Logic of Uncertainty",
    "section": "",
    "text": "3.1 Combining Probabilities with AND",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Logic of Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html",
    "href": "04-binomial-distribution.html",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "",
    "text": "4.1 Structure of a Binomial Distribution\nA binomial distribution is used to calculate the probability of a certain number of successful outcomes, given a number of trials and the probability of the successful outcome. The “bi” in the term binomial refers to the two possible outcomes that we’re concerned with: an event happening and an event not happening. (If there are more than two outcomes, the distribution is called multinomial.)\nExamples for a binomial distribution are:\nCalculating the probability of flipping two heads in three coin tosses:\nFor the example of two heads in three coin tosses, we would write \\(B(2; 3, 1/2)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html",
    "href": "05-beta-distribution.html",
    "title": "5  The Beta Distribution",
    "section": "",
    "text": "5.1 A Strange Scenario: Getting the Data\nIf you drop a quarter into a black box, it eject sometimes two quarter but sometimes it “eats” your quarter. So the question is: “What’s the probability of getting two quarters?”",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html#reasoning-about-strange-experiences",
    "href": "01-everyday-reasoning.html#reasoning-about-strange-experiences",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "",
    "text": "Note\n\n\n\nWill Kurt show with an UFO example how Bayesian thinking about beliefs and their updates when new data come is very natural and a common sense procedure. This is an interesting approach I haven’t thought before, because many Bayesian introductions are not only very complex but develops formulae that we are not using in the everyday world.\n\n\n\n\nObserve data\nBuild a hypothesis\nUpdate your beliefs based on new data\n\n\n1.1.1 Observing Data\n\\[P(\\text{bright light outside window}, \\text{saucer-shaped object in sky}) = \\text{very low}\\] You would read this equation as: “The probability of observing bright lights outside the window and a saucer-shaped object in the sky is very low.” In probability theory, we use a comma to separate events when we’re looking at the combined probability of multiple events.\n\n1.1.2 Holding Prior Beliefs and Conditioning Probabilities\n\\[\n\\begin{align*}\nP(\\text{bright light outside window},\\\\\n\\text{saucer-shaped object in sky} \\mid \\text{eperience on Earth}) = \\text{very low}\n\\end{align*}\n\\tag{1.1}\\] We would read this equation as: “The probability of observing bright lights and a saucer-shaped object in the sky, given our experience on Earth, is very low.”\nThe probability outcome is called a conditional probability (GLOSSARY) because we are conditioning the probability of one event occurring on the existence of something else.\nShorter variable names for events and conditions:\n\nD: all of our data\nX: prior belief\n\nLet \\(D = \\text{bright light outside window}, \\text{saucer-shaped object in sky}\\) and \\(X = \\text{experience on Earth}\\) then we can wrote Equation 1.1 as \\(P(D \\mid X) = \\text{very low})\\).\n\n1.1.3 Conditioning on Multiple Beliefs\n\\[\n\\begin{align*}\nP(\\text{bright light outside window},\\\\\n\\text{saucer-shaped object in sky} \\mid \\\\\n\\text{July 4th, eperience on Earth}) = \\text{low}\n\\end{align*}\n\\tag{1.2}\\] Taking both these experiences into account, our conditional probability changed from “very low” to “low.”\n\n1.1.4 Assuming Prior Beliefs in Practice\nIn order to explain what you saw, you need to form some kind of hypothesis—a model about how the world works that makes a prediction. All of our basic beliefs about the world are hypotheses.\n\nIf you believe the Earth rotates, you predict the sun will rise and set at certain times.\nIf you believe that your favorite baseball team is the best, you predict they will win more than the other teams.\nA scientist may hypothesize that a certain treatment will slow the growth of cancer.\nA quantitative analyst in finance may have a model of how the market will behave.\n\n\\[H_{1} = \\text{A UFO is in my backyard!}\\]\nBut what is this hypothesis predicting? We might ask, “If there was a UFO in your back yard, what would you expect to see?” And you might answer, “Bright lights and a saucer-shaped object.” Formally we write this as:\n\\[\nP(D \\mid H_{1}, X) &gt;&gt; P(D \\mid X)\n\\]\nThis equation says: “The probability of seeing bright lights and a saucer-shaped object in the sky, given my belief that this is a UFO and my prior experience, is much higher [indicated by the double greater-than sign &gt;&gt;] than just seeing bright lights and a saucer-shaped object in the sky without explanation.”\n\n1.1.5 Spotting Hypotheses in Everyday Speech\n\nSaying something is “surprising,” for example, might be the same as saying it has low-probability data based on our prior experiences.\nSaying something “makes sense” might indicate we have high-probability data based on our prior experiences.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html#gathering-more-evidence-and-updating-your-beliefs",
    "href": "01-everyday-reasoning.html#gathering-more-evidence-and-updating-your-beliefs",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "\n1.2 Gathering More Evidence and Updating Your Beliefs",
    "text": "1.2 Gathering More Evidence and Updating Your Beliefs\nTo collect more data, we need to make more observations. In our scenario, you look out your window: With new evidence, you realize it looks more like someone is shooting a movie nearby.\nBayesian analysis process\n\nYou started with your initial hypothesis: \\(H_{1} = \\text{A UFO is in my backyard!}\\).\nIn isolation, this hypothesis, given your experience, is extremely unlikely: \\(P(H_{1} \\mid X) = \\text{very, very low}\\)\n\nWith new data you are going to update your belief: \\(H_{2} = \\text{A film is being made}\\).\nIn isolation, the probability of this hypothesis is also intuitively very low: \\(P(H_{1} \\mid X) = \\text{very low}\\)\n\nYou updated your prior belief from “very, very low” to “very low”.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html#comparing-hypotheses",
    "href": "01-everyday-reasoning.html#comparing-hypotheses",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "\n1.3 Comparing Hypotheses",
    "text": "1.3 Comparing Hypotheses\nWith new data you have formed an alternate hypothesis. Let’s break this process down into Bayesian reasoning. Your first hypothesis, \\(H_{1}\\), gave you a way to explain your data and end your confusion, but with your additional observations \\(H_{1}\\) no longer explains the data well:\nYou started with\n\\[P(D \\mid H_{1}, X) = \\text{very, very low}\\] and updated our belief with\n\\[P(D_{updated} \\mid H_{2}, X) &gt;&gt; P(D \\mid H_{1}, X)\\] We say that one belief is more accurate than another because it provides a better explanation of the world we observe. Mathematically, we express this idea as the ratio of the two probabilities:\n\\[\\frac{P(D_{updated} \\mid H_{2}, X)}{P(D \\mid H_{1}, X)}\\]\nWhen this ratio is a large number, say 1,000, it means “\\(H_{2}\\) explains the data 1,000 times better than \\(H_{1}\\).”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html#data-informs-belief-belief-should-not-inform-data",
    "href": "01-everyday-reasoning.html#data-informs-belief-belief-should-not-inform-data",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "\n1.4 Data Informs Belief; Belief Should Not Inform Data",
    "text": "1.4 Data Informs Belief; Belief Should Not Inform Data\nOne final point worth stressing is that the only absolute in all these examples is your data. Your hypotheses change, and your experience in the world, \\(X\\), may be different from someone else’s, but the data, \\(D\\), is shared by all.\nCase 1 (used throughout this chapter):\n\\[P(D \\mid H, X) \\tag{1.3}\\] “How well do my beliefs explain what I observe?”\nCase 2 (used often in everyday thinking)\n\\[P(H \\mid D, X) \\tag{1.4}\\]\nIn the first case, we change our beliefs according to data we gather and observations we make about the world that describe it better. In the second case, we gather data to support our existing beliefs. Bayesian thinking is about changing your mind and updating how you understand the world. The data we observe is all that is real, so our beliefs ultimately need to shift until they align with the data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html#wrapping-up",
    "href": "01-everyday-reasoning.html#wrapping-up",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "\n1.5 Wrapping Up",
    "text": "1.5 Wrapping Up\n\n\n\n\n\n\nImportant\n\n\n\nYou should be far more concerned with data changing your beliefs \\(P(D \\mid H)\\) (Equation 1.3) than with ensuring data supports your beliefs, \\(P(H \\mid D)\\) (Equation 1.4).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "01-everyday-reasoning.html#exercises",
    "href": "01-everyday-reasoning.html#exercises",
    "title": "\n1  Bayesian Thinking and Everyday Reasoning\n",
    "section": "\n1.6 Exercises",
    "text": "1.6 Exercises\nTry answering the following questions to see how well you understand Bayesian reasoning. The solutions can be found at No Starch Press (PDF).\n\nExercise 1.1 Rewrite the following statements as equations using the mathematical notation you learned in this chapter:\n\nThe probability of rain is low: \\(P(rain) = low\\)\n\nThe probability of rain given that it is cloudy is high: \\(P(rain \\mid cloudy) = high\\)\n\nThe probability of you having an umbrella given it is raining is much greater than the probability of you having an umbrella in general: \\(P(\\text{I have umbrella} \\mid \\text{raining}) &gt;&gt; P(\\text{I have umbrella})\\)\n\n\n\n\n\nExercise 1.2 Organize the data you observe in the following scenario into a mathematical notation, using the techniques we’ve covered in this chapter. Then come up with a hypothesis to explain this data:\n\nYou come home from work and notice that your front door is open and the side window is broken. As you walk inside, you immediately notice that your laptop is missing.\n\n\\[\nP(\\text{door open, window broken, laptop missing} \\mid H_{hausbreaking})\n\\]\n\n\n\nExercise 1.3 The following scenario adds data to the previous one. Demonstrate how this new information changes your beliefs and come up with a second hypothesis to explain the data, using the notation you’ve learned in this chapter.\n\nA neighborhood child runs up to you and apologizes profusely for accidentally throwing a rock through your window. They claim that they saw the laptop and didn’t want it stolen so they opened the front door to grab it, and your laptop is safe at their house.\n\n\\[\nP(\\text{door open, window broken, laptop missing, child explains} \\mid H_{accident})\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Bayesian Thinking and Everyday Reasoning</span>"
    ]
  },
  {
    "objectID": "03-logic-uncertainty.html#combining-probabilities-with-and",
    "href": "03-logic-uncertainty.html#combining-probabilities-with-and",
    "title": "3  Logic of Uncertainty",
    "section": "",
    "text": "3.1.1 Solving a Combination of Two Probabilities\nSuppose we want to know the probability of getting a heads in a coin flip AND rolling a 6 on a die. We know that the probability of each of these events individually is:\n\\[P(heads) = \\frac{1}{2}, P(six) = \\frac{1}{6}\\]\nNow we want to know the probability of both of these things occurring, written as:\n\\[P(heads, six) = ?\\]\n\n3.1.2 Applying the Product Rule of Probability\n\n\nTheorem 3.1 (Product rule for combining probabilities) \\[P(A,B) = P(A) \\times P(B) \\tag{3.1}\\]\n\n\nIn our example:\n\\[P(heads,six) = \\frac{1}{2} \\times \\frac{1}{6} = \\frac{1}{12}\\]\n\n3.1.3 Example: Calculating the Probability of Being Late\nLet’s assume the local transit authority publishes data that tells us that 15 percent of the time the train is late, and 20 percent of the time the bus is late. Since you’ll be late only if both the bus and the train are late, we can use the product rule to solve this problem:\n\\[P(Late) = P(Late_{train}) \\times P(Late_{bus}) = 0.15 \\times 0.20 = 0.03\\] Even though there’s a pretty reasonable chance that either the bus or the train will be late, the probability that they will both be late is significantly less, at only 0.03. We can also say there is a 3 percent chance that both will be late. With this calculation done, you can be a little less stressed about being late.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Logic of Uncertainty</span>"
    ]
  },
  {
    "objectID": "03-logic-uncertainty.html#combining-probabilities-with-or",
    "href": "03-logic-uncertainty.html#combining-probabilities-with-or",
    "title": "3  Logic of Uncertainty",
    "section": "\n3.2 Combining Probabilities with OR",
    "text": "3.2 Combining Probabilities with OR\nThe probability of one event OR another event occurring is slightly more complicated because the events can either be mutually exclusive or not mutually exclusive. Events are mutually exclusive if one event happening implies the other possible events cannot happen.\n\n3.2.1 Calculating OR for Mutually Exclusive Events\nThe process of combining two events with OR feels logically intuitive. If you’re asked, “What is the probability of getting heads or tails on a coin toss?” you would say, “1.”, because we know that:\n\\[P(heads) = \\frac{1}{2}, P(tails) = \\frac{1}{2}\\]\nIntuitively, we might just add the probability of these events together. We know this works because heads and tails are the only possible outcomes, and the probability of all possible outcomes must equal 1.\nFrom this we can see that, as long as events are mutually exclusive, we can simply add up all of the probabilities of each possible event to get the probability of either event happening to calculate the probability of one event OR the other.\nThis addition rule applies only to combinations of mutually exclusive outcomes. In probabilistic terms, mutually exclusive means that:\n\\[P(A) \\operatorname{AND} P(B) = 0\\] To really understand combining probabilities with OR, we need to look at the case where events are not mutually exclusive.\n\n3.2.2 Using the Sum Rule for Non–Mutually Exclusive Events\nGiven that we know that \\(P(heads) = 1/2\\) and \\(P(six) = 1/6\\), it might initially seem plausible that the probability of either of these events is simply \\(4/6\\). It becomes obvious that this doesn’t work, however, when we consider the possibility of either flipping a heads (=1/2) or rolling a number less than \\(6\\). Because \\(P(\\text{less than six}) = 5/6\\), adding these probabilities together wit \\(1/2\\) gives us \\(8/6\\), which is greater than \\(1\\)! Since this violates the rule that probabilities must be between \\(0\\) and \\(1\\), we must have made a mistake.\nThe trouble is that flipping a heads and rolling a 6 are not mutually exclusive. As we know from earlier in the chapter, \\(P(heads, six) = 1/12\\). Because the probability of both events happening at the same time is not \\(0\\), we know they are, by definition, not mutually exclusive.\nThe reason that adding our probabilities doesn’t work for non–mutually exclusive events is that doing so doubles the counting of events where both things happen. To correct our probabilities, we must add up all of our probabilities and then subtract the probability of both events occurring.\n\n\nTheorem 3.2 (Sum Rule for Non–Mutually Exclusive Events) \\[P(A) \\operatorname{OR} P(B) = P(A) + P(B) – P(A,B) \\tag{3.2}\\]\n\n\nUsing our die roll and coin toss example, the probability of rolling a number less than 6 or flipping a heads is:\n\\[P(heads) \\operatorname{OR} P(six) = P(heads) + P(six) - P(heads, six) = \\frac{1}{2} + \\frac{1}{6} - \\frac{1}{12} = \\frac{7}{12}\\]\n\n3.2.3 Example: Calculating the Probability of Getting a Hefty Fine\nRemains empty: Doesn’t bring new knowledge.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Logic of Uncertainty</span>"
    ]
  },
  {
    "objectID": "03-logic-uncertainty.html#wrapping-up",
    "href": "03-logic-uncertainty.html#wrapping-up",
    "title": "3  Logic of Uncertainty",
    "section": "\n3.3 Wrapping Up",
    "text": "3.3 Wrapping Up\nWe’ve learned the logic of uncertainty by adding rules for combining probabilities with AND and OR.\n\n\nAND operator: Use the product rule as in Equation 3.1.\n\nOR mutually exclusive events: Add all probabilities together.\n\nOR not mutually exclusive events: Use the sum rule as in Equation 3.2.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Logic of Uncertainty</span>"
    ]
  },
  {
    "objectID": "03-logic-uncertainty.html#exercises",
    "href": "03-logic-uncertainty.html#exercises",
    "title": "3  Logic of Uncertainty",
    "section": "\n3.4 Exercises",
    "text": "3.4 Exercises\nTry answering the following questions to make sure you understand the rules of logic as they apply to probability. The solutions can be found at https://nostarch.com/learnbayes/.\n\nExercise 3.1 What is the probability of rolling a 20 three times in a row on a 20-sided die?\nSolution:\n\\[\n\\frac{1}{20} \\times \\frac{1}{20} \\times \\frac{1}{20} = \\frac{1}{8,000}\n\\]\n\n\nExercise 3.2 The weather report says there’s a 10 percent chance of rain tomorrow, and you forget your umbrella half the time you go out. What is the probability that you’ll be caught in the rain without an umbrella tomorrow?\nSolution: \\[\nP(rain) = 0.1 \\times P(\\text{no umbrella}) = 0.5 = 0.05\n\\]\n\n\nExercise 3.3 Raw eggs have a 1/20,000 probability of having salmonella. If you eat two raw eggs, what is the probability you ate a raw egg with salmonella?\nSolution: This are not mutually exclusive events as both raw eggs could have salmonella. So Equation 3.2 applies:\n\\[\n\\begin{align*}\n(\\frac{1}{20,000} + \\frac{1}{20,000}) - (\\frac{1}{20,000} \\times \\frac{1}{20,000}) = \\\\\n\\frac{2}{20,000} - \\frac{1}{400,000,000} = \\\\\n\\frac{40000}{400,000,000} - \\frac{1}{400,000,000} = \\\\\n\\frac{39,999}{400,000,000}\n\\end{align*}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nI had problems with the many zeros. My result was 39/400,000. I tried the calculation again with the help of R.\n\n\n\nListing 3.1: Exercise 3 of “Logic of Uncertainty” (Chapter 3)\n\n# disabling scientific notation\n# https://stackoverflow.com/a/27318351/7322615\noptions(scipen = 999) \n\n(1 / 2e4 + 1 / 2e4) - (1 / 2e4 * 1 / 2e4)\n\n\n\n\n[1] 0.0000999975\n\n\n\nListing 3.2: Exercise 3 of “Logic of Uncertainty” (Chapter 3)\n\n# to compare with:\n39999 / 4e8\n\n\n\n\n[1] 0.0000999975\n\n\n\nListing 3.3: Exercise 3 of “Logic of Uncertainty” (Chapter 3)\n\n# or witouth scientific notation\noptions(scipen = -999) \n39999 / 4e8\n\n\n\n\n[1] 9.99975e-05\n\n\n\n\n\n\nExercise 3.4 What is the probability of either flipping two heads in two coin tosses or rolling three 6s in three six-sided dice rolls?\nSolution:\n\\[\n\\begin{align*}\nP(heads) \\operatorname{AND} P(heads) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4} = P(h)\\\\\nP(six) \\operatorname{AND} P(six) \\operatorname{AND} P(six) = \\frac{1}{6} \\times \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{216} = P(s)\\\\\nP(h) \\operatorname{OR} P(s) = (\\frac{1}{4} + \\frac{1}{216}) - (\\frac{1}{4} \\times \\frac{1}{216}) = \\\\\n\\frac{55}{216} - \\frac{1}{864} = \\frac{219}{864} = \\frac{73}{288}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\nNote\n\n\n\nI did not calculate percent values. But this would be sensible to get the result into the probability scale from 0 to 100%. Then it would be more surprising to see that the probability of Exercise 3.4 was pretty high: a little more than 25%.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Logic of Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#structure-of-a-binomial-distribution",
    "href": "04-binomial-distribution.html#structure-of-a-binomial-distribution",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "",
    "text": "Flipping two heads in three coin tosses\nBuying 1 million lottery tickets and winning at least once\nRolling fewer than three 20s in 10 rolls of a 20-sided die\n\n\n\nDefinition 4.1 (Parameter for the binomial distribution) All binomial distributions involve three parameters:\n\n\nk The number of outcomes we care about\n\nn The total number of trials\n\np The probability of the event happening\n\n\n\n\n\n\n\\(k = 2\\), the number of events we care about, in this case flipping a heads\n\n\\(n = 3\\), the number times the coin is flipped\n\n\\(p = 1/2\\), the probability of flipping a heads in a coin toss\n\n\n\nTheorem 4.1 (Shorthand notation of a binomial distribution) \\[B(k; n, p) \\tag{4.1}\\]\n\n\n\n\n\nB stands for binomial distribution\n\nk is separated from the other parameters by a semicolon. This is because when we are talking about a distribution of values, we usually care about all values of \\(k\\) for a fixed \\(n\\) and \\(p\\).\n\nB(k; n, p) denotes each value in the distribution\n\nB(n, p) denotes the whole distribution",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#understanding-and-abstracting-out-the-details-of-our-problem",
    "href": "04-binomial-distribution.html#understanding-and-abstracting-out-the-details-of-our-problem",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "\n4.2 Understanding and Abstracting Out the Details of Our Problem",
    "text": "4.2 Understanding and Abstracting Out the Details of Our Problem\nWe’ll continue with the example of calculating the probability of flipping two heads in three coin tosses. Since the number of possible outcomes is small, we can quickly figure out the results we care about with just pencil and paper.\n\\[HHT, HTH, THH\\] To start generalizing, we’ll break this problem down into smaller pieces we can solve right now, and reduce those pieces into manageable equations. As we build up the equations, we’ll put them together to create a generalized function for the binomial distribution.\n\n\nTheorem 4.2 (Permuation Example for the Binomial Distribution)  \n\nEach outcome we care about will have the same probability.\nEach outcome is just a permutation (GLOSSARY), or reordering, of the others\n\n\\[\n\\begin{align*}\nP({heads, heads, tails}) = P({heads, tails, heads}) = P({tails, heads, heads}) = \\\\\nP(\\text{Desired Outcome})\n\\end{align*}\n\\tag{4.2}\\]\nSee how to do this calculation with R in Section 4.7.1.\n\n\nThere are three outcomes, but only one of them can possibly happen and we don’t care which. And because it’s only possible for one outcome to occur, we know that these are mutually exclusive, denoted as:\n\\[P(\\{heads, heads, tails\\},\\{heads, tails, heads\\},\\{tails, heads, heads\\}) = 0\\] This makes using the sum rule of probability easy.\n\\[\n\\begin{align*}\nP(\\{heads, heads, tails\\} \\operatorname{OR} \\{heads, tails, heads\\} \\operatorname{OR} \\{tails, heads, heads\\}) = \\\\\nP(\\text{Desired Outcome}) + P(\\text{Desired Outcome}) + P(\\text{Desired Outcome}) = \\\\\n3 \\times P(Desired Outcome)\n\\end{align*}\n\\] The value “3” is specific to this problem and therefore not generalizable. We can fix this by simply replacing “3” with a variable called \\(N_{outcomes}\\).\n\n\nTheorem 4.3 (Solution with place holders) \\[B(k;n,p) = N_{outcomes} \\times P(\\text{Desired Outcome}) \\tag{4.3}\\]\n\n\nNow we have to figure out two subproblems:\n\nHow to count the number of outcomes we care about?\nHow to determine the probability for a single outcome?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#counting-our-outcomes-with-the-binomial-coefficient",
    "href": "04-binomial-distribution.html#counting-our-outcomes-with-the-binomial-coefficient",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "\n4.3 Counting Our Outcomes with the Binomial Coefficient",
    "text": "4.3 Counting Our Outcomes with the Binomial Coefficient\nFirst we need to figure out how many outcomes there are for a given k (the outcomes we care about) and n (the number of trials). For small numbers we can simply count. But it doesn’t take much for this to become too difficult to do by hand. The solution is combinatorics (GLOSSARY))`.\n\n4.3.1 Combinatorics: Advanced Counting with the Binomial Coefficient\nThere is a special operation in combinatorics, called the binomial coefficient, that represents counting the number of ways we can select k from n — that is, selecting the outcomes we care about from the total number of trials.\n\n\nTheorem 4.4 (Notation for the binomial coefficient) \\[\\binom{n}{k} \\tag{4.4}\\]\n\n\nWe read this as “n choose k”. In our example we would say “in three tosses choose two heads”:\n\\[\\binom{3}{2}\\]\n\n\nTheorem 4.5 (Definition of the binomial coefficient operation) \\[\\binom{n}{k} = \\frac{n!}{k! \\times (n-k)!} \\tag{4.5}\\]\n\n\nThe ! means factorial, which is the product of all the numbers up to and including the number before the ! symbol, so \\(5! = (5 × 4 × 3 × 2 × 1)\\).\nIn R we compute the binomial coefficient for the case of flipping two heads in three tosses with the following function call:\n\n\n\n\nListing 4.1: Compute the binomial coefficient for flipping two heads in three tosses\n\nchoose(3,2)\n\n\n\n\n[1] 3\n\n\n\nSee how to calculate the binomial coefficient with Base R in Section 4.7.2.\nWe can now replace \\(N_{Outcomes}\\) in Equation 4.3 with the binomial coefficient:\n\\[B(k;n,p) = \\binom{n}{k} \\times P(\\text{Desired Outcome})\\]\n\n4.3.2 Calculating the Probability of the Desired Outcome\nAll we have left to figure out is the \\(P(\\text{Desired Outcome})\\), which is the probability of any of the possible events we care about. So far we’ve been using \\(P(\\text{Desired Outcome})\\) as a variable to help organize our solution to this problem, but now we need to figure out exactly how to calculate this value.\nLet’s focus on a single case of our example of tow heads in three tosses: \\(HHT\\). Using the product rule and negation from the previous chapter, we can describe this problem as: \\[P(heads, heads, no heads) = P(heads, heads, 1-heads)\\] Now we can use the product rule from Equation 3.1:\n\\[\n\\begin{align*}\nP(heads, heads, 1-heads) = \\\\\nP(heads) \\times P(heads) \\times (1-P(heads)) = \\\\\nP(heads)^2 \\times (1-P(heads))^1\n\\end{align*}\n\\] You can see that the exponents for \\(P(heads)^2\\) and \\(1 – P(heads)^1\\) are just the number of heads and the number of not heads in our scenario. These equate to k, the number of outcomes we care about, and n – k, the number of trials minus the outcomes we care about. Puting all together:\n\\[\n\\binom{n}{k} \\times P(heads)^{k} \\times (1- P(heads))^{n-k}\n\\] Generalizing for any probability, not just heads, we replace \\(P(heads)\\) with just p. This gives us a general solution. Compare the following list with Definition 4.1.\n\n\nk, the number of outcomes we care about;\n\nn, the number of trials; and\n\np, the probability of the individual outcome.\n\n\n\nTheorem 4.6 (Probability Mass Function (PMF) for the Binomial Distribution) \\[\n\\binom{n}{k} \\times p^{k} \\times (1- p)^{n-k}\n\\tag{4.6}\\]\n\n\nEquation 4.6 is the basis of the binomial distribution. It is called a Probability Mass Function (GLOSSARY) (PMF). The mass part of the name comes from the fact that we can use it to calculate the amount of probability for any given k using a fixed n and p, so this is the mass of our probability.\nNow that we have this equation, we can solve any problem related to outcomes of a coin toss. For example, we could calculate the probability of flipping exactly 12 heads in 24 coin tosses:\n\\[\nB(12,24,\\frac{1}{2}) = \\binom{24}{12} \\times (\\frac{1}{2})^{12} \\times (1-\\frac{1}{2})^{24-12} = 0.1611803\n\\]\n\n\n\n\nListing 4.2: Calculate the probability of flipping exactly 12 heads in 24 coin tosses\n\nchoose(24,12) * (1 / 2)^(12) * (1 - 1/2)^(24 - 12)\n\n\n\n\n[1] 0.1611803\n\n\n\nThe calculation in Listing 4.2 is only valid for our concrete example.\nFor example, we can plug in all the possible values for k in 10 coin tosses into our PMF and visualize what the binomial distribution looks like for all possible values.\n\n\nFigure 4.1: Binomial Distribution for 10 Coin Flips\n\n\n\n\n\nSee my Figure 4.4 as a replication of Figure 4.1.\nWe can also look at the same distribution for the probability of getting a 6 when rolling a six-sided die 10 times, as shown in Figure 4.2.\n\n\nFigure 4.2: Binomial Distribution for 10 Coin Flips\n\n\n\n\n\nAgain I replicated Figure 4.2 with my Figure 4.6.\nBottom line of the discussion in this section: A probability distribution is a way of generalizing an entire class of problems.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#sec-gacha-games",
    "href": "04-binomial-distribution.html#sec-gacha-games",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "\n4.4 Example: Gacha Games",
    "text": "4.4 Example: Gacha Games\nThere is only one new content in this section: Instead of computing the probability of one event we are going to calculate the possibility of drawing at least one specific card from a pile of infinite numbers of cards where we know the probability of this card we are interested. The aim is to have a p of at last 50% with 100 trials and a probability of 0.720% for the card we are interested.\nAt first let us compute the probability for getting exactly one card we are interested with 100 draws form the pile. We know the probability to draw the featured card is 0.720%.\n\\[\\binom{100}{1} \\times 0.00720^{1} \\times (1- 0.00720)^{100-1}\\]\n\n\n\nListing 4.3: Draw exact one card that has p = 0.720%\n\ndbinom(1, 100, 0.00720)\n\n\n\n\n[1] 0.352085\n\n\nAnd now let’s compute the probability for at least one card we are interested.\nIn R, we can use the Binomial Cumulative Distribution Function pbinom() to automatically sum up all the values of the card we are interested in our PMF.\n\n\nFigure 4.3: How the pbinom() function works\n\n\n\n\n\nThe pbinom() function takes three required arguments and an optional fourth called lower.tail (which defaults to TRUE). When the fourth argument is TRUE, the first argument sums up all of the probabilities less than or equal to our argument. When lower.tail is set to FALSE, it sums up the probabilities strictly greater than the first argument. By setting the first argument to \\(0\\), we are looking at the probability of getting one or more the cards we are interested. We set lower.tail to FALSE because that means we want values greater than the first argument (by default, we get values less than the first argument).\n\n\n\nListing 4.4: Example Calculation with the pbinom() Function\n\npbinom(0, 100, 0.00720, lower.tail = FALSE)\n\n\n\n\n[1] 0.5145138\n\n\nVoilá! This is the same result as in @#fig-pbinom-function.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#wrapping-up",
    "href": "04-binomial-distribution.html#wrapping-up",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "\n4.5 Wrapping Up",
    "text": "4.5 Wrapping Up\nIn this chapter Will Kurt demonstrated how we can deduce intuitively the formula for the binomial coefficient (GLOSSARY).\n\n\n\n\n\n\nNote\n\n\n\nI have seen this monstrosity of expression for the binomial coefficient many times in different books and was always overwhelmed from its complexity. But this has changed now: Will Kurt succeeded to demystify the formula for me!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#exercises",
    "href": "04-binomial-distribution.html#exercises",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "\n4.6 Exercises",
    "text": "4.6 Exercises\nTry answering the following questions to make sure you’ve grasped binomial distributions fully. The solutions can be found at https://nostarch.com/learnbayes/.\n\n4.6.1 Exercise 4.1\n\nExercise 4.1 What are the parameters of the binomial distribution for the probability of rolling either a 1 or a 20 on a 20-sided die, if we roll the die 12 times?\n\nk = interested events: 1 and 20 = 2.\nn = number of trials = 12\np = probability for each trial = \\(\\frac{2}{12}\\)\n\n\n\n\n\nListing 4.5: Binomial distribution for the probability of rolling either a 1 or a 20 on a 20-sided die, if we roll the die 12 times\n\ndbinom(2, 12, 2/20)\n\n\n\n\n[1] 0.2301278\n\n\n\n\n4.6.2 Exercise 4.2\n\nExercise 4.2 There are four aces in a deck of 52 cards. If you pull a card, return the card, then reshuffle and pull a card again, how many ways can you pull just one ace in five pulls?\n\n\n\nListing 4.6: If you pull a card, return the card, then reshuffle and pull a card again, how many ways can you pull just one ace in five pulls?\n\ncombinat::combn(x = 1:5, m = 1, fun = tabulate, simplify = TRUE, nbins = 5)\n\n\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    0    0    0    0\n[2,]    0    1    0    0    0\n[3,]    0    0    1    0    0\n[4,]    0    0    0    1    0\n[5,]    0    0    0    0    1\n\n\n\nListing 4.7: If you pull a card, return the card, then reshuffle and pull a card again, how many ways can you pull just one ace in five pulls?\n\nchoose(5,1)\n\n\n\n\n[1] 5\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn contrast to the result in the solution manual I programmed the exercise with combinat::combn(). This correct solution pretends that I could use it for every possible arrangement. That is not true. For instance I could not manage to display the many ways of rolling two 6s in three rolls of a six-sided die.\n\n\n\n\n4.6.3 Exercise 4.3\n\nExercise 4.3 For the example in Exercise 4.2, what is the probability of pulling five aces in 10 pulls (remember the card is shuffled back in the deck when it is pulled)?\n\n\n\nListing 4.8: Probability of pulling five aces in 10 pulls with replacing\n\ndbinom(5, 10, 4 / 52) * 100\n\n\n\n\n[1] 0.04548553\n\n\n\n\n\n\n\n\nWarning\n\n\n\nOnly about 0.0455%. But this is different than the result in the solution manual with 1/32000 = 0.003125%. I don’t know why there is this difference.\n\n\n\n\n4.6.4 Exercise 4.4\n\nExercise 4.4 When you’re searching for a new job, it’s always helpful to have more than one offer on the table so you can use it in negotiations. If you have a 1/5 probability of receiving a job offer when you interview, and you interview with seven companies in a month, what is the probability you’ll have at least two competing offers by the end of that month?\n\n\n\nListing 4.9: Probability of at least 2 interviews each with 1/5 chance for a job offer having 7 interviews\n\npbinom(1, 7, 1/5, lower.tail = FALSE)\n\n\n\n\n[1] 0.4232832\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere is chance of about 42% that you receive at least two job offers.\nIn my first trial I calculated wrongly the probability for exact 2 competing offers with dbinom(2, 7, 1/2) instead of at least 2 competing offers! Additionally I forgot to add lower.tail = FALSE. to calculate more than x: x = 1, more than 1 = 2, therefore the first parameter is 1 (and not 2 as could be thought wrongly). Not using lower.tail = FALSE means that the default value of lower.tail = TRUE computes the probability of \\(P[X &lt;= x]\\) (instead of \\(P[X &gt; x]\\)).\n\n\n\n\n4.6.5 Exercise 4.5\n\nExercise 4.5 You get a bunch of recruiter emails and find out you have 25 interviews lined up in the next month. Unfortunately, you know this will leave you exhausted, and the probability of getting an offer will drop to 1/10 if you’re tired. You really don’t want to go on this many interviews unless you are at least twice as likely to get at least two competing offers. Are you more likely to get at least two offers if you go for 25 interviews, or stick to just 7?\n\n\n\nListing 4.10: Probability of at least 2 interviews each with 1/10 chance for a job offer having 25 interviews\n\npbinom(1, 25, 1/10, lower.tail = FALSE)\n\n\n\n\n[1] 0.7287941\n\n\nWith a reduced probability per interview you raised your changes from 42,3% to 72,9%. But to get an job offer is not twice as likely so you stick with 7 interviews.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "04-binomial-distribution.html#experiments",
    "href": "04-binomial-distribution.html#experiments",
    "title": "4  Creating a Binomial Probability Distribution",
    "section": "\n4.7 Experiments",
    "text": "4.7 Experiments\n\n4.7.1 Permutation with R\nI want to get the same result as in Equation 4.2, but this time using R. What are the permutations of possible events by flipping two heads in three coin tosses?\nLet’s P(heads) = 1 and P(tails) = 0, then we can use combinat::combn(). The package {combinat} is not part of Base R, so you have to install it.\n\n\n\nListing 4.11: Permutations of possible events by flipping two heads in three coin tosses\n\ncombinat::combn(x = c(1,2,3), m = 2, fun = tabulate, simplify = TRUE, nbins = 3)\n\n\n\n\n     [,1] [,2] [,3]\n[1,]    1    1    0\n[2,]    1    0    1\n[3,]    0    1    1\n\n\nThe syntax is: combn(x, m, fun = NULL, simplify = TRUE, ...).\n\n\nx: vector source for combinations equivalent to the the number of events.\n\nm: number of elements we are interested in\n\nfun = function to be applied to each combination (may be null). I am using the base::tabulate() to take the integer-valued vector and counting the number of times each integer occurs in it.\n\nsimplify: logical, if FALSE, returns a list, otherwise returns vector or array.\n\n...: arguments for the used function. In our case nbins refers to the number of bin used by the tabulate() function.\n\nLet’s try another example to understand better the pattern of the combn() functions: What are the permutations of possible events by flipping a coin 5 times and getting three heads:\n\n\n\nListing 4.12: Permutations of possible events by flipping two heads in five coin tosses\n\ncombinat::combn(x = 1:5, m = 2, fun = tabulate, simplify = TRUE, nbins = 5)\n\n\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1    1    1    1    0    0    0    0    0     0\n[2,]    1    0    0    0    1    1    1    0    0     0\n[3,]    0    1    0    0    1    0    0    1    1     0\n[4,]    0    0    1    0    0    1    0    1    0     1\n[5,]    0    0    0    1    0    0    1    0    1     1\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere is also a special package {dice} for the calculation of various dice-rolling events. We could for instance compute the probability “What is the probability of rolling two 6s in three rolls of a six-sided die?” directly with:\n\n\n\nListing 4.13: Compute the probability of rolling two 6s in three rolls of a six-sided die\n\ndice::getEventProb(nrolls = 3,\n                   ndicePerRoll = 2,\n                   nsidesPerDie = 6,\n                   eventList = list(6, 6))\n\n\n\n\n[1] 0.052512\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nActually I did not understand the many implications of computing combinations and / or permutations with different functions and different packages:\n\nutils::combn()\ncombinat::combn()\n\ngtools::combinations() and gtools::permutations()\n\n\npermute::permute(), permute::shuffle()\n\nbase::expand.grid()\n\ntidyr::expand(), tidyr::crossing(), tidyr::nesting(), tidyr::expand_grid()\n\n\nAs far as I understand from my study of the Statistical Rethinking book, these functions are an important topic to understand Bayesian Statistics. These types of functions are used for grid approximation and in Bayesian statistics to extract or draw samples from fit models (e.g., rethinking::extract.samples(), rethinking::extract.prior())\nI am sure I will need to come back to this issue and study available material more in detail! But at the moment I am stuck and will skip this subject.\n\n\n\n4.7.2 Compute binomial coefficient manually\nI want to replicate the Base R function chosse() with Equation 4.5. This involves to calculate factorials with the base::factorial() function.\n\\[\\binom{n}{k} = \\frac{n!}{k! \\times (n-k)!}\\]\n\n\n\nListing 4.14: Calculate the probability of flipping exactly 12 heads in 24 coin tosses\n\nmy_choose &lt;-  function(n, k) {\n    factorial(n) / (factorial(k) * factorial(n - k))\n}\n\nchoose(24, 12) == my_choose(24, 12)\n\n\n\n\n[1] TRUE\n\n\nCalculation of \\(\\binom{24}{12}\\):\n\nWith Base R function choose(24, 12) = 2.704156^{6}.\nWith my own function my_choose(24, 12) = 2.704156^{6}.\n\n4.7.3 Compute density of the binomial distribution\nTo generalize I write my own function for the density of the binomial distribution. I will use the same arguments names as in Definition 4.1.\n\n\n\nListing 4.15: Function for the density of the binomial distribution\n\nmy_dbinom &lt;- function(k, n, p) {\n    choose(n, k) * p^k * (1 - p)^(n - k)\n}\n\nmy_dbinom(12, 24, 0.5)\n\n\n\n\n[1] 0.1611803\n\n\nVoilá: It gives the same result as the manual calculation in Listing 4.2.\nI wonder if there is not a Base R function which does the same as my_dbinom(). I tried stats::dbinom() and it worked!\n\n\n\nListing 4.16: Base R dbinom() function calculates the density of the binomial distribution\n\ndbinom(12, 24, 0.5)\n\n\n\n\n[1] 0.1611803\n\n\nAgain the same result as in Listing 4.2 and Listing 4.15!\n\n4.7.4 Replication of the Binomial Distribution of 10 Coin Flips\nHere I am going to try to replicate Figure 4.1.\n\n\n\nListing 4.17: Replicate Figure 4.1: Binomial Distribution of 10 Coin Flips\n\nk_values &lt;- seq.int(from = 0, to = 10 , by = 1)\n\ndata.frame(x = k_values, \n           y = dbinom(k_values, 10, 0.5)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_col()\n\n\n\n\n\n\nFigure 4.4: Replication of Figure 4.1: Binomial Distribution of 10 Coin Flips with {ggplot2}\n\n\n\n\n\n\n\nWriting Listing 4.17 I had troubles applying the correct geom. At first I used geom_bar() but this did not work until I learned that I have to add the option “stat = identity” or to use geom_col(). The difference is:\n\n\ngeom_bar() makes the height of the bar proportional to the number of cases in each group. It uses stat_count() by default, e.g. it counts the number of cases at each x position. If there aren’t cases but only the values then one has to add “stat = identity” to declare that ggplot2 should take the data “as-is”.\n\n\ngeom_col() instead takes the heights of the bars to represent values in the data. It uses stat_identity() and leaves the data “as-is” by default.\n\n\n\n\n\n\n\nTip\n\n\n\nDuring my research for writing Listing 4.17 I learned of the {tidydice} package. It simulates dice rolls and coin flips and can be used for teaching basic experiments in introductory statistics courses.\nWith {tidydice} we replicate Figure 4.1 with just 2 lines using the binom_coin() inside the plot_binom() function. In addition to the graphical distribution it print also the exact values on top of the bars.\n\n\n\nListing 4.18: Replicate Figure 4.1: Binomial Distribution of 10 Coin Flips {tidydice}\n\ntidydice::plot_binom(\n  tidydice::binom_coin(times = 10, sides = 2, success = 2),\n  title = \"Binomial distribution of 10 coin flips\"\n)\n\n\n\n\n\n\nFigure 4.5: Replication of Figure 4.1: Binomial Distribution of 10 Coin Flips with {tidydice}\n\n\n\n\n\n\n\n{tidydice} has many other functions related to coin and dice experiments.\n\n\n\n4.7.5 Replication of the Binomial Distribution of 10 Dice Rolls\nI will replicate Figure 4.2 with {ggplot2} and with {tidydice}:\n\n\n\nListing 4.19: Replicate Figure 4.2: Binomial Distribution of 10 Dice Rolls\n\nk_values &lt;- seq.int(from = 0, to = 10 , by = 1)\n\ndata.frame(x = k_values, \n           y = dbinom(k_values, 10, 1/6)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_col()\n\n\n\n\n\n\nFigure 4.6: Replication of Figure 4.2: Binomial Distribution of 10 Dice Rolls with {ggplot2}\n\n\n\n\n\n\n\n\n\n\nListing 4.20: Replicate Figure 4.2: Binomial Distribution of 10 Dice Rolls {tidydice}\n\ntidydice::plot_binom(\n  tidydice::binom_dice(times = 10, sides = 6, success = 6),\n  title = \"Binomial distribution of 10 dice rolls\"\n)\n\n\n\n\n\n\nFigure 4.7: Replication of Figure 4.2: Binomial Distribution of 10 Dice Rolls with {tidydice}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Creating a Binomial Probability Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html#a-strange-scenario-getting-the-data",
    "href": "05-beta-distribution.html#a-strange-scenario-getting-the-data",
    "title": "5  The Beta Distribution",
    "section": "",
    "text": "5.1.1 Distinguishing Probability, Statistics, and Inference\nIn all of the examples so far, outside of the first chapter, we’ve known the probability of all the possible events, or at least how much we’d be willing to bet on them. In real life we are almost never sure what the exact probability of any event is; instead, we just have observations and data.\nThis is commonly considered the division between probability and statistics. In probabilities, probability (GLOSSARY), we know exactly how probable all of our events are, and what we are concerned with is how likely certain observations are. For example, we might be told that there is 1/2 probability of getting heads in a fair coin toss and want to know the probability of getting exactly 7 heads in 20 coin tosses.\nIn statistics discipline, statistics (GLOSSARY), we would look at this problem backward: assuming you observe 7 heads in 20 coin tosses, what is the probability of getting heads in a single coin toss? In a sense, statistics is probability in reverse. The task of figuring out probabilities given data is called inferential statistics, inference (GLOSSARY), and it is the foundation of statistics.\n\n5.1.2 Collecting Data\nWe want to estimate the probability that the mysterious box will deliver two quarters, and to do that, we first need to see how frequently you win after a few more tries. We’ve got 14 wins and 27 losses.\nWithout doing any further analysis, you might intuitively want to update your guess that P(two quarters) = 1/2 to P(two quarters) = 14/41. But what about your original guess—does your new data mean it’s impossible that 1/2 is the real probability?\n\n5.1.3 Calculating the Probability of Probabilities\n\\[\n\\begin{align*}\nH_{1} \\space is \\space P(\\text{two coins}) = \\frac{1}{2} \\\\\nH_{2} \\space is \\space P(\\text{two coins}) = \\frac{14}{41}\n\\end{align*}\n\\] “How probable is what we observed if \\(H_{1}\\) were true versus if \\(H_{2}\\) were true?” We can easily calculate this using Equation 4.6 of the binomial distribution from Chapter 4.\n\n\n\nListing 5.1: Calculating the Probability of Probabilities with dbinom()\n\n(H1 &lt;- dbinom(14, 41, 1/2))\n\n\n\n\n[1] 0.01602537\n\n\n\nListing 5.2: Calculating the Probability of Probabilities with dbinom()\n\n(H2 &lt;- dbinom(14, 41, 14/41))\n\n\n\n\n[1] 0.1304709\n\n\nThis shows us that, given the data (observing 14 cases of getting two coins out of 41 trials), \\(H_{2}\\) is almost 10 times more probable than \\(H_{1}\\)! However, it also shows that neither hypothesis is impossible and that there are, of course, many other hypotheses we could make based on our data.\nIf we wanted to look for a pattern, we could pick every probability from 0.1 to 0.9, incrementing by 0.1; calculate the probability of the observed data in each distribution; and develop our hypothesis from that.\n\n\nFigure 5.1: Visualization of different hypotheses about the rate of getting two quarters\n\n\n\n\n\nEven with all these hypotheses, there’s no way we could cover every possible eventuality because we’re not working with a finite number of hypotheses. So let’s try to get more information by testing more distributions. If we repeat the last experiment, testing each possibility at certain increments starting with 0.01 and ending with 0.99, incrementing by only 0.01 would give us the results in Figure 5.2.\n\n\nFigure 5.2: We see a definite pattern emerging when we look at more hypotheses\n\n\n\n\n\nThis seems like valuable information; we can easily see where the probability is highest. Our goal, however, is to model our beliefs in all possible hypotheses (that is, the full probability distribution of our beliefs).\nThere are two problems:\n\nThere’s an infinite number of possible hypotheses, incrementing by smaller and smaller amounts doesn’t accurately represent the entire range of possibilities—we’re always missing an infinite amount. (In practice, this isn’t a huge problem.)\nThere are 11 dots above 0.1 right now, and we have an infinite number of points to add. This means that our probabilities don’t sum to 1!\n\nEven though there are infinitely many possibilities here, we still need them all to sum to 1. This is where the beta distribution comes in.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html#sec-beta-distribution",
    "href": "05-beta-distribution.html#sec-beta-distribution",
    "title": "5  The Beta Distribution",
    "section": "\n5.2 Beta Distribution",
    "text": "5.2 Beta Distribution\nUnlike the binomial distribution (GLOSSARY), which breaks up nicely into discrete values, the beta distribution (GLOSSARY) represents a continuous range of values, which allows us to represent our infinite number of possible hypotheses.\nWe define the beta distribution with a probability density function PDF (GLOSSARY), which is very similar to the probability mass function we use in the binomial distribution, but is defined for continuous values.\n\nTheorem 5.1 (Formula for the PDF of the beta function) \\[\nBeta(p; \\alpha,\\beta) = \\frac{p^{\\alpha - 1} \\times (1 - p)^{\\beta - 1}}{beta(\\alpha, \\beta)}\n\\tag{5.1}\\]\n\n\n5.2.1 Breaking Down the Probability Density Function\np: Represents the probability of an event. This corresponds to our different hypotheses for the possible probabilities for our black box.\n$\\alpha$: Represents how many times we observe an event we care about, such as getting two quarters from the box.\n$\\beta$: Represents how many times the event we care about didn’t happen. For our example, this is the number of times that the black box ate the quarter.\n$\\alpha + \\beta$: The total number of trials. This is different than the binomial distribution, where we have k observations we’re interested in and a finite number of n total trials.\nThe top part of the PDF (GLOSSARY) function should look pretty familiar because it’s almost the same as the binomial distribution’s PMF (GLOSSARY) in Equation 4.6.\nDifferences between the PMF of the binomial distribution and the PDF of the beta distribution:\n\nIn the PDF, rather than \\(p^{k} \\times (1- p)^{n-k}\\), we have \\(p^{\\alpha - 1} \\times (1 - p)^{\\beta - 1}\\) where we subtract 1 from the exponent terms.\nWe also have another function in the denominator of our equation: the beta function (note the lowercase) for which the beta distribution is named. We subtract 1 from the exponent and use the beta function to normalize our values—this is the part that ensures our distribution sums to 1. The beta function is the integral from 0 to 1 of \\(p^{\\alpha - 1} \\times (1 - p)^{\\beta - 1}\\). (A discussion of how subtracting 1 from the exponents and dividing by the beta functions normalizes our values is beyond the scope of this chapter.)\n\nWhat we get in the end is a function that describes the probability of each possible hypothesis for our true belief in the probability of getting two heads from the box, given that we have observed \\(\\alpha\\) examples of one outcome and \\(\\beta\\) examples of another. Remember that we arrived at the beta distribution by comparing how well different binomial distributions, each with its own probability \\(p\\), described our data. In other words, the beta distribution represents how well all possible binomial distributions describe the data observed.\n\n5.2.2 Applying the Probability Density Function to Our Problem\nWhen we plug in our values for our black box data and visualize the beta distribution, shown in Figure 5.3, we see that it looks like a smooth version of the plot in Figure 5.2.\n\n\nFigure 5.3: Visualizing the beta distribution for our data collected about the black box\n\n\n\n\n\nWhile we can see the distribution of our beliefs by looking at a plot, we’d still like to be able to quantify exactly how strongly we believe that “the probability that the true rate at which the box returns two quarters is less than 0.5.”\n\n5.2.3 Quantifying Continuous Distributions with Integration\nThe beta distribution is fundamentally different from the binomial distribution in that with the latter, we are looking at the distribution of \\(k\\), the number of outcomes we care about, which is always something we can count. For the beta distribution, however, we are looking at the distribution of \\(p\\), for which we have an infinite number of possible values.\nWe know that the fundamental rule of probability is that the sum of all our values must be 1, but each of our individual values is infinitely small, meaning the probability of any specific value is in practice 0.\n\n\n\n\n\n\nNote\n\n\n\nThe zero probability of an event in a continuous distribution does not mean that this event never could happen. Zero probability only means that the events gets the probability measure of zero.\nOur intuition from discrete probability is that if an outcome has zero probability, then the outcome is impossible. With continuous random variables (or more generally, an infinite number of possible outcomes) that intuition is flawed. (StackExchange)\n\n\nFor example, even if we divided a 1-pound bar of chocolate into infinitely many pieces, we can still add up the weight of the pieces in one half of the chocolate bar. Similarly, when talking about probability in continuous distributions, we can sum up ranges of values. But if every specific value is 0, then isn’t the sum just 0 as well?\nThis is where calculus comes in: in calculus, there’s a special way of summing up infinitely small values called the integral.\nIf we want to know whether the probability that the box will return a coin is less than 0.5 (that is, the value is somewhere between 0 and 0.5), we can sum it up like this:\n\\[\\int_{0}^{0.5} \\frac{p^{14 - 1} \\times (1 - p)^{27 - 1}}{beta(14, 27)} \\tag{5.2}\\]\nR includes a function called dbeta() that is the PDF for the beta distribution. This function takes three arguments, corresponding to \\(p\\), \\(\\alpha\\), and \\(\\beta\\). We use this together with R’s integrate() function to perform this integration automatically. Here we calculate the probability that the chance of getting two coins from the box is less than or equal to 0.5, given the data:\n\n\n\nListing 5.3: Probability of getting two coins from the box is less than or equal to 0.5, given the data\n\nintegrate(function(p) dbeta(p,14,27),0,0.5)\n\n\n\n\n0.9807613 with absolute error &lt; 5.9e-06\n\n\nThe “absolute error” message appears because computers can’t perfectly calculate integrals so there is always some error, though usually it is far too small for us to worry about. This result from R tells us that there is a 0.98 probability that, given our evidence, the true probability of getting two coins out of the black box is less than 0.5. This means it would not be good idea to put any more quarters in the box, since you very likely won’t break even.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html#reverse-engineering-the-gacha-game",
    "href": "05-beta-distribution.html#reverse-engineering-the-gacha-game",
    "title": "5  The Beta Distribution",
    "section": "\n5.3 Reverse-Engineering the Gacha Game",
    "text": "5.3 Reverse-Engineering the Gacha Game\nIn real-life situations, we almost never know the true probabilities for events. That’s why the beta distribution is one of our most powerful tools for understanding our data.\nIn Section 4.4 of Chapter 4 , we knew the probability of the card we wanted to pull. In reality, the game developers are very unlikely to give players this information, for many reasons (such as not wanting players to calculate how unlikely they are to get the card they want).\nThis time we don’t know the rates for the card, but we really want that card—and more than one if possible. We spend a ridiculous amount of money and find that from 1,200 cards pulled, we received only 5 cards we’re interested in. Our friend is thinking of spending money on the game but only wants to do it if there is a better than 0.7 probability that the chance of pulling the card is greater than 0.005.\nOur data tells us that of 1,200 cards pulled, only 5 were cards we are interested in, so we can visualize this as Beta(5,1195), shown in Figure 5.4 (remember that the total cards pulled is \\(\\alpha + \\beta\\)).\n\n\nFigure 5.4: The beta distribution for getting the card we are interested in, given our data\n\n\n\n\n\nFrom our visualization we can see that nearly all the probability density is below 0.01. We need to know exactly how much is above 0.005, the value that our friend cares about. We can solve this by integrating over the beta distribution in R:\n\n\n\nListing 5.4: Probability that the rate of pulling a card we are interested is 0.005 or greater\n\nintegrate(function(x) dbeta(x,5,1195),0.005,1)\n\n\n\n\n0.2850559 with absolute error &lt; 1e-04\n\n\nThis tells us the probability that the rate of pulling a card we are interested is 0.005 or greater, given the evidence we have observed, is only 0.29. Our friend will pull for this card only if the probability is around 0.7 or greater, so based on the evidence from our data collection, our friend should not try his luck.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html#wrapping-up",
    "href": "05-beta-distribution.html#wrapping-up",
    "title": "5  The Beta Distribution",
    "section": "\n5.4 Wrapping Up",
    "text": "5.4 Wrapping Up\nWe learned about the beta distribution, which is closely related to the binomial distribution but behaves quite differently. The major difference between the beta distribution and the binomial distribution is that the beta distribution is a continuous probability distribution. Because there are an infinite number of values in the distribution, we cannot sum results the same way we do in a discrete probability distribution. Instead, we need to use calculus to sum ranges of values. Fortunately, we can use R instead of solving tricky integrals by hand.\nWe built up to the beta distribution by observing how well an increasing number of possible binomial distributions explained our data. The beta distribution allows us to represent how strongly we believe in all possible probabilities for the data we observed. This enables us to perform statistical inference on observed data by determining which probabilities we might assign to an event and how strongly we believe in each one: a probability of probabilities.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html#exercises",
    "href": "05-beta-distribution.html#exercises",
    "title": "5  The Beta Distribution",
    "section": "\n5.5 Exercises",
    "text": "5.5 Exercises\nTry answering the following questions to make sure you understand how we can use the Beta distribution to estimate probabilities. The solutions can be found at https://nostarch.com/learnbayes/.\n\n5.5.1 Exercise 5-1\nYou want to use the beta distribution (GLOSSARY) to determine whether or not a coin you have is a fair coin — meaning that the coin gives you heads and tails equally. You flip the coin 10 times and get 4 heads and 6 tails. Using the beta distribution, what is the probability that the coin will land on heads more than 60 percent of the time?\n\n\n\nListing 5.5: Probability that a coin will land on heads more than 60% given 4 heads in 10 tosses\n\nintegrate(function(p) dbeta(p, 4, 6), 0.6, 1)\n\n\n\n\n0.09935258 with absolute error &lt; 1.1e-15\n\n\n\n5.5.2 Exercise 5-2\nYou flip the coin 10 more times and now have 9 heads and 11 tails total. What is the probability that the coin is fair, using our definition of fair, give or take 5 percent?\n\n\n\nListing 5.6: Probability that a coin is fair within a 5% range given 9 heads in 20 tosses\n\nintegrate(function(p) dbeta(p, 9, 11), 0.45, 0.55)\n\n\n\n\n0.30988 with absolute error &lt; 3.4e-15\n\n\n\n5.5.3 Exercise 5-3\nData is the best way to become more confident in your assertions. You flip the coin 200 more times and end up with 109 heads and 111 tails. Now what is the probability that the coin is fair, give or take 5 percent?\n\n\n\nListing 5.7: Probability that a coin is fair within a 5% range given 109 heads in 220 tosses\n\nintegrate(function(p) dbeta(p, 109, 111), 0.45, 0.55)\n\n\n\n\n0.8589371 with absolute error &lt; 9.5e-15",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "05-beta-distribution.html#experiments",
    "href": "05-beta-distribution.html#experiments",
    "title": "5  The Beta Distribution",
    "section": "\n5.6 Experiments",
    "text": "5.6 Experiments\n\n5.6.1 Replicating Figure 5.1\nTo replicate Figure 5.1 we need to pick every probability from 0.1 to 0.9, incrementing by 0.1; and then to calculate the probability of the observed data (14 cases of getting two coins out of 41 trials) in each distribution:\n\n\n\nListing 5.8: Replication of Figure 5.1: Visualization of different hypotheses about the rate of getting two quarters from the black box\n\ntibble::tibble(x = seq(from = 0.1, to = 0.9, by = 0.1),\n                    y = dbinom(14, 41, x)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_point() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Probability of different values for p given observation\",\n        x = \"p\",\n        y = \"Probability\"\n    )\n\n\n\n\n\n\nFigure 5.5: Visualization of different hypotheses about the rate of getting two quarters from the black box\n\n\n\n\n\n\n\n\n5.6.2 Replicating Figure 5.2\nRepeating Section 5.6.1, we want to display each possibility at smaller increments starting with 0.01 and ending with 0.99, incrementing by only 0.01:\n\n\n\nListing 5.9: Replication of Figure 5.2: We see a definite pattern emerging when we look at more hypotheses\n\ntibble::tibble(x = seq(from = 0.01, to = 0.99, by = 0.01),\n                    y = dbinom(14, 41, x)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_point() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Probability of different values for p given observation\",\n        x = \"p\",\n        y = \"Probability\"\n    )\n\n\n\n\n\n\nFigure 5.6: A definite pattern emerging when we look at more hypotheses\n\n\n\n\n\n\n\n\n5.6.3 Replicating Figure 5.3\nOur data: We’ve got 14 successes (two coins) with 41 trials.\n\n\n\nListing 5.10: Replication of Figure 5.3: Visualizing the beta distribution for our data collected about the black box\n\ntibble::tibble(x = seq(from = 0, to = 1, by = 0.01),\n                    y = dbeta(x, 14, 27)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution for Beta(14, 27)\",\n        x = \"p\",\n        y = \"Probability\"\n    )\n\n\n\n\n\n\nFigure 5.7: Visualizing the beta distribution for our data collected about the black box\n\n\n\n\n\n\n\n\n5.6.4 Replicating Figure 5.4\nOur data tells us that of 1,200 cards pulled, there were only 5 cards we are interested in. Our friend is thinking of spending money on the game but only wants to do it if there is a better than 0.7 probability that the chance of pulling a Bradley Efron (the card we are interested) is greater than 0.005.\n\n\n\nListing 5.11: Replication of Figure 5.4: The beta distribution for getting the card we are interested in, given our data\n\ntibble::tibble(x = seq(from = 0, to = 1, length = 1000),\n              y = dbeta(x,5,1195)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Pulling a Bradley Efron Card, Beta(5, 1195)\",\n        x = \"p\",\n        y = \"Probability\"\n)\n\n\n\n\n\n\nFigure 5.8: The beta distribution form 0 to 1 for getting the card we are interested in, given our data\n\n\n\n\n\n\n\nThis was my first try. At first I thought that my Listing 5.11 is wrong as Figure 5.4 has a very different appearance. But then I noticed that my graphics displays value from 0 to 1 whereas Figure 5.4 visualizes only values between 0 and 0.01!\nIn Listing 5.12 I changed the visualization just showing values from 0 to 0.01.\n\n\n\nListing 5.12: Replication of Figure 5.4: The beta distribution for getting the card we are interested in, given our data\n\ntibble::tibble(x = seq(from = 0, to = 0.01, length = 1000),\n              y = dbeta(x,5,1195)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Pulling a Bradley Efron Card, Beta(5, 1195)\",\n        x = \"p\",\n        y = \"Probability\"\n)\n\n\n\n\n\nThe beta distribution form 0 to 0.01 for getting the card we are interested in, given our data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Beta Distribution</span>"
    ]
  },
  {
    "objectID": "index.html#sec-book-motivation",
    "href": "index.html#sec-book-motivation",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "About My Motivation for this Quarto Book",
    "text": "About My Motivation for this Quarto Book\nI am not an expert in statistics. During my study in sociology back in 1970er I had only rudimentary learned about frequentist statistics (GLOSSARY). There weren’t computer only via time-sharing and keypunching for card-to-tape converter available. This was painstaking and not motivating because it had not much practical values. 10 years later I worked sometimes with SPSS but used — as many of my colleagues — the “statistics all” option without much understanding. It was no fun and so I dedicated most of my time to theoretical work and later sometimes to qualitative social research via grounded theory.\nOnly when I heard 2015 about R and began to exerpiment with it, I started my self-directed education in statistics again. Still I was not so intrigued by Null Hypothesis Statistical Testing (NHST) but more from Data Science. I noticed the problems with p-values and was therefore fascinated with Introduction to the New Statistics by Geoff Cumming & Robert Calin-Jageman (cumming2017?). Instead of concentrating on p-values the book teaches the importance of confidence interval,confidence intervals (GLOSSARY), (CIs). But at that time I came across some discussion about Bayesian statistics (GLOSSARY. I read The Theory That Would Not Die: How Bayes’ Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant From Two Centuries of Controversy by Sharon Bertsch McGrayne (mcgrayne2011?) but didn’t understand at that time how Bayesian statistics works.\nThe real game changer for me then was Statistical Rethinking by Richard McElreath (mcelreath2020?). I immediately started my first Quarto book with notes about the book and the companion bookdown website Statistical rethinking with brms, ggplot2, and the tidyverse: Second edition by A Solomon Kurz. But unfortunately after four chapters I noticed that I am lacking basic knowledge and looked around for other books on Bayesian statistics that are easier to digest for me. I tried A Student’s Guide to Bayesian Statistics by Ben Lambert (lambert2018?), but I stopped reading it after chapter eight. I has to much theory for me and I was missing the opportunity trying my own hands out with R.\nSo finally I came around to Will Kurt’s book. I understand that the modern simulation methods like MCMC are not in the focus of the book and also the usage of R code is distributed very sparsely in the book. But I learned (and understood) many Bayesian concepts and could all the graphics in the book — where the R code is missing — replicate with {ggplot2} (ggplot2?) in tidyverse (tidyverse?) style. The book was at the time (September/October 2023) a perfect match for my rudimentary knowledge. I have now more trust to continue with Statistical Rethinking or — as a possible alternative — to start with a new Quarto book on Doing Bayesian Data Analysis: A Tutorial With R, JAGS, and Stan (kruschke2014?) which I have already read and (I believe) mostly understood.\nAnother motivation to write a Quarto book was to learn how to use Quarto. I already wrote some books with bookdown (bookdown?) but Quarto was relatively new for me. This book was therefore a good occasion to learn and experiment with the functionality of Quarto.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#content-and-goals-of-this-book",
    "href": "index.html#content-and-goals-of-this-book",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "Content and Goals of this Book",
    "text": "Content and Goals of this Book\nThis book collects personal notes during reading of Bayesian Statistics the Fun Way by Will Kurt. Additionally I am using C: Answers to Exercises\nEach chapter of the book has three main parts:\nShort summaries of the book content\nThis summarizes my own highlights but gives also the necessary information for my section about “Experiments”. Mostly I quote the text but without page references. Often I made minor editing (e.g., shorting the text) or put sometimes the content in my own wording. As I follow the text section by section reader can easily find the quoted passage.\nAlmost all of my text of this first part of the Quarto book are not mine, but is coming from the resources mentioned above. There are two exceptions:\n\nWhenever necessary I include personal notes already in this part of the chapter. Most of the time it is combined with a cross reference to the third main part of the book: my experiments.\nSometimes there is also base R Code by the author provided. Whenever possible I convert this base R code by the author in {tidyverse} code.\nI copied all figures into the text as a template for my own replication.\n\n\n\n\n\n\n\nImportant\n\n\n\nAlthough I have quoted many passages from the original as highlights for me to remember, this Quarto ebook is not meant to stand alone. My summaries are driven by my personal interests and my huge gaps in my statistical knowledge and especially in Bayesian statistics. My notes are therefore in no way a substitute for Will Kurt’s book Bayesian Statistics the Fun Way: Understanding Statistics and Probability With Star Wars, LEGO, and Rubber Ducks by Will Kurt (kurt2019?). Please buy the book so that you can embed my notes appropriately in the general argumentation of the author.\n\n\nExercises\nAgain I quote the full question text and then try my own solution. If my solution is not correct or I cant find a solution I will note this in a personal callout and will correct the solution. If my solution is correct but with a different method I will also reflect on the result, but will not adapt or change my solution.\nExperiments\nHere I am trying to make my own exercises. Most of the examples are replications of the book figures because the author has not included the R code. Additionally I cross referenced to the figure from the first part, the author section. If you hover over the cross reference link you will get the authors figure overlaid and can compare it with my replication.\nWriting my own R chunks I am using the tidy approach with the collection of the {tidyverse} packages, especially with {ggplot2} for the figures. But instead of using the library() command I always mention the used packages explicitly. Whenever I used another packages I called the function with the package name in front with the syntax &lt;package name&gt;::&lt;function name&gt;(), like ggplot2::gplot(). This is tedious work but it helps me to learn & remember which command “belongs” to which package. Only exception is the {patchwork} package, as I do not know how to call commands like p1 + p2 with the package name.\nIn graphics I use not only caption for figures but also captions for the R code. There is no easy standardized way to use code listings with captions and to evaluate the code at the same time, but I found a workaround with the following structure of code options in the code chunk:\n#| label: fig-name\n#| fig-cap: \"fig-title\"\n#| attr-source: '#lst-fig-name lst-cap=\"list-title\"'\nThis code generates a warning because at the moment the = symbol is not allowed in RStudio when running a R chunks interactively in a Quarto document. See issue 13326. Although I got a warning the code does what I want: It gives the figure and the code listing a heading and evaluates the code at the same time.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#glossary",
    "href": "index.html#glossary",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "Glossary",
    "text": "Glossary\nI started a glossary using the {glossary} package by Lisa DeBruine (glossary?). A glossary entry is visualized with a double underline. Every chapter has a section where the text of all glossary entries of the chapter are displayed. When you hover with the mouse over the link it opens a pop-up window with the glossary text. You can see example in the section about my motivation for this ebook (See About My Motivation for this Quarto Book).\nI am using this glossary for all my other Quarto books but it is till work in progress. Please keep in mind that I collected the definition at various places and be attentive because there is no guarantee that the entry is appropriate and correct. I have added the sources where I got the content for the glossary entry.\nGlossary\nI am using the {glossary} package to create links to glossary entries. (See (pak-glossary?)). Glossaries for Markdown and Quarto Documents\n\n\n\nExperiment 1 : Load glossary\n\n\n\n\n\n\nListing 1: Install and load the glossary package with the appropriate glossary.yml file\n\n## 1. Install the glossary package:\n## https://debruine.github.io/glossary/\n\nlibrary(glossary)\n\n## If you want to use my glossary.yml file:\n\n## 1. fork my repo\n##    https://github.com/petzi53/glossary-pb\n\n## 2. Download the `glossary.yml` file from\n##    https://github.com/petzi53/glossary-pb/blob/master/glossary.yml)\n\n## 3. Store the file on your hard disk\n##    and change the following path accordingly\n\nglossary::glossary_path(\"/Volumes/T9/bayesian-fun/pb/glossary-pb/glossary-pb/glossary.yml\")\n\n\n\n\n\n\n::: ## Session Info\nEvery chapter ends with a session information printed with the sessionInfo() function.\n\n\n\n\n\n\nWarning\n\n\n\nI wrote this book as a text for others to read because that forces me to be become explicit and explain all my learning outcomes more carefully. Please keep in mind that this text is not written by an expert but by a learner. In spite of replicating most of the content it may contain many mistakes. All these misapprehensions and errors are my responsibility.\nIn any case I am the only responsible person for this text, especially if I have used code from the resources wrongly or misunderstood a quoted text passage.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#session-info",
    "href": "index.html#session-info",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "Session Info",
    "text": "Session Info\nEvery chapter ends with a session information printed with the sessionInfo() function.\n\n\n\n\n\n\nWarning\n\n\n\nI wrote this book as a text for others to read because that forces me to be become explicit and explain all my learning outcomes more carefully. Please keep in mind that this text is not written by an expert but by a learner. In spite of replicating most of the content it may contain many mistakes. All these misapprehensions and errors are my responsibility.\nIn any case I am the only responsible person for this text, especially if I have used code from the resources wrongly or misunderstood a quoted text passage.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#install-the-package-glossary",
    "href": "index.html#install-the-package-glossary",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "1. Install the package glossary",
    "text": "1. Install the package glossary",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#httpsdebruine.github.ioglossary",
    "href": "index.html#httpsdebruine.github.ioglossary",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "https://debruine.github.io/glossary/",
    "text": "https://debruine.github.io/glossary/\nlibrary(glossary)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#if-you-want-to-see-baumgartners-glossary",
    "href": "index.html#if-you-want-to-see-baumgartners-glossary",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "If you want to see Baumgartner’s glossary:",
    "text": "If you want to see Baumgartner’s glossary:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#fork-his-repository",
    "href": "index.html#fork-his-repository",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "1. fork his repository",
    "text": "1. fork his repository",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#httpsgithub.competzi53glossary-pb",
    "href": "index.html#httpsgithub.competzi53glossary-pb",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "https://github.com/petzi53/glossary-pb",
    "text": "https://github.com/petzi53/glossary-pb",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#download-the-glossary-pb-repository-to-your-computer",
    "href": "index.html#download-the-glossary-pb-repository-to-your-computer",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "2. Download the glossary-pb repository to your computer",
    "text": "2. Download the glossary-pb repository to your computer",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#httpsgithub.competzi53glossary-pbblobmasterglossary.yml",
    "href": "index.html#httpsgithub.competzi53glossary-pbblobmasterglossary.yml",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "https://github.com/petzi53/glossary-pb/blob/master/glossary.yml)",
    "text": "https://github.com/petzi53/glossary-pb/blob/master/glossary.yml)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#store-the-file-on-your-hard-disk",
    "href": "index.html#store-the-file-on-your-hard-disk",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "3. Store the file on your hard disk",
    "text": "3. Store the file on your hard disk",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#and-change-the-following-path-to-your-path",
    "href": "index.html#and-change-the-following-path-to-your-path",
    "title": "Bayesian Statistics the Fun Way. Een notitieboek",
    "section": "and change the following path to your path",
    "text": "and change the following path to your path\nglossary::glossary_path(“../glossary.yml”)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "02-measuring-uncertainty.html#calculating-probabilities-by-counting-outcomes-of-events",
    "href": "02-measuring-uncertainty.html#calculating-probabilities-by-counting-outcomes-of-events",
    "title": "\n2  Measuring Uncertainty\n",
    "section": "\n2.2 Calculating Probabilities by Counting Outcomes of Events",
    "text": "2.2 Calculating Probabilities by Counting Outcomes of Events\nThe most common way to calculate probability is to count outcomes of events. We have two sets of outcomes that are important:\n\nAll possible outcomes of an event. For a coin toss, this would be “heads” or “tails.”\nThe count of the outcomes you’re interested in. If you’ve decided that heads means you win, the outcomes you care about are those involving heads.\n\nIn probability theory, we use \\(\\Omega\\) (the capital Greek letter omega) to indicate the set of all events:\n\\[\\Omega = \\{heads, tails\\} \\tag{2.2}\\]\n\nExample 2.1 What is the probability of getting at least one heads when we toss two coins?\n\nCount the list of all possible events:\n\n\\[\\Omega = \\{(heads, heads), (heads, tails), (tails, heads), (tails, tails) \\} \\tag{2.3}\\]\n\nHow many events match our condition?\n\n\\[\\{(heads, heads), (heads, tails), (tails, heads) \\} \\tag{2.4}\\]\n\nDivide number of matches by number of all possible events:\n\n\\[\\frac{3}{4}\\] Solving harder probability problems of this nature often involves a field of mathematics called combinatorics.\n\n\n\nCombinatorics is an area of mathematics primarily concerned with counting. (BS, Chap.2) One of the basic problems of combinatorics is to determine the number of possible configurations of a given type. (Britannica)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measuring Uncertainty</span>"
    ]
  },
  {
    "objectID": "02-measuring-uncertainty.html#calculating-probabilities-as-ratios-of-beliefs",
    "href": "02-measuring-uncertainty.html#calculating-probabilities-as-ratios-of-beliefs",
    "title": "\n2  Measuring Uncertainty\n",
    "section": "\n2.3 Calculating Probabilities as Ratios of Beliefs",
    "text": "2.3 Calculating Probabilities as Ratios of Beliefs\nCounting events is only useful for physical objects. How to reason about more abstract problems? – Making bets is a practical way that we can express how strongly we hold our beliefs.\n\n2.3.1 Using Odds to Determine Probability\nOdds are a common way to represent beliefs as a ratio of how much you would be willing to pay if you were wrong about the outcome of an event to how much you’d want to receive for being correct. For example, say the odds of a horse winning a race are 12 to 1.\n\n\n*Odds Odds is usually defined in statistics as the probability an event will occur divided by the probability that it will not occur. An odds ratio (OR) is a measure of association between a certain property A and a second property B in a population. Specifically, it tells you how the presence or absence of property A has an effect on the presence or absence of property B. (Statistics How To). An odds ratio is a ratio of two ratios. They quantify the strength of the relationship between two conditions. They indicate how likely an outcome is to occur in one context relative to another. (Statistics by Jim)\nOdds have a simple relation with probabilities: the odds of an outcome are the ratio of the probability that the outcome occurs to the probability that the outcome does not occur. In mathematical terms, where p is the probability of the outcome and 1- p is the probability that the outcome does not occur:\n\\[odds = \\frac{p}{1-p} \\tag{2.5}\\]\n\n\nProbability is a mathematical tool used to study randomness. It deals with the chance of an event occurring. (OpenStax: Statistics) In the discrete case, to calculate the probability that a random variable takes on any value within a range, we sum the individual probabilities corresponding to each of the values. We use Pr to explicitly state that the result is a probability from a discrete probability distribution, whereas p(value) is a probability density from a continuous probability distribution. (Bayesian Statistics, Chap.3)\n\n2.3.2 Solving for the Probabilities\nUsing algebra we can convert Equation 2.5 to find the probability of a hypotheses:\n\\[p = \\frac{odds}{1 + odds} \\tag{2.6}\\]\n\n2.3.3 Measuring Beliefs in a Coin Toss\nRather than thinking about a coin toss as an event, we can rephrase the question as “How strongly do I believe the next coin toss will be heads?” Now we’re not talking about \\(P(heads)\\) but rather a hypothesis or belief about the coin toss, \\(P(H_{heads})\\). Just like before, we need an alternate hypothesis to compare our belief with.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measuring Uncertainty</span>"
    ]
  },
  {
    "objectID": "02-measuring-uncertainty.html#wrapping-up",
    "href": "02-measuring-uncertainty.html#wrapping-up",
    "title": "\n2  Measuring Uncertainty\n",
    "section": "\n2.4 Wrapping Up",
    "text": "2.4 Wrapping Up\n\nWe explored two different types of probabilities: those of events and those of beliefs.\nWe defined probability as the ratio of the outcome(s) we care about to the number of all possible outcomes.\n\nWhile this is the most common definition of probability, it is difficult to apply to beliefs because most practical, everyday probability problems do not have clear-cut outcomes and so aren’t intuitively assigned discrete numbers. To calculate the probability of beliefs, then, we need to establish how many times more we believe in one hypothesis over another. One good test of this is how much you would be willing to bet on your belief",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measuring Uncertainty</span>"
    ]
  },
  {
    "objectID": "02-measuring-uncertainty.html#exercises",
    "href": "02-measuring-uncertainty.html#exercises",
    "title": "\n2  Measuring Uncertainty\n",
    "section": "\n2.5 Exercises",
    "text": "2.5 Exercises\nTry answering the following questions to make sure you understand how we can assign real values between 0 and 1 to our beliefs.\n\nExample 2.2 What is the probability of rolling two six-sided dice and getting a value greater than 7?\nFollowing Example 2.1:\n\n\nEquation 2.3: \\(36\\)\n\n\n\\[\n\\begin{align*}\n\\Omega = \\{(1,1), (1,2), (1,3), (1,4), (1,5), (1,6) \\\\\n(2,1), (2,2), (2,3), (2,4), (2,5), (2,6) \\\\\n(3,1), (3,2), (3,3), (3,4), (3,5), (3,6) \\\\\n(4,1), (4,2), (4,3), (4,4), (4,5), (4,6) \\\\\n(5,1), (5,2), (5,3), (5,4), (5,5), (5,6) \\\\\n(6,1), (6,2), (6,3), (6,4), (6,5), (6,6) \\}\n\\end{align*}\n\\] 2. Equation 2.4: \\(15\\)\nSolution:\n\\[\\frac{15}{36} = \\frac{5}{12}\\]\n\n\n\nExample 2.3 What is the probability of rolling three six-sided dice and getting a value greater than 7?\nSolution:\n\npossible_events = dice_sum = success = 0\nfor (i in 1:6) {\n    for (j in 1:6) {\n        for (k in 1:6) {\n            possible_events &lt;- possible_events + 1\n            dice_sum &lt;- i + j + k\n            if (dice_sum &gt; 7) {\n                success &lt;- success + 1\n            }\n        }\n    }\n}\n\nglue::glue('Possible events = {possible_events}, \\n',\n            'Dice value &gt; 7 = {success}, \\n',\n           'Probability = {success} / {possible_events} = {success / possible_events}')\n\nPossible events = 216, \nDice value &gt; 7 = 181, \nProbability = 181 / 216 = 0.837962962962963\n\n\n\n\nThe Yankees are playing the Red Sox. You’re a diehard Sox fan and bet your friend they’ll win the game. You’ll pay your friend $30 if the Sox lose and your friend will have to pay you only $5 if the Sox win. What is the probability you have intuitively assigned to the belief that the Red Sox will win?\nSolution:\n\\[odds = \\frac{30}{5} = 6\\] Probability is calculated with Equation 2.6:\n\\[p = \\frac{odds}{1 + odds} = \\]\n\n\\(p = \\frac{6}{1 + 6} = \\frac{6}{7}\\) = 0.86",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Measuring Uncertainty</span>"
    ]
  },
  {
    "objectID": "06-conditional-probability.html",
    "href": "06-conditional-probability.html",
    "title": "\n6  Conditional Probability\n",
    "section": "",
    "text": "6.1 Introducing Conditional Probability\nIn our first example of conditional probabilities, we’ll look at flu vaccines and possible complications of receiving them. When you get a flu vaccine, you’re typically handed a sheet of paper that informs you of the various risks associated with it. One example is an increased incidence of Guillain-Barré syndrome (GBS), a very rare condition that causes the body’s immune system to attack the nervous system, leading to potentially life-threatening complications. According to the Centers for Disease Control and Prevention (CDC), the probability of contracting GBS in a given year is 2 in 100,000.\n\\[P(GBS) = \\frac{2}{100,000}\\]\nNormally the flu vaccine increases your probability of getting GBS only by a trivial amount. In 2010, however, there was an outbreak of swine flu, and the probability of getting GBS if you received the flu vaccine that year rose to 3/100,000. In this case, the probability of contracting GBS directly depended on whether or not you got the flu vaccine, and thus it is an example of a conditional probability.\nWe express conditional probabilities as \\(P(A \\mid B)\\), or the probability of A given B. Mathematically, we can express the chance of getting GBS as:\n\\[P(GBS \\mid \\text{flu vaccine}) = \\frac{3}{100,000}\\] We read this expression in English as “The probability of having GBS, given that you got the flu vaccine, is 3 in 100,000.”",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability</span>"
    ]
  },
  {
    "objectID": "06-conditional-probability.html#introducing-conditional-probability",
    "href": "06-conditional-probability.html#introducing-conditional-probability",
    "title": "\n6  Conditional Probability\n",
    "section": "",
    "text": "6.1.1 Why Conditional Probabilities Are Important\nConditional probabilities are an essential part of statistics because they allow us to demonstrate how information changes our beliefs.\n\\[\\frac{P(GBS \\mid \\text{flu vaccine})}{P(GBS)} = 1.5\\] So if you had the flu shot in 2010, we have enough information to believe you’re 50 percent more likely to get GBS than a stranger picked at random. Fortunately, on an individual level, the probability of getting GBS is still very low. But if we’re looking at populations as a whole, we would expect 50 percent more people to have GBS in a population of people that had the flu vaccine than in the general population.\nThere are also other factors that can increase the probability of getting GBS. For example, males and older adults are more likely to have GBS. Using conditional probabilities, we can add all of this information to better estimate the likelihood that an individual gets GBS.\n\n6.1.2 Dependence and the Revised Rules of Probability\nAs a second example of conditional probabilities, we’ll use color blindness, a vision deficiency that makes it difficult for people to discern certain colors. In the general population, about 4.25 percent of people are color blind. The vast majority of cases of color blindness are genetic. Color blindness is caused by a defective gene in the X chromosome. Because males have only a single X chromosome and females have two, men are about 16 times more likely to suffer adverse effects of a defective X chromosome and therefore to be color blind. So while the rate of color blindness for the entire population is 4.25 percent, it is only 0.5 percent in females but 8 percent in males. For all of our calculations, we’ll be making the simplifying assumption that the male/female split of the population is exactly 50/50. Let’s represent these facts as conditional probabilities:\n\\[\n\\begin{align*}\nP(\\text{color blind}) = 0.0425 \\\\\nP(\\text{color blind} \\mid female) = 0.005 \\\\\nP(\\text{color blind} \\mid male) = 0.08\n\\end{align*}\n\\] Given this information, if we pick a random person from the population, what’s the probability that they are male and color blind?\nYou can’t use the product rule of Equation 3.1 because it works only with independent probabilities. But being male (or female) and color blind are dependent probabilities. So the true probability of finding a male who is color blind is the probability of picking a male multiplied by the probability that he is color blind.\n\\[P(male, \\text{color blind}) = P(male) \\times P(\\text{color blind} \\mid male) = 0.5 \\times 0.08 = 0.04\\] We can generalize this solution to rewrite our product rule as follows:\n\\[P(A,B) = P(A) \\times P(B \\mid A) \\tag{6.1}\\]\nThis definition works for independent probabilities as well, because for independent probabilities \\(P(B) = P(B \\mid A)\\). This makes intuitive sense when you think about flipping heads and rolling a 6; because \\(P(six)\\) is 1/6 independent of the coin toss, \\(P(six | heads)\\) is also 1/6.\nWe can also update our definition of the sum rule (Equation 3.2) to account for this fact:\n\\[P(A \\operatorname{OR} B) = P(A) + P(B) – P(A) × P(B \\mid A) \\tag{6.2}\\]\nNow we can still easily use our rules of probabilistic logic from Chapter 3 and handle conditional probabilities.\n\n\n\n\n\n\nProduct & Sum Rules revised\n\n\n\nTo understand better the differences I will contrast the independent rules with their conditional version:\n\nProduct Rule of Probability\n\n\\[\n\\begin{align*}\nP(A,B) = P(A) \\times P(B) \\\\\nP(A,B) = P(A) \\times P(B \\mid A)\n\\end{align*}\n\\]\n\n\nSum Rule of Probability\n\n\\[\n\\begin{align*}\nP(A) \\operatorname{OR} P(B) = P(A) + P(B) – P(A,B) \\\\\nP(A \\operatorname{or} B) = P(A) + P(B) – P(A) × P(B \\mid A)\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn practice, knowing how two events are related is often difficult. Assuming that two events are independent (even when they likely aren’t) is therefore a very common practice in statistics.\nWhile assuming independence is often a practical necessity, never forget how much of an impact dependence can have.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability</span>"
    ]
  },
  {
    "objectID": "06-conditional-probability.html#conditional-probabilities-in-reverse-and-bayes-theorem",
    "href": "06-conditional-probability.html#conditional-probabilities-in-reverse-and-bayes-theorem",
    "title": "\n6  Conditional Probability\n",
    "section": "\n6.2 Conditional Probabilities in Reverse and Bayes’ Theorem",
    "text": "6.2 Conditional Probabilities in Reverse and Bayes’ Theorem\nOne of the most amazing things we can do with conditional probabilities is reversing the condition to calculate the probability of the event we’re conditioning on; that is, we can use \\(P(A\\mid B)\\) to arrive at \\(P(B \\mid A)\\).\nAs an example, say you’re emailing a customer service rep at a company that sells color blindness–correcting glasses. The glasses are a little pricey, and you mention to the rep that you’re worried they might not work. The rep replies, “I’m also color blind, and I have a pair myself—they work really well!”\nWe want to figure out the probability that this rep is male. However, the rep provides no information except an ID number. So how can we figure out the probability that the rep is male?\nWe know that \\(P(\\text{color blind} \\mid male) = 0.08\\) and that \\(P(\\text{color blind} \\mid female) = 0.005\\), but how can we determine \\(P(male \\mid \\text{color blind})\\)?\nThe heart of Bayesian statistics is data, and right now we have only one piece of data (other than our existing probabilities): we know that the customer support rep is color blind. Our next step is to look at the portion of the total population that is color blind; then, we can figure out what portion of that subset is male.\nTo help reason about this, let’s add a new variable \\(N\\), which represents the total population of people. As stated before, we first need to calculate the total subset of the population that is color blind. We know \\(P(\\text{color blind})\\), so we can write this part of the equation like so:\n\\[\nP(male \\mid \\text{color blind}) = \\frac{?}{P(\\text{color blind}) \\times N}\n\\] Next we need to calculate the number of people who are male and color blind. This is easy to do since we know \\(P(male)\\) and \\(P(\\text{color blind} | male)\\), and we have our revised product rule Equation 6.1. So we can simply multiply this probability by the population:\n\\[P(male) \\times P(\\text{color blind} | male) × N\\]\nSo the probability that the customer service rep is male, given that they’re color blind, is:\n\\[\nP(male \\mid \\text{color blind}) = \\frac{P(male) \\times P(\\text{color blind} \\mid male) \\times N} {P(\\text{color blind}) \\times N}\n\\]\nOur population variable \\(N\\) is on both the top and the bottom of the fraction, so the \\(N\\)s cancel out:\n\\[\nP(male \\mid \\text{color blind}) = \\frac{P(male) \\times P(\\text{color blind} \\mid male)} {P(\\text{color blind})}\n\\]\nWe can now solve our problem since we know each piece of information:\n\\[\nP(male \\mid \\text{color blind}) = \\frac{P(male) \\times P(\\text{color blind} \\mid male)} {P(\\text{color blind})} = \\frac{0.5 \\times 0.08}{0.0425} = 0.941\n\\] Given the calculation, we know there is a 94.1 percent chance that the customer service rep is in fact male!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability</span>"
    ]
  },
  {
    "objectID": "06-conditional-probability.html#introducing-bayes-theorem",
    "href": "06-conditional-probability.html#introducing-bayes-theorem",
    "title": "\n6  Conditional Probability\n",
    "section": "\n6.3 Introducing Bayes’ Theorem",
    "text": "6.3 Introducing Bayes’ Theorem\nThere is nothing actually specific to our case of color blindness in the preceding formula, so we should be able to generalize it to any given A and B probabilities. If we do this, we get the most foundational formula in this book, Bayes’ theorem (GLOSSARY):\n\nTheorem 6.1 (Bayes’ Theorem (Variation 1)) \\[\n\\begin{align*}\nP(A \\mid B) = \\frac{P(B) \\times P(B) \\mid A)}{P(B)} = (\\text{Bayes Theorem}) \\\\\n(\\text{And now the application with the Color Blind Example}) \\\\\nP(male \\mid \\text{color blind}) = \\frac{P(male) \\times P(\\text{color blind} \\mid male)} {P(\\text{color blind})}\n\\end{align*}\n\\tag{6.3}\\]\n\nOur beliefs describe the world we know, so when we observe something, its conditional probability represents the likelihood of what we’ve seen given what we believe, or:\n\\[P(data \\mid belief)\\] “What is the probability of what I’ve observed (the data), given that I believe climate change is true?” But what you want is some way to quantify how strongly you believe climate change is really happening, given what (data) you have observed.\n\\[P(belief \\mid data)\\]\nIn this example, Bayes’ theorem allows you to transform your observation of five droughts in a decade into a statement about how strongly you believe in climate change after you have observed these droughts. The only other pieces of information you need are the general probability of 5 droughts in 10 years (which could be estimated with historical data) and your initial certainty of your belief in climate change. And while most people would have a different initial probability for climate change, Bayes’ theorem allows you to quantify exactly how much the data changes any belief.\nFor example, if the expert says that 5 droughts in 10 years is very likely if we assume that climate change is happening, most people will change their previous beliefs to favor climate change a little, whether they’re skeptical of climate change or they’re Al Gore.\nHowever, suppose that the expert told you that in fact, 5 droughts in 10 years was very unlikely given your assumption that climate change is happening. In that case, your prior belief in climate change would weaken slightly given the evidence. The key takeaway here is that Bayes’ theorem ultimately allows evidence to change the strength of our beliefs.\nBayes’ theorem allows us to take our beliefs about the world, combine them with data, and then transform this combination into an estimate of the strength of our beliefs given the evidence we’ve observed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability</span>"
    ]
  },
  {
    "objectID": "06-conditional-probability.html#wrapping-up",
    "href": "06-conditional-probability.html#wrapping-up",
    "title": "\n6  Conditional Probability\n",
    "section": "\n6.4 Wrapping Up",
    "text": "6.4 Wrapping Up\nIn this chapter, you learned about conditional probabilities and about Bayes’ theorem which is fundamental to understanding how we can use data to update what we believe about the world.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability</span>"
    ]
  },
  {
    "objectID": "06-conditional-probability.html#exercises",
    "href": "06-conditional-probability.html#exercises",
    "title": "\n6  Conditional Probability\n",
    "section": "\n6.5 Exercises",
    "text": "6.5 Exercises\nTry answering the following questions to see how well you understand conditional probability and Bayes’ theorem. The solutions can be found at https://nostarch.com/learnbayes/.\n\n6.5.1 Exercise 6-1\nWhat piece of information would we need in order to use Bayes’ theorem to determine the probability that someone in 2010 who had GBS also had the flu vaccine that year?\nThis is the question for \\(P(\\text{flu vaccine} \\mid GBS)\\). Let’s set up Bayes’ theorem and compare which information we have for this example in the book text and which information is missing:\n\\[\nP(\\text{flu vaccine} \\mid GBS) = \\frac{P(\\text{flu vaccine}) \\times P(GBS \\mid \\text{flu vaccine})}{P(GBS)}\n\\] - We know that \\(P(GBS) = \\frac{2}{100,000}\\) - We know that \\(P(GBS \\mid \\text{flu vaccine}) = \\frac{3}{100,000}\\)\nThe only factor in the formula we do not know is \\(P(\\text{flu vaccine})\\).\n\n6.5.2 Exercise 6-2\nWhat is the probability that a random person picked from the population is female and is not color blind?\n\\[\n\\begin{align*}\nP(female \\mid \\text{not color blind}) = P(female) \\times P(\\text{not color blind} \\mid P(female)) \\\\\n= 0.5 \\times 0.995 = 0.4975\n\\end{align*}\n\\]\n\n\n\n\n\n\nWarning\n\n\n\nMy calculation was wrong as I used Bayes’ rule instead just the product rule:\n\\[\n\\begin{align*}\nP(female \\mid \\text{not color blind}) = \\frac{P(female) \\times P(\\text{not color blind} \\mid P(female))}{P({\\text{not color blind})}} \\\\\n= \\frac{0.5 \\times 0.995}{0.9575} \\\\\n= 0.5195822\n\\end{align*}\n\\]\nThinking about the result I should have known that it couldn’t be correct: There are 50% women in the population. From these 50% is a tiny percentage color blind. Therefore the result of women that are not color blind should be a proportion slightly under 50%.\n\n\n\n6.5.3 Exercise 6-3\nWhat is the probability that a male who received the flu vaccine in 2010 is either color blind or has GBS?\nHere I should use the revised sum rule from Equation 6.2. But I am still working on this problem. Up to now (2023-09-13) I haven’t found a solution.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conditional Probability</span>"
    ]
  },
  {
    "objectID": "07-bayes-lego.html",
    "href": "07-bayes-lego.html",
    "title": "\n7  Bayes’ Theorem With LEGO\n",
    "section": "",
    "text": "7.1 Exercises\nTry answering the following questions to see if you have a solid understanding of how we can use Bayes’ Theorem to reason about conditional probabilities. The solutions can be found at https://nostarch.com/learnbayes/.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bayes’ Theorem With LEGO</span>"
    ]
  },
  {
    "objectID": "07-bayes-lego.html#exercises",
    "href": "07-bayes-lego.html#exercises",
    "title": "\n7  Bayes’ Theorem With LEGO\n",
    "section": "",
    "text": "7.1.1 Exercise 7-1\nKansas City, despite its name, sits on the border of two US states: Missouri and Kansas. The Kansas City metropolitan area consists of 15 counties, 9 in Missouri and 6 in Kansas. The entire state of Kansas has 105 counties and Missouri has 114. Use Bayes’ theorem to calculate the probability that a relative who just moved to a county in the Kansas City metropolitan area also lives in a county in Kansas. Make sure to show \\(P(Kansas)\\) (assuming your relative either lives in Kansas or Missouri), \\(P(\\text{Kansas City metropolitan area})\\), and \\(P(\\text{Kansas City metropolitan area}| Kansas)\\).\nUS states: 219 counties = 105 Kansas, 114 Missouri Kansas City: 15 counties = 6 Kansas, 9 Missouri\nIntuitively: \\(\\frac{6}{15} = \\frac{2}{5}\\)\n$$ \\[\\begin{align*}\nP(\\text{County in Kansas} | \\text{Kansas City}) = \\frac{P(\\text{Kansas City} | \\text{County in Kansas}) \\times P(\\text{County in Kansas})}{P(\\text{Kansas City})} \\\\\n= \\frac{\\frac{6}{105} \\times \\frac{105}{219}}{\\frac{15}{219}}\n= \\frac{\\frac{6}{219}}{\\frac{15}{219}}\n= \\frac{6}{15}\n= \\frac{2}{5}\n\n\\end{align*}\\] $$\n\n7.1.2 Exercise 7-2\nA deck of cards has 52 cards with suits that are either red or black. There are four aces in a deck of cards: two red and two black. You remove a red ace from the deck and shuffle the cards. Your friend pulls a black card. What is the probability that it is an ace?\nCards: 51 cards = 26 black, 25 red Aces: 3 aces = 2 black, 1 red \\(P(ace | \\text{black card})\\)?\n$$ \\[\\begin{align*}\nP(ace | \\text{black card}) = \\frac{P(\\text{black card} | ace) \\times P(ace))}{P(\\text{black card})} \\\\\n= \\frac{\\frac{2}{3} \\times \\frac{3}{51}}{\\frac{26}{51}}\n= \\frac{\\frac{6}{153}} {\\frac{26}{51}}\n= \\frac{6 \\times 51} {26 \\times 153}\n= \\frac{6}{26} \\times \\frac{1}{3}\n= \\frac{2}{26}\n= \\frac{1}{13}\n\n\\end{align*}\\] $$ Or more easily without Bayes’ rule: We have 26 black cards with 2 aces = \\(P(\\frac{2}{26}) = \\frac{1}{13}\\)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bayes’ Theorem With LEGO</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html",
    "href": "08-prior-likelihood-posterior.html",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "",
    "text": "8.1 The Three Parts\nBayes’ theorem (GLOSSARY) has three parts:\nThe fourth part of Bayes’ theorem, probability of the data, \\(P(data)\\) is used to normalize the posterior so it accurately reflects a probability from 0 to 1. In practice, we don’t always need P(data), so this value doesn’t have a special name.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html#the-three-parts",
    "href": "08-prior-likelihood-posterior.html#the-three-parts",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "",
    "text": "Prior Probability (GLOSSARY), \\(P(belief)\\)\n\nLikelihood (GLOSSARY), \\(P(data | belief)\\) and the\nPosterior Probability (GLOSSARY), \\(P(belief | data)\\).\n\n\n\n\nFigure 8.1: The different parts of Bayes’ theorem",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html#investigating-the-scene-of-a-crime",
    "href": "08-prior-likelihood-posterior.html#investigating-the-scene-of-a-crime",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "\n8.2 Investigating the Scene of a Crime",
    "text": "8.2 Investigating the Scene of a Crime\nKurt explains again Bayes’ theorem with an example: This time the probability of being robbed after finding that the is window broken, the front door is open, and a laptop is missing. One of the differences in the explanation with this example is the explicit use of the different parts of Bayes’ rule and the missing of data. He shows how to bypass missing data by comparing alternative hypotheses.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html#empty-considering-alternative-hypotheses",
    "href": "08-prior-likelihood-posterior.html#empty-considering-alternative-hypotheses",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "\n8.3 empty: Considering Alternative Hypotheses",
    "text": "8.3 empty: Considering Alternative Hypotheses",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html#comparing-our-unnormalized-posteriors",
    "href": "08-prior-likelihood-posterior.html#comparing-our-unnormalized-posteriors",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "\n8.4 Comparing Our Unnormalized Posteriors",
    "text": "8.4 Comparing Our Unnormalized Posteriors\nIf you compare alternative hypotheses than both the numerator and denominator contain P(data), so that you can remove it and still maintain the ratio.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html#empty-wrapping-up",
    "href": "08-prior-likelihood-posterior.html#empty-wrapping-up",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "\n8.5 empty: Wrapping Up",
    "text": "8.5 empty: Wrapping Up",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "08-prior-likelihood-posterior.html#exercises",
    "href": "08-prior-likelihood-posterior.html#exercises",
    "title": "\n8  The Prior, Likelihood, and Posterior of Bayes’ Theorem\n",
    "section": "\n8.6 Exercises",
    "text": "8.6 Exercises\nTry answering the following questions to see if you have a solid understanding of the different parts of Bayes’ Theorem. The solutions can be found at https://nostarch.com/learnbayes/.\n\n8.6.1 Exercise 8-1\nAs mentioned, you might disagree with the original probability \\(P(robbed) = \\frac{1}{1000}\\) assigned to the likelihood:\n\\(P(\\text{broken window, open front door, missing laptop | robbed}) = \\frac{3}{10}\\)\nHow much does this change our strength in believing \\(H_{1}\\) over \\(H_{2}\\)? (In the example in the text \\(H_{1}\\) explained what has observed 6,570 times better than \\(H_{2}\\). In the example the posterior probability of \\(H_{2}\\) was calculated with \\(\\frac{1}{21,900,000}\\)\n$$ \\[\\begin{align*}\n\\frac{\\frac{1}{1,000} \\times \\frac{3}{10}}{\\frac{1}{21,900.000}} = \\frac{\\frac{3}{10,000}}{\\frac{1}{21,900,000}} = \\frac{65,700,000}{10,000} = 657\n\n\\end{align*}\\] $$ The result still favors \\(H_{1}\\), but the difference is much smaller now.\n\n8.6.2 Exercise 8-2\nHow unlikely would you have to believe being robbed is—our prior for \\(H_{1}\\)—in order for the ratio of \\(H_{1}\\) to \\(H_{2}\\) to be even?\n$$ \\[\\begin{align*}\n\\frac{\\frac{1}{1,000} \\times \\frac{1}{21,900}}{\\frac{1}{21,900.000}} = \\frac{\\frac{1}{21,900,000}}{\\frac{1}{21,900,000}} = 1\n\n\\end{align*}\\] $$ ::: {.callout-warning} I misunderstood the question of the exercise: I did not take into account the updated belief from Section 8.6.1. But the solution has the same principle: It would need an extremely unlikely belief, so that both hypotheses would be equally possible.\nBy the way: The high unlikeliness of \\(H_{2}\\) is a result in estimating each aspect of the data (broken window, open front door, and missing laptop) separately. Using the #eq-product-rule by multiplying the probability of all three events has resulted in an extremely low prior probability. I am therefore not sure if it is a good idea to estimate each factor individually. :::",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>The Prior, Likelihood, and Posterior of Bayes’ Theorem</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html",
    "href": "09-probability-distributions.html",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "",
    "text": "9.1 C-3PO’s Asteroid Field Doubts",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#c-3pos-asteroid-field-doubts",
    "href": "09-probability-distributions.html#c-3pos-asteroid-field-doubts",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "",
    "text": "As an example, we’ll use one of the most memorable errors in statistical analysis from a scene in Star Wars: The Empire Strikes Back. When Han Solo, attempting to evade enemy fighters, flies the Millennium Falcon into an asteroid field, the ever-knowledgeable C-3PO informs Han that probability isn’t on his side. C-3PO says, “Sir, the possibility of successfully navigating an asteroid field is approximately 3,720 to 1!” (78)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#determining-c-3pos-beliefs",
    "href": "09-probability-distributions.html#determining-c-3pos-beliefs",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "\n9.2 Determining C-3PO’s Beliefs",
    "text": "9.2 Determining C-3PO’s Beliefs\n\n\nTheorem 9.1 (Parameterization of the Beta Distribution)  \n\nRecall that the beta distribution is parameterized with an \\(\\alpha\\) (number of observed successes) and a \\(\\beta\\) (the number of observed failures) (79):\n\n\\[\nP(\\text{Rate Of Success} | \\text{Successes and Failures}) = Beta(\\alpha,\\beta)\n\\tag{9.1}\\]\n\n\n\nLet’s say that C-3PO has records of 2 people surviving the asteroid field, and 7,440 people ending their trip in a glorious explosion! (79)\n\n\n\nFigure 9.1: A beta distribution representing C-3PO’s belief that Han will survive",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#accounting-for-hans-badassery",
    "href": "09-probability-distributions.html#accounting-for-hans-badassery",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "\n9.3 Accounting for Han’s Badassery",
    "text": "9.3 Accounting for Han’s Badassery\n\nWe have a prior belief that Han will make it through the asteroid field, because Han has survived every improbable situation so far. (80)\n\n\nWe’ll start with some sort of upper bound on Han’s badassery. If we believed Han absolutely could not die, the movie would become predictable and boring. At the other end, our belief that Han will succeed is stronger than C-3PO’s belief that he won’t, so let’s say that our belief that Han will survive is 20,000 to 1. (81)\n\n\n\nFigure 9.2: The beta distribution representing the range of our prior belief in Han Solo’s survival",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#creating-suspense-with-a-posterior",
    "href": "09-probability-distributions.html#creating-suspense-with-a-posterior",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "\n9.4 Creating Suspense with a Posterior",
    "text": "9.4 Creating Suspense with a Posterior\nBy combining the different beliefs, C-3PO’s belief about the small changes of success (likelihood, (GLOSSARY)) and our belief about the skills of Han Solo (prior probability, prior) GLOSSAY), we create the posterior probability (GLOSSARY).\n\n\nTheorem 9.2 (Proportional Form of Bayes’ theorem) \\[Posterior \\propto Likelihood \\times Prior  \\tag{9.2}\\] The sign \\(\\propto\\) is the proportional operator (GLOSSARY) and stands for “is proportional to”.\n\n\n\nRemember, using this proportional form of Bayes’ theorem means that our posterior distribution doesn’t necessarily sum to 1. But we’re lucky because there’s an easy way to combine beta distributions that will give us a normalized posterior when all we have is the likelihood and the prior. (82)\n\n\n\nTheorem 9.3 (Normalized Posterior with just Likelihood and Beta) \\[\nBeta(\\alpha_{posterior},\\beta_{posterior}) = Beta(\\alpha_{likelihood} + \\alpha_{prior}, \\beta_{likelihood} + \\beta_{prior})\n\\tag{9.3}\\]\n\n\nWith our example:\n\\[\n\\begin{align*}\nBeta(?,?) = Beta(2 + 20000, 7440 + 1) \\\\\nBeta(20002,7441) = Beta(2 + 20000, 7440 + 1)\n\\end{align*}\n\\]\n\n\nFigure 9.3: Combining likelihood with prior gives the more intriguing posterior\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis is a wrong figure on p.88 as the prior belief should be Beta(2 + 20000, 7440 + 1) instead of Beta(2 + 20000, 7440 + 1). See also page 2 the Errata file. But I did not change it here and in my Figure 9.6 as it is not so important for the general argumentation.\n\n\nThe combined belief of C-3PO for the very low chances to live through the asteroid field and our prior belief of the exceptional skills of Han Solo accounts to a pretty good 73% chance of survival.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#wrapping-up",
    "href": "09-probability-distributions.html#wrapping-up",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "\n9.5 Wrapping Up",
    "text": "9.5 Wrapping Up\nThe chapter provides two learnings:\n\nThe prior provides important background information that is essential to get realistic expectations for the probability distribution of the posterior.\nInstead of using a single probability (some central measure, like mean, median etc.) you can express express a range of possible beliefs. The best way is to use the whole probability distributions, rather than a summary like a single probability or range of the distribution.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#exercises",
    "href": "09-probability-distributions.html#exercises",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "\n9.6 Exercises",
    "text": "9.6 Exercises\nTry answering the following questions to see if you understand how to combine prior probability and likelihood distributions to come up with an accurate posterior distribution; solutions to the questions can be found at https://nostarch.com/learnbayes/.\n\n9.6.1 Exercise 9-1\nA friend finds a coin on the ground, flips it, and gets six heads in a row and then one tails. Give the beta distribution that describes this. Use integration to determine the probability that the true rate of flipping heads is between 0.4 and 0.6, reflecting that the coin is reasonably fair.\n\n\n\nListing 9.1: Probability that the true rate of flipping heads is between 0.4 and 0.6\n\nintegrate(function(p) dbeta(p, 6, 1), 0.4, 0.6)\n\n\n\n\n0.04256 with absolute error &lt; 4.7e-16\n\n\nThere is only a 4% probability that the coin is fair, at least based only on the likelihood probability.\n\n9.6.2 Exercise 9-2\nCome up with a prior probability that the coin is fair. Use a beta distribution such that there is at least a 95 percent chance that the true rate of flipping heads is between 0.4 and 0.6.\n\n\n\n\n\n\nNote\n\n\n\nI could note solve this problem, because I did not come up with the idea that ‘any \\(\\alpha\\) prior = \\(\\beta\\) prior will give us a “fair” prior; and the larger those values are, the stronger that prior is.’ (240)\nSo the solution is:\nintegrate(function(p) dbeta(p, 6 + added_prior, 1 + added_prior), 0.4, 0.6).\nTo get at least 95% change that the coin is fair we need to determine the value of the added prior. Instead of trial and error manually I will do it with a little R program.\n\n\n\n\n\nListing 9.2: Change the prior so that the beta distribution will show at least a 95 percent chance that the true rate of flipping heads is between 0.4 and 0.6.\n\nadded_prior = NULL\n\nfor (i in 1:100) {\n    j &lt;- integrate(function(p) dbeta(p, 6 + i, 1 + i), 0.4, 0.6)\n    if (j$value &gt;= .95) {\n       print(glue::glue('{i}: {j$value}'))\n       added_prior = i\n       break\n    }\n}\n\n\n\n\n54: 0.950427480766883\n\n\nThe nearest value of the prior to get at least a 95 percent chance that the true rate of flipping heads is between 0.4 and 0.6 is 54. This is slightly lower than the trial & error solution in the Appendix C of the book.\n\n9.6.3 Exercise 9-3\nNow see how many more heads (with no more tails) it would take to convince you that there is a reasonable chance that the coin is not fair. In this case, let’s say that this means that our belief in the rate of the coin being between 0.4 and 0.6 drops below 0.5.\nWith our added prior value we have a beta distribution of Beta(6 + 54, 1 + 54).\n\n\n\nListing 9.3: How mandy more heads in a row are necessary that our belief of a fair coin drop under 50%?\n\nfor (i in 1:100) {\n    j &lt;- integrate(function(p) dbeta(p, 6 + added_prior + i, 1 + added_prior), 0.4, 0.6)\n    if (j$value &lt;= .50) {\n       print(glue::glue('{i}: {j$value}'))\n       break\n    }\n}\n\n\n\n\n23: 0.481467889312114\n\n\nTo drop our expectation under 50% we need 23 more heads in row.\n\nThis shows that even a strong prior belief can be overcome with more data. (241)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "09-probability-distributions.html#experiments",
    "href": "09-probability-distributions.html#experiments",
    "title": "9  Bayesian Priors and Working with Probability Distributions",
    "section": "\n9.7 Experiments",
    "text": "9.7 Experiments\n\n9.7.1 Replicating Figure 9-1\n\nLet’s say that C-3PO has records of 2 people surviving the asteroid field, and 7,440 people ending their trip in a glorious explosion! (79)\n\n\n\n\nListing 9.4: Replication of Figure 9.1: Distribution of C-3PO’s Likelihood of Surviving\n\ntibble::tibble(x = seq(from = 0, to = 0.003, by = 0.00001),\n                    y = dbeta(x, 2, 7440)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution of  C-3PO’s Likelihood of Surviving\",\n        x = \"Probability\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 9.4: A beta distribution representing C-3PO’s belief that Han will survive\n\n\n\n\n\n\n\n\n9.7.2 Replicating Figure 9-2\nOur belief that Han will succeed is 20,000 to 1.\n\n\n\nListing 9.5: Replication of Figure 9.2: Distribution of our prior belief of Han Solo surviving\n\ntibble::tibble(x = seq(from = 0.99900, to = 1, by = 0.00001),\n                    y = dbeta(x, 20000, 1)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution of our prior belief of Han Solo surviving\",\n        x = \"Probability of success\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 9.5: The beta distribution representing the range of our prior belief in Han Solo’s survival\n\n\n\n\n\n\n\n\n9.7.3 Replicating Figure 9-3\nCombining the distributions of prior (\\(Beta(2, 20000)\\)) and likelihood (\\(Beta(7400, 1)\\)) generates the posterior distribution of \\(Beta(20002, 7401)\\).\n\n\n\nListing 9.6: Replication of Figure 9.3: Distribution of prior belief Beta(2 + 20000, 7400 + 1)\n\ntibble::tibble(x = seq(from = 0.6, to = 0.8, by = 0.001),\n                    y = dbeta(x, 20002, 7401)) |&gt; \n\nggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Distribution of prior belief Beta(2 + 20000, 7400 + 1)\",\n        x = \"Probability of success\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 9.6: Combining likelihood with the prior gives thea more intriguing posterior.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bayesian Priors and Working with Probability Distributions</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html",
    "href": "11-data-spread.html",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "",
    "text": "11.1 Dropping Coins in a Well\nHaving different spreads in two data set does not prevent that they have the same mean (\\(\\mu\\)).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html#finding-the-mean-absolute-deviation",
    "href": "11-data-spread.html#finding-the-mean-absolute-deviation",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "\n11.2 Finding the Mean Absolute Deviation",
    "text": "11.2 Finding the Mean Absolute Deviation\nTo measure the dispersion of data you can’t simply sum the distances from the mean because the positive and negative differences cancel each other out. To take absolute values wouldn’t work either because we got higher values with more data. We need to normalize by dividing by the total number of observations.\nThe mean absolute deviation uses this procedure but instead to divide by the number of observation it divides by its reciprocal value \\(\\frac{1}{n}\\).\n\n\nTheorem 11.1 (Formula for the Mean Absolute Deviation (MAD)) \\[MAD(x) = \\frac{1}{n} \\times \\sum_{1}^{n}|x_{i} - \\mu| \\tag{11.1}\\]\n\nWe call the result of this formula the mean absolute deviation (MAD). The MAD is a very useful and intuitive measure of how spread out your observations are. (98)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html#finding-the-variance",
    "href": "11-data-spread.html#finding-the-variance",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "\n11.3 Finding the Variance",
    "text": "11.3 Finding the Variance\nTo square the differences to the mean (\\(x_{i} - \\mu\\)) is another way to get only positive values. This measure of dispersion is called Variance var, variance and has the advantage to produce an “exponential penalty, meaning measurements very far away from the mean are penalized much more.” (99)\n\n\nTheorem 11.2 (Formula for the Variance (Var)) \\[Var(x) = \\frac{1}{n} \\times \\sum_{1}^{n}(x_{i} - \\mu)^2 \\tag{11.2}\\]\nThe formula for the variance is exactly the same as MAD in Equation 11.1 except that the absolute value function in MAD has been replaced with squaring.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html#finding-the-standard-deviation",
    "href": "11-data-spread.html#finding-the-standard-deviation",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "\n11.4 Finding the Standard Deviation",
    "text": "11.4 Finding the Standard Deviation\nWith the squared results in computing the variance we are loosing the intuitive meaning of the values. Therefore by taking the square root the standard deviation as another measure of dispersion that is easier to interpret than the variance.\n\n\nTheorem 11.3 (Formula for the Standard Deviation (sigma, \\(\\sigma\\))) \\[\\sigma = \\sqrt{\\frac{1}{n} \\times \\sum_{1}^{n}(x_{i} - \\mu)^2} \\tag{11.3}\\]\n\nThe standard deviation is so useful and ubiquitous that, in most of the literature on probability and statistics, variance is defined simply as \\(\\sigma^2\\), or sigma squared!\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThere is another difference between the simple variance and standard deviation. In the base R case both use as denominator \\(n - 1\\) and not just \\(n\\). The reason is – as Will Kurt explains in the solution manual page 242 – that both measure addresses the sample (variance and standard deviation) and not the population.\nThe difference is not important if you have a large data set, but with the toy data in this chapter the difference matters.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html#wrapping-up",
    "href": "11-data-spread.html#wrapping-up",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "\n11.5 Wrapping Up",
    "text": "11.5 Wrapping Up\nIn this chapter we learned about three different methods to measure the spread of data:\n\n\nMean absolute deviation (MAD): It is the most intuitive measure.\n\nvariance var, Variance (var): It is mathematically easy to use and has the nice property of an exponential penalty.\n\nStandard deviation (sigma, \\(\\sigma\\)): This is the most used measure for dispersion as it is reasonable intuitive and mathematically easy to use.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html#exercises",
    "href": "11-data-spread.html#exercises",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "\n11.6 Exercises",
    "text": "11.6 Exercises\nTry answering the following questions to see how well you understand these different methods of measuring the spread of data. The solutions can be found at https://nostarch.com/learnbayes/.\n\n11.6.1 Exercise 11-1\nOne of the benefits of variance is that squaring the differences makes the penalties exponential. Give some examples of when this would be a useful property.\nSolution:\n\n\n\n\n\n\nNote\n\n\n\nMy solution hinted at outliers but this is not the much more practical intended solution. The penalty is not only useful whenever the distance to missing the intended value is important. Will Kurt uses the example of a teleporter missing its intended location by 3 feet, 3 miles of 30 miles.\n\n\n\n11.6.2 Exercise 11-2\nCalculate the mean, variance, and standard deviation for the following values: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\nSolution:\n\n\n\nListing 11.1: Exercise 11-2: Calculate the mean, variance, and standard deviation for the following values: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\n\nvar_fun &lt;- function(x) {\n  sum((x - mean(x))^2) * 1 / length(x)\n}\n\nsd_fun &lt;- function(x) {\n  sqrt(sum((x - mean(x))^2) * 1 / length(x))\n}\n\n\nx3 &lt;-  1:10\nmean(x3)\n\n\n\n\n[1] 5.5\n\n\n\nListing 11.2: Exercise 11-2: Calculate the mean, variance, and standard deviation for the following values: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\n\nvar_fun(x3)\n\n\n\n\n[1] 8.25\n\n\n\nListing 11.3: Exercise 11-2: Calculate the mean, variance, and standard deviation for the following values: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\n\nsd_fun(x3)\n\n\n\n\n[1] 2.872281",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "11-data-spread.html#experiments",
    "href": "11-data-spread.html#experiments",
    "title": "\n11  Measuring the Spread of our Data\n",
    "section": "\n11.7 Experiments",
    "text": "11.7 Experiments\n\n11.7.1 Computing the MAD\nThere is a function stats::mad() in base R to compute the MAD, but it is in several aspects different to the calculation of Will Kurt:\n\nFirst of all the abbreviation stands for Median Absolute Deviation., e.g. it computes by default the deviation from the median. This is the more robust central measure as outliers does not have so much impact as in the case of the mean calculation. But you could change the default parameter center = median(x) to center = mean(x).\nThe function includes a scale factor of 1.4826 to ensure consistency for \\(X_{i}\\), distributed as \\(N(\\mu, \\sigma^2)\\) and large \\(n\\). Again you could change this by setting the parameter constant = 1.\nBut most important the base R function divides by n and not by the reciprocal value of \\(\\frac{1}{n}\\).\n\nSo the best way is to write our own R function corresponding to the calculation by Will Kurt:\n\n\n\nListing 11.4: Create a function to compute the mean absolute deviation (MAD) as used in the book\n\nmad_fun &lt;- function(x) {\n    sum(abs(x - mean(x))) * 1 / length(x)\n}\n\nx1 &lt;- c(3.02, 2.95, 2.98, 3.08, 2.97)\nx2 &lt;- c(3.31, 2.16, 3.02, 3.71, 2.80)\n\nmad_fun(x1)\n\n\n\n\n[1] 0.04\n\n\n\nListing 11.5: Create a function to compute the mean absolute deviation (MAD) as used in the book\n\nmad_fun(x2)\n\n\n\n\n[1] 0.416\n\n\nThis is the same result as in the book, page 98.\n\n11.7.2 Computing the variance\nThe variance can be computed with the R base function stats::var(). But again there is the difference that this formula does not take the reciprocal value of the observed events but just divides by n.\nAgain we have to develop our own R function to get the same results as Will Kurt:\n\n\n\nListing 11.6: Create a function to compute the variance as used in the book\n\nvar_fun &lt;- function(x) {\n  sum((x - mean(x))^2) * 1 / length(x)\n}\n\nvar_fun(x1)\n\n\n\n\n[1] 0.00212\n\n\n\nListing 11.7: Create a function to compute the variance as used in the book\n\nvar_fun(x2)\n\n\n\n\n[1] 0.26924\n\n\n\n11.7.3 Comouting the Standard Deviation (sigma \\(\\sigma\\))\nThe base R function for the standard deviation is stats::sd() But as in Equation 11.1 and Equation 11.2 we need to write our own function to get the same values as in the book because of the difference divided by \\(n\\) (base R) and divided by the reciprocal value \\(\\frac{1}{n}\\) (book).\n\n\n\nListing 11.8: Create a function to compute the standard deviation as used in the book\n\nsd_fun &lt;- function(x) {\n  sqrt(sum((x - mean(x))^2) * 1 / length(x))\n}\n\nsd_fun(x1)\n\n\n\n\n[1] 0.04604346\n\n\n\nListing 11.9: Create a function to compute the standard deviation as used in the book\n\nsd_fun(x2)\n\n\n\n\n[1] 0.5188834",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Measuring the Spread of our Data</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html",
    "href": "13-pdf-cdf-quantile.html",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "",
    "text": "13.1 Estimating the Conversion Rate for an Email Signup List",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#estimating-the-conversion-rate-for-an-email-signup-list",
    "href": "13-pdf-cdf-quantile.html#estimating-the-conversion-rate-for-an-email-signup-list",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "",
    "text": "Say you run a blog and want to know the probability that a visitor to your blog will subscribe to your email list. In marketing terms, getting a user to perform a desired event is referred to as the conversion event, or simply a conversion, and the probability that a user will subscribe is the conversion rate.\n\n\nAs discussed in Section 5.2, we would use the beta distribution to estimate p, the probability of subscribing, when we know k, the number of people subscribed, and n, the total number of visitors. The two parameters needed for the beta distribution are α, which in this case represents the total subscribed (k), and β, representing the total not subscribed (n – k).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#the-probability-density-function",
    "href": "13-pdf-cdf-quantile.html#the-probability-density-function",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "\n13.2 The Probability Density Function",
    "text": "13.2 The Probability Density Function\n\nlet’s say for the first 40,000 visitors, you get 300 subscribers. The PDF for our problem is the beta distribution where α = 300 and β = 39,700.\n\n\nTheorem 13.1 (Computing the mean of the beta distribution) \\[\n\\begin{align*}\n\\mu_{Beta} = \\frac{\\alpha}{\\alpha + \\beta} \\\\\n\\mu_{Beta} = \\frac{300}{300 + 39,700} = 0.0075\n\\end{align*}\n\\tag{13.1}\\]\nThe blog’s average conversion rate is simply \\(\\frac{subscribed}{visited}\\).\n\n\n13.2.1 Visualizing and Interpreting the PDF\n\n\nFigure 13.1: Visualizing the beta PDF for our beliefs in the true conversion rate\n\n\n\n\n\n\nGiven that we have uncertainty in our measurement, and we have a mean, it could be useful to investigate how much more likely it is that the true conversion rate is 0.001 higher or lower than the mean of 0.0075 we observed.\n\n\n\n\nListing 13.1: How much more likely it is that the true conversion rate is 0.001 higher or lower\n\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0, 0.0065)\n\n\n\n\n0.007978686 with absolute error &lt; 3.8e-07\n\n\n\nListing 13.2: How much more likely it is that the true conversion rate is 0.001 higher or lower\n\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0.0085, 1)\n\n\n\n\n0.01248151 with absolute error &lt; 9.4e-09\n\n\n\nif we had to make a decision with the limited data we have, we could still calculate how much likelier one extreme is than the other:\n\n\n\n\nListing 13.3: How much likelier is one extreme than the other\n\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0.0085, 1)[[\"value\"]] /\nintegrate(function(x)\n    dbeta(x, 300, 39700), 0, 0.0065)[[\"value\"]]\n\n\n\n\n[1] 1.564357\n\n\nIt’s 56 percent more likely that our true conversion rate is greater than 0.0085 than that it’s lower than 0.0065.\n\n13.2.2 Working with the PDF in R\nI am going to use my own code in Section 13.7.1. But to see what it looks like I use the R base code lines from the book:\n\n\n\nListing 13.4: Working with the PDF in base R\n\nxs &lt;- seq(0.005, 0.01, by = 0.00001)\nxs.all &lt;- seq(0, 1, by = 0.0001)\nplot(\n    xs,\n    dbeta(xs, 300, 40000 - 300),\n    type = 'l',\n    lwd = 3,\n    ylab = \"density\",\n    xlab = \"probability of subscription\",\n    main = \"PDF Beta(300,39700)\"\n)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#introducing-the-cumulative-distribution-function",
    "href": "13-pdf-cdf-quantile.html#introducing-the-cumulative-distribution-function",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "\n13.3 Introducing the Cumulative Distribution Function",
    "text": "13.3 Introducing the Cumulative Distribution Function\n\nwe can save ourselves a lot of effort with the cumulative distribution function (CDF), which sums all parts of our distribution, replacing a lot of calculus work. … The CDF takes in a value and returns the probability of getting that value or lower.\n\n\nThe CDF gets this probability by taking the cumulative area under the curve for the PDF (for those comfortable with calculus, the CDF is the anti-derivative of the PDF). We can summarize this process in two steps: (1) figure out the cumulative area under the curve for each value of the PDF, and (2) plot those values. That’s our CDF.\n\n\n\nFigure 13.2: Visualizing the cumulative area under the curve\n\n\n\n\n\nFigure 13.2 shows the cumulative area under the curve for the PDF of Beta(300,39700). As you can see, our cumulative area under the curve takes into account all of the area in the pieces to its left.\nUsing this approach, as we move along the PDF, we take into account an increasingly higher probability until our total area is 1, or complete certainty. To turn this into the CDF, we can imagine a function that looks at only these areas under the curve.\nFigure 13.3 shows what happens if we plot the area under the curve for each of our points, which are 0.0005 apart.\n\n\nFigure 13.3: Plotting just the cumulative probability from Figure 13.2\n\n\n\n\n\n\nNow we have a way of visualizing just how the cumulative area under the curve changes as we move along the values for our PDF. Of course, the problem is that we’re using these discrete chunks. In reality, the CDF just uses infinitely small pieces of the PDF, so we get a nice smooth line as seen in Figure 13.4.\n\n\n\nFigure 13.4: The CDF for our problem\n\n\n\n\n\n\n13.3.1 Visualizing and Interpreting the CDF\n\nThe PDF is most useful visually for quickly estimating where the peak of a distribution is, and for getting a rough sense of the width (variance) and shape of a distribution. However, with the PDF it is very difficult to reason about the probability of various ranges visually. The CDF is a much better tool for this.\n\n\n13.3.1.1 Finding the median\n\nUnlike the mean, computing the median can actually be pretty tricky. For small, discrete cases, it’s as simple as putting your observations in order and selecting the value in the middle. But for continuous distributions like our beta distribution, it’s a little more complicated.\n\n\nThankfully, we can easily spot the median on a visualization of the CDF. We can simply draw a line from the point where the cumulative probability is 0.5, meaning 50 percent of the values are below this point and 50 percent are above.\n\n\n\n\n\n\n\nNote\n\n\n\nThere are many packages about the beta functions out there that provides functions for parameter calculation: For instance betamedian() of {betafunctions}. But in a StackOverflow post is the suggestion simple to use qbeta() with p = 0.5.\nThis is what I have done in replicating Figure 13.5 with my Figure 13.17.\n\n\n\n\nFigure 13.5: Estimating the median visually using the CDF\n\n\n\n\n\n\n13.3.1.2 Approximating Integrals Visually\n\nWhen working with ranges of probabilities, we’ll often want to know the probability that the true value lies somewhere between some value y and some value x.\n\nTime-consuming computation the integration with R is not necessary as we can eyeball whether or not a certain range of values has a very high probability or a very low probability of occurring.\n\n\nFigure 13.6: Visually performing integration using the CDF\n\n\n\n\n\n\n13.3.1.3 Estimating Confidence Intervals\n\nLooking at the probability of ranges of values leads us to a very important concept in probability: the confidence interval. A confidence interval is a lower and upper bound of values, typically centered on the mean, describing a range of high probability, usually 95, 99, or 99.9 percent. When we say something like “The 95 percent confidence interval is from 12 to 20,” what we mean is that there is a 95 percent probability that our true measurement is somewhere between 12 and 20. Confidence intervals provide a good method of describing the range of possibilities when we’re dealing with uncertain information.\n\nIn spite of a special note “In Bayesian statistics what we are calling a ”confidence interval” can go by a few other names, such as ”critical region” or ”critical interval.” In some more traditional schools of statistics, ”confidence interval” has a slightly different meaning, which is beyond the scope of this book.” this concept and notions are not correct for Bayesian statistics. At least what I have learned reading other books, especially (mcelreath2020?).\n\n\n\n\n\n\nWarning\n\n\n\nBayesian statistics (GLOSSARY) talks about credible interval, credible intervals (GLOSSARY) that have a very different meaning as the confidence interval, confidence intervals (GLOSSARY) of frequentist statistics (GLOSSARY). McElreath even proposes the notion of compatibility interval, compatibility intervals (GLOSSARY).\n\n\n\nSay we wanted to know the range that covers 80 percent of the possible values for the true conversion rate. We solve this problem by combining our previous approaches: we draw lines at the y-axis from 0.1 and 0.9 to cover 80 percent, and then simply see where on the x-axis these intersect with our CDF:\n\n\n\nFigure 13.7: Estimating our confidence intervals visually using the CDF\n\n\n\n\n\n\n13.3.2 Using the CDF in R\n\nJust as nearly all major PDFs have a function starting with \\(d\\), like dnorm(), CDF functions start with \\(p\\), such as pnorm().\n\n\n\n\n\n\n\nNote\n\n\n\nThis is a new information for me. Now I understand better the differences and use cases of the different types of distribution. My comprehension will be fostered with the next section when the application of function starting with \\(q\\) is explained.\n\n\n\n\n\nListing 13.5: Calculate the probability that Beta(300,39700) is less than 0.0065\n\npbeta(0.0065,300,39700)\n\n\n\n\n[1] 0.007978686\n\n\n\n\n\nListing 13.6: Calculate the true probability that the conversion rate is greater than 0.0085\n\npbeta(1,300,39700) - pbeta(0.0085,300,39700)\n\n\n\n\n[1] 0.01248151\n\n\n\nThe great thing about CDFs is that it doesn’t matter if your distribution is discrete or continuous. If we wanted to determine the probability of getting three or fewer heads in five coin tosses, for example, we would use the CDF for the binomial distribution like this:\n\n\n\n\nListing 13.7: Calculate the probability of getting three or fewer heads in five coin tosses\n\npbinom(3, 5, 0.5)\n\n\n\n\n[1] 0.8125",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#the-quantile-function",
    "href": "13-pdf-cdf-quantile.html#the-quantile-function",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "\n13.4 The Quantile Function",
    "text": "13.4 The Quantile Function\n\nMathematically, the CDF is like any other function in that it takes an \\(x\\) value, often representing the value we’re trying to estimate, and gives us a \\(y\\) value, which represents the cumulative probability. But there is no obvious way to do this in reverse; that is, we can’t give the same function a \\(y\\) to get an \\(x\\).\n\nBut we did reversing the function when we estimated the median in Section 13.3.1.1 respectively in my version in Section 13.7.5.\n\nThe inverse of the CDF is an incredibly common and useful tool called the quantile function. To compute an exact value for our median and confidence interval, we need to use the quantile function for the beta distribution.\n\n\n13.4.1 Visualizing and Understanding the Quantile Function\n\nBecause the quantile function is simply the inverse of the CDF, it just looks like the CDF rotated 90 degrees, as shown in Figure 13.8.\n\n\n\nFigure 13.8: Visually, the quantile function is just a rotation of the CDF\n\n\n\n\n\n\nWhenever you hear phrases like:\n\n“The top 10 percent of students …”\n“The bottom 20 percent of earners earn less than …”\n“The top quartile has notably better performance than …”\n\nyou’re talking about values that are found using the quantile function\n\n\n13.4.2 Calculating Quantiles in R\nWe are using the function qnorm() for calculating quantile, quantiles (GLOSSARY).\n\nFor example, if we want to know the value that 99.9 percent of the distribution is less than, we can use qbeta() with the quantile we’re interested in calculating as the first argument, and the alpha and beta parameters of our beta distribution as the second and third arguments, like so:\n\n\n\n\nListing 13.8: Value that we 99.9 percent certain that the true conversion rate for our emails is less than 0.0089\n\nqbeta(0.999, 300, 39700)\n\n\n\n\n[1] 0.008903462\n\n\nThe result is 0.0089, meaning we can be 99.9 percent certain that the true conversion rate for our emails is less than 0.0089.\nWith the quantile function we can also calculate the 95% confidence interval by finding the lower and upper 2.5% quantile:\n\n\n\nListing 13.9: Calculate the 95% confidence interval\n\nglue::glue(\"The lower bound is {round(qbeta(0.025,300,39700), 7)} and the upper bound is {round(qbeta(0.975,300,39700) ,7)}.\")\n\n\n\n\nThe lower bound is 0.0066781 and the upper bound is 0.0083686.\n\n\n\nNow we can confidently say that we are 95 percent certain that the real conversion rate for blog visitors is somewhere between 0.67 percent and 0.84 percent. … Suppose an article on your blog goes viral and gets 100,000 visitors. Based on our calculations, we know that we should expect between 670 and 840 new email subscribers.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#wrapping-up",
    "href": "13-pdf-cdf-quantile.html#wrapping-up",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "\n13.5 Wrapping Up",
    "text": "13.5 Wrapping Up",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#exercises",
    "href": "13-pdf-cdf-quantile.html#exercises",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "\n13.6 Exercises",
    "text": "13.6 Exercises\nTry answering the following questions to see how well you understand the tools of parameter estimation. The solutions can be found at https://nostarch.com/learnbayes/.\n\n13.6.1 Exercise 13-1\nUsing the code example for plotting the PDF on page 127, plot the CDF and quantile functions.\n\nFor the CDF see Listing 13.18 and Figure 13.13.\nFor the quantile function see Listing 13.28 and Figure 13.23.\n\n13.6.2 Exercise 13-2\nReturning to the task of measuring snowfall from Chapter 10, say you have the following measurements (in inches) of snowfall: 7.8, 9.4, 10.0, 7.9, 9.4, 7.0, 7.0, 7.1, 8.9, 7.4\nWhat is your 99.9 percent confidence interval for the true value of snowfall?\n\n\n\nListing 13.10: Calculate the 99% confidence interval\n\nx &lt;-  c(7.8, 9.4, 10.0, 7.9, 9.4, 7.0, 7.0, 7.1, 8.9, 7.4)\n\nglue::glue(\"The lower bound is {round(qnorm(0.0005,mean(x), sd(x)), 2)} and the upper bound is {round(qnorm(0.9995,mean(x), sd(x)), 2)}.\")\n\n\n\n\nThe lower bound is 4.46 and the upper bound is 11.92.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBesides that in my try I used the sd_fun() function from Listing 12.3, I commit an error in using bounds of 0.001 and 0.999 instead of 0.0005 and 0.9995.\n\n\n\n13.6.3 Exercise 13-3\nA child is going door to door selling candy bars. So far she has visited 30 houses and sold 10 candy bars. She will visit 40 more houses today. What is the 95 percent confidence interval for how many candy bars she will sell the rest of the day?\n\n\n\nListing 13.11: Calculate the 95 percent confidence interval for how many candy bars will be sold\n\nglue::glue(\"The lower bound is {round(qbeta(0.025, 10, 20), 2)}% and the upper bound is {round(qbeta(0.975, 10, 20), 2)}%.\")\n\n\n\n\nThe lower bound is 0.18% and the upper bound is 0.51%.\n\n\n\nListing 13.12: Calculate the 95 percent confidence interval for how many candy bars will be sold\n\nglue::glue(\"This means that she will with 95% probability get between 40 * 0.18 = {40 * 0.18} and 40 * 0.51 = {40 * 0.51} candy bars.\")\n\n\n\n\nThis means that she will with 95% probability get between 40 * 0.18 = 7.2 and 40 * 0.51 = 20.4 candy bars.\n\n\n\nListing 13.13: Calculate the 95 percent confidence interval for how many candy bars will be sold\n\nglue::glue(\"But she can only sell complete bars: Therefore she will sell between {floor(40 * 0.18)} and {floor(40 * 0.51)} candy bars.\")\n\n\n\n\nBut she can only sell complete bars: Therefore she will sell between 7 and 20 candy bars.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "13-pdf-cdf-quantile.html#experiments",
    "href": "13-pdf-cdf-quantile.html#experiments",
    "title": "13  Tools of Parameter Estimation: The PDF, CDF, and Quantile Function",
    "section": "\n13.7 Experiments",
    "text": "13.7 Experiments\nI started with Figure 13.13 because this is the easiest graph, as it replicates Figure 13.4 with just the CDF and nothing else. So maybe you will begin also with this basic plot. After Figure 13.13 the natural sequence – ordered by complexity – is Figure 13.12. After that you can inspect in detail my different tries with Figure 13.2 (Figure 13.9, Figure 13.10 and my best solution Figure 13.11) . Then follow my sequences here from Figure 13.5 to Figure 13.8.\n\n\n\n\n\n\nImportant\n\n\n\nThere is the following system in using distributions with R, exemplified with the normal distribution:\n\n\ndnorm for plotting probability densities functions (PDFs).\n\npnorm for plotting cumulative distribution functions (CDFs).\n\nqnorm for plotting quantile functions, it is the reverse of CDFs.\n\nrnorm for generating and plotting random distributions.\n\nSee\n\nR help file for Distributions in the stats package.\n\nThe distribution zoo (a shiny application by Ben Lambert & Fergus Cooper). See for the code the GitHub repo.\n\n\n\n\n13.7.1 Replicate Figure 13-1\n\n13.7.1.1 Wrong dimension of x-axis for Figure 13-1\nAt first I got the following graph:\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y = dbeta(x, 300, 39700)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n\n\n\n\n\n\n\nThe problem here is that the interesting part of the PDF is very small as we know from the \\(\\frac{300}{40000} = 0.0075\\). Therefore it does not make sense to spread the grid from 0 to 1. We get a much better visualization in the area 0 to 001:\n\n13.7.1.2 Better dimension of x-axis but still not identical for Figure 13-1\n\ntibble::tibble(x = seq(0, 0.01, .0001),\n               y = dbeta(x, 300, 39700)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n\n\n\n\n\n\n\nBut even this curve is not optimal. Now let’s try the interval [0.005, 0.01]:\n\n13.7.1.3 Optimal dimension of x-axis but grid too wide for smooth Figure 13-1\n\ntibble::tibble(x = seq(0.005, 0.01, .0001),\n               y = dbeta(x, 300, 39700)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n\n\n\n\n\n\n\nIt turns out that this is the interval also used in the book example. But in my visualization you can see some irregularity at the top, because my grid has too coarse. It has only 51 values. Let’s try a much finer grid with 5001 values:\n\n13.7.1.4 Optimal replication of Figure 13-1\n\ntibble::tibble(x = seq(0.005, 0.01, .00001),\n               y = dbeta(x, 300, 39700)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line()\n\n\n\n\n\n\n\n\n13.7.2 Replicate Figure 13-2\n\n13.7.2.1 First try (bad)\n\n\n\n\n\n\nNote\n\n\n\nI had to learn about the difference between annotate(geom = \"text\" …) and annotate(geom = \"label\" …). There are two big differences:\n\n\ngeom_text() does not understand the fill aesthetics, e.g. you can’t change the background color of the text.\n\ngeom_label() “is considerable slower than geom_text()” and does not support the check_overlap argument and the angle aesthetic. But more important for my use case geom_label() draws a rectangle around the label. You need to add label.size = NA to remove the label. Although the option label.size is documented (“Size of label border, in mm.”) using NA to remove the border completely is not explained. I had to find out it the hard way via StackOverflow.\n\n\n\n\n\n\nListing 13.14: Highlighting the cumulative area under the curve\n\nx_lower &lt;-  seq(0.006, 0.0085, 0.0005)\nx_upper &lt;-  seq(0.0065, 0.009, 0.0005)\ntext_pos &lt;- seq(0.00625, 0.00875, 0.0005)\ncolors &lt;- c(\"gray90\", \"gray80\", \"gray70\", \"gray50\", \"gray40\", \"black\") \n\ndf_13_2 &lt;- \ntibble::tibble(x = seq(0.006, 0.009, length.out = 6000),\n               y = dbeta(x, 300, 39700))\n\nggplot2::ggplot(df_13_2, ggplot2::aes(x = x, y = y)) +\nggplot2::geom_line() +\n        ggplot2::geom_area(data = df_13_2 |&gt;\n                           dplyr::filter(x &gt;= x_lower[1] & x &lt;  x_upper[1]),\n                           fill = colors[1]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[1], \n                          size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA,\n                          label = round(integrate(function(x) \n                  dbeta(x, 300, 39700), x_lower[1], x_upper[1])[[\"value\"]], 3)) +\n    \n        ggplot2::geom_area(data = df_13_2 |&gt; \n                           dplyr::filter(x &gt;= x_lower[2] & x &lt;  x_upper[2]),\n                           fill = colors[2]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[2], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA,\n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[2])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |&gt; \n                           dplyr::filter(x &gt;= x_lower[3] & x &lt;  x_upper[3]),\n                           fill = colors[3]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[3], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[3])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |&gt; \n                           dplyr::filter(x &gt;= x_lower[4] & x &lt;  x_upper[4]),\n                           fill = colors[4]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[4], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[4])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |&gt; \n                           dplyr::filter(x &gt;= x_lower[5] & x &lt;  x_upper[5]),\n                           fill = colors[5]\n                           ) +\n        ggplot2::annotate(\"label\", x = text_pos[5], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[5])[[\"value\"]], 3)) +\n\n        ggplot2::geom_area(data = df_13_2 |&gt; \n                           dplyr::filter(x &gt;= x_lower[6] & x &lt;  x_upper[6]),\n                           fill = colors[6]\n                           ) +\n        ggplot2::annotate(geom = \"label\", x = text_pos[6], size = 5, y = 125, color = \"black\", fill = \"white\", label.size = NA, \n            label = round(integrate(function(x) \n              dbeta(x, 300, 39700), x_lower[1], x_upper[6])[[\"value\"]], 3)) +\n\nggplot2::theme_bw() +\nggplot2::labs(\n    title = \"Visualizing the cumulative area under the curve\",\n    x = \"Probability of Subscription\",\n    y = \"Density\"\n)\n\n\n\n\n\n\nFigure 13.9: Visualizing the cumulative area under the curve\n\n\n\n\n\n\n\n\n13.7.2.2 Second try (Slightly better)\n\n\n\n\n\n\nWarning\n\n\n\nI am very unhappy about the many duplicates of Listing 13.14. I tried to use loops or vectorized commands but the best I found out is Listing 13.15 with has still six duplicate code lines.\n\n\n\n\n\nListing 13.15: Highlighting the cumulative area under the curve\n\nx_lower &lt;-  seq(0.006, 0.0085, 0.0005)\nx_upper &lt;-  seq(0.0065, 0.009, 0.0005)\nlabel_x_pos &lt;- seq(0.00625, 0.00875, 0.0005)\ncolors &lt;- c(\"gray90\", \"gray80\", \"gray70\", \"gray50\", \"gray40\", \"black\") \n\ncum_rate = 0\nfor (i in 1:6) {\n    cum_rate[i] &lt;- \n    round(integrate(function(x) \n                      dbeta(x, 300, 39700), x_lower[1], x_upper[i])[[\"value\"]], 3) \n}\n\nadd_label &lt;- function(x_pos, txt) {\n    ggplot2::annotate(\n        geom = \"label\",\n        x = x_pos,\n        y = 125,\n        size = 5,\n        label = txt,\n        label.size = NA\n    )\n}\n\n\nhighlight_one_area &lt;- function(df, i) {\n        ggplot2::geom_area(data = df |&gt;\n                       dplyr::filter(x &gt;= x_lower[i] & x &lt;  x_upper[i]),\n                       fill = colors[i])\n}\n\n\n\ndf_13_2 &lt;- \n    tibble::tibble(x = seq(0.006, 0.009, length.out = 6000),\n                   y = dbeta(x, 300, 39700)) \n\n\np_13_2 &lt;- \n    ggplot2::ggplot(df_13_2, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    highlight_one_area(df_13_2, 1) +\n    highlight_one_area(df_13_2, 2) +\n    highlight_one_area(df_13_2, 3) +\n    highlight_one_area(df_13_2, 4) +\n    highlight_one_area(df_13_2, 5) +\n    highlight_one_area(df_13_2, 6) +\n    add_label(label_x_pos, cum_rate) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Visualizing the cumulative area under the curve\",\n        x = \"Probability of Subscription\",\n        y = \"Density\"\n    )\n\np_13_2\n\n\n\n\n\n\nFigure 13.10: Visualizing the cumulative area under the curve\n\n\n\n\n\n\n\n\n13.7.2.3 Third try (My best version)\nAs I could not find a better solution for Listing 13.15 myself I posted my question in StackOverflow and got an answer with two different options within one hour!\nThe first solution is to use lapply(). I should have known that as I came over a similar solution. The second solution is for me more complex and I have still to study it thoroughly to understand it.\nWhat follows in Listing 13.16 is the modern take of lapply() using the purrr::map() function. (I do not understand why I had to use exactly the argument “df” and asked via SO comment.)\n\n\n\nListing 13.16: Highlighting the cumulative area under the curve\n\n########### Vectors ##############\n\nx_lower &lt;-  seq(0.006, 0.0085, 0.0005)\nx_upper &lt;-  seq(0.0065, 0.009, 0.0005)\nlabel_x_pos &lt;- seq(0.00625, 0.00875, 0.0005)\ncolors &lt;- c(\"gray90\", \"gray80\", \"gray70\", \"gray50\", \"gray40\", \"black\") \n\n########### Functions ############\n\n\ncum_rate = 0\nfor (i in 1:6) {\n    cum_rate[i] &lt;- \n    round(integrate(function(x) \n                      dbeta(x, 300, 39700), x_lower[1], x_upper[i])[[\"value\"]], 3) \n}\n\nadd_label &lt;- function(x_pos, txt) {\n    ggplot2::annotate(\n        geom = \"label\",\n        x = x_pos,\n        y = 125,\n        size = 5,\n        label = txt,\n        label.size = NA\n    )\n}\n\nhighlight_areas &lt;- function(df, i) {\n        ggplot2::geom_area(data = df |&gt;\n                       dplyr::filter(x &gt;= x_lower[i] & x &lt;  x_upper[i]),\n                       fill = colors[i])\n}\n\n######### Graph plotting ############\n\ndf_13_2 &lt;- \n    tibble::tibble(x = seq(0.006, 0.009, length.out = 6000),\n                   y = dbeta(x, 300, 39700)) \n\np_13_2 &lt;- \n    ggplot2::ggplot(df_13_2, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    purrr::map(1:6, highlight_areas, df = df_13_2) +\n    add_label(label_x_pos, cum_rate) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Visualizing the cumulative area under the curve\",\n        x = \"Probability of Subscription\",\n        y = \"Density\"\n    )\n\np_13_2\n\n\n\n\n\n\nFigure 13.11: Visualizing the cumulative area under the curve\n\n\n\n\n\n\n\n\n13.7.3 Replicate Figure 13-3\n\n\n\nListing 13.17: Plot the cumulative area under the curve\n\ndf_13_3 &lt;- \ntibble::tibble(x = seq(0.006, 0.009, 0.0005),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_3, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_point() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The cumulative distribution function\",\n        x = \"Subscription rate\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\n\n\nFigure 13.12: Plotting just the cumulative probability from Figure 13-2\n\n\n\n\n\n\n\n\n13.7.4 Replicate Figure 13-4\n\n13.7.4.1 Cumulative Distribution Function (CDF)\n\n\n\nListing 13.18: Plot the Cumulative Distribution Function (CDF)\n\ndf_13_4a &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_4a, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The cumulative distribution function\",\n        x = \"Subscription rate\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\n\n\nFigure 13.13: The CDF for our problem\n\n\n\n\n\n\n\n\n13.7.4.2 Empiricial Cumulative Distribution Function (ECDF) - with steps\n\n\n\n\n\n\nNote\n\n\n\nTrying to apply the CDF I noticed that there is also an ECDF(Empirical Cumulative Distribution Function) (GLOSSARY). The differences are that the ECDF is a step function whereas the CDF is smooth. But with many different values the ECDF approximates to ta smooth function.\n\n\n\n\n\nListing 13.19: Plot the Empirical Cumulative Distribution Function (ECDF)\n\ndf_13_4b &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-4),\n               y = rbeta(x, 300, 39700)) \n\n\nggplot2::ggplot(df_13_4b, ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"step\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The empirical cumulative distribution function (ECDF)\",\n        x = \"x\",\n        y = \"ECDF\"\n    )\n\n\n\n\n\n\nFigure 13.14: The ECDF for our problem\n\n\n\n\n\n\n\n\n13.7.4.3 Empiricial Cumulative Distribution Function (ECDF) - with points\n\n\n\nListing 13.20: Plot the Cumulative Distribution Function (CDF)\n\ndf_13_4c &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-4),\n               y = rbeta(x, 300, 39700)) \n\n\nggplot2::ggplot(df_13_4c, ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"point\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The empirical cumulative distribution function (ECDF)\",\n        x = \"x\",\n        y = \"ECDF\"\n    )\n\n\n\n\n\n\nFigure 13.15: The ECDF for our problem\n\n\n\n\n\n\n\n\n13.7.4.4 Empiricial Cumulative Distribution Function (ECDF) - smooth\n\n\n\nListing 13.21: Plot the Empirical Cumulative Distribution Function (ECDF)\n\ndf_13_4d &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = rbeta(x, 300, 39700)) \n\n\nggplot2::ggplot(df_13_4d, ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"step\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"The empirical cumulative distribution function (ECDF)\",\n        x = \"x\",\n        y = \"ECDF\"\n    )\n\n\n\n\n\n\nFigure 13.16: The ECDF for our problem\n\n\n\n\n\n\n\n\n13.7.5 Replicate Figure 13-5\n\n\n\nListing 13.22: Estimate and display median using the CDF\n\nmedian_beta &lt;- round(qbeta(0.5, 300, 39700), 5)\n\ndf_13_5 &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_5, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(ggplot2::aes(x = 0.005, y = 0.50, \n                          xend = median_beta, yend = 0.50),\n                          lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n                          size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(ggplot2::aes(x = median_beta, y = 0.50, \n                      xend = median_beta, yend = 0.00),\n                      lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n                      size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::annotate(\"text\", y = 0.625, x = 0.0087,\n                      label = \"median = qbeta(0.5, 300, 39700)\") +\n        ggplot2::annotate(\"text\", y = 0.55, x = 0.0087,\n                      label = glue::glue(\"= {median_beta}\")) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating median\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.005, y = 0.5, xend = median_beta, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = median_beta, y = 0.5, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\nFigure 13.17: Estimating the median visually using the CDF\n\n\n\n\n\n\n\n\n13.7.6 Replicate Figure 13-6\nIn contrast to Figure 13.17 where I cheated by calculating the median of the beta distribution I will in Section 13.7.6 try to approximate the integration just visually.\nWe are going to estimate the range between p(x &gt; 0.0075 and x &lt; 0.0085). The solution could be visually done approximately either with a ruler or (not so exact) just by eyeballing. To do it programmatically without integration is a somewhat complex procedure with four steps:\n\nFirst I have to draw vertical lines from the start and end of the interesting range. These lines have to cross the CDF because I do not know the value of the cumulative probability where they meet the CDF.\nThen I have to inspect the intersection visually and try to estimate and draw the horizontal lines. This has to be done several times until the two lines cross (almost) exactly at the CDF.\nNow I can limit the vertical and horizontal lines, so that they stop at the CDF.\nThe last step is to estimate the range by reading the intersection at the y-axis.\n\n\n13.7.6.1 First step\n\n\n\nListing 13.23: Approximate the integration of a range of the CDF: First step\n\ndf_13_6 &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_vline(xintercept = 0.0075, color = \"steelblue\",\n                        linetype = \"dashed\") +\n    ggplot2::geom_vline(xintercept = 0.0085, color = \"steelblue\",\n                        linetype = \"dashed\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x &gt; 0.0075 and x &lt; 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\n\n\nFigure 13.18: Visually performing integration using the CDF: First step\n\n\n\n\n\n\n\n\n13.7.6.2 Second step\nThe lower cumulative probability is almost exact 0.5 as I can see and already know from Figure 13.17. Without knowing the solution in the book my first approach was to draw a line at 0.98% of the CDF (orange). As this seems a little to less a tried with it .99%\n\n\n\nListing 13.24: Approximate the integration of a range of the CDF: Second step\n\ndf_13_6 &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_vline(xintercept = 0.0075, color = \"steelblue\",\n                        linetype = \"dashed\") +\n    ggplot2::geom_vline(xintercept = 0.0085, color = \"steelblue\",\n                        linetype = \"dashed\") +\n\n    ggplot2::geom_hline(yintercept = 0.5, color = \"steelblue\",\n                    linetype = \"dashed\") +\n    ggplot2::geom_hline(yintercept = 0.98, color = \"orange\",\n        linetype = \"dashed\") +\n    ggplot2::geom_hline(yintercept = 0.99, color = \"steelblue\",\n            linetype = \"dashed\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x &gt; 0.0075 and x &lt; 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\n\n\nFigure 13.19: Visually performing integration using the CDF: Second step\n\n\n\n\n\n\n\n\n13.7.6.3 Third step\n\n\n\nListing 13.25: Approximate the integration of a range of the CDF: Third step\n\ndf_13_6 &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.005, yend = 0.50, \n              x = 0.00750, y = 0.50),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0075, yend = 0.50, \n              x = 0.0075, y = 0.00),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0,\n              xend = 0.0085, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0.99,\n              xend = 0.005, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n  \n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x &gt; 0.0075 and x &lt; 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.005, yend = 0.5, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.0075, yend = 0.5, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.0085, y = 0, xend = 0.0085, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.0085, y = 0.99, xend = 0.005, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\nFigure 13.20: Visually performing integration using the CDF: Third step\n\n\n\n\n\n\n\n\n13.7.6.4 Fourth step\n\n\n\nListing 13.26: Approximate the integration of a range of the CDF: Fourth step\n\ndf_13_6 &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_6, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.005, yend = 0.50, \n              x = 0.00750, y = 0.50),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0075, yend = 0.50, \n              x = 0.0075, y = 0.00),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0,\n              xend = 0.0085, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0085, y = 0.99,\n              xend = 0.005, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n        \n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.0055, y = 0.5,\n              xend = 0.0055, yend = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"red\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0055, yend = 0.5,\n              x = 0.0055, y = 0.99),\n              lineend = \"square\", linejoin = \"bevel\", color = \"red\",\n              size = 0.8, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::annotate(\"text\", x = 0.0058, y = 0.75,\n                      label = \"~ 0.49\", color = \"red\", size = 5) +\n  \n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating P(x &gt; 0.0075 and x &lt; 0.0085)\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.005, yend = 0.5, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.0075, yend = 0.5, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.0085, y = 0, xend = 0.0085, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.0085, y = 0.99, xend = 0.005, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.0055, y = 0.5, xend = 0.0055, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.0055, yend = 0.5, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\nFigure 13.21: Visually performing integration using the CDF: Fourth step\n\n\n\n\n\n\n\n\n13.7.7 Replicate Figure 13-7\nThere is nothing new for approximating the range that covers 80 percent of the possible values for the true conversion rate. We use the same strategy as in Section 13.7.6 but this time starting from the y-axis:\n\n\n\nListing 13.27: Approximate the confidence interval via the CDF\n\ndf_13_7 &lt;- \ntibble::tibble(x = seq(0.005, 0.01, 1e-6),\n               y = pbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_7, ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.007, yend = 0.125, \n              x = 0.005, y = 0.125),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(xend = 0.0080, yend = 0.875, \n              x = 0.005, y = 0.875),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.007, y = 0.125,\n              xend = 0.007, yend = 0.0),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0.008, y = 0.875,\n              xend = 0.008, yend = 0.0),\n              lineend = \"square\", linejoin = \"bevel\", color = \"steelblue\",\n              size = 0.6, arrow = ggplot2::arrow(length = ggplot2::unit(0.5, \"cm\"))) +\n\n  \n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Estimating 80% Confidence Interval\",\n        x = \"Probability of subscription\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.007, yend = 0.125, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(xend = 0.008, yend = 0.875, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.007, y = 0.125, xend = 0.007, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0.008, y = 0.875, xend = 0.008, : All aesthetics have length 1, but the data has 5001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\nFigure 13.22: Estimating our confidence intervals visually using the CDF\n\n\n\n\n\n\n\n\n13.7.8 Replicate Figure 13-8\n\n\n\nListing 13.28: Plot the quantile function\n\ndf_13_8 &lt;- \ntibble::tibble(x = seq(0, 1, 1e-4),\n               y = qbeta(x, 300, 39700)) \n\n    ggplot2::ggplot(df_13_8, ggplot2::aes(x = x, y = y)) +\n    ggplot2::ylim(0.006, 0.009) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Quantile Function Beta(300, 39700)\",\n        x = \"Subscription rate\",\n        y = \"Cumulative Probability\"\n    )\n\n\n\n\nWarning: Removed 7 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\nFigure 13.23: Visually, the quantile function is just a rotation of the CDF.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Tools of Parameter Estimation: The PDF, CDF, and Quantile Function</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html",
    "href": "14-prior-probabilities.html",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "",
    "text": "14.1 Predicting Email Conversion Rates",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html#predicting-email-conversion-rates",
    "href": "14-prior-probabilities.html#predicting-email-conversion-rates",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "",
    "text": "Our data so far tells us that of the first five people that open an email, two of them click the link.\n\n\n\nFigure 14.1: The beta distribution for our observations so far\n\n\n\n\n\n\nUnlike in the previous chapter, where we had a pretty narrow spike in possible values, here we have a huge range of possible values for the true conversion rate because we have very little information to work with.\n\n\nThe 95 percent confidence interval (i.e., a 95 percent chance that our true conversion rate is somewhere in that range) is marked to make it easier to see. At this point our data tells us that the true conversion rate could be anything between 0.05 and 0.8! This is a reflection of how little information we’ve actually acquired so far.\n\n\n\nFigure 14.2: CDF for our observation",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html#taking-in-wider-context-with-priors",
    "href": "14-prior-probabilities.html#taking-in-wider-context-with-priors",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "\n14.2 Taking in Wider Context with Priors",
    "text": "14.2 Taking in Wider Context with Priors\nThis data (80% conversion rate) seems unrealistic.\n\nLet’s look at some wider context. For blogs listed in the same category as yours, the provider’s data claims that on average only 2.4 percent of people who open emails click through to the content.\n\nWe learned about producing the posterior probability (GLOSSARY) with the combination of prior probability (GLOSSARY) and likelihood (GLOSSARY) distribution in Chapter 9. The prior will change if new data (likelihood) come in. This process is called Bayesian updating (GLOSSARY).\n\nAs you know by now, in Bayesian terms the data we have observed is our likelihood, and the external context information—in this case from our personal experience and our email service—is our prior probability. Our challenge now is to figure out how to model our prior.\n\n\nThe conversion rate of 2.4 percent from your email provider gives us a starting point: now we know we want a beta distribution whose mean is roughly 0.024. (The mean of a beta distribution is $.) However, this still leaves us with a range of possible options: Beta(1,41), Beta(2,80), Beta(5,200), Beta(24,976), and so on. So which should we use? Let’s plot some of these out and see what they look like (see Figure 14.3).\n\n\n\n\n\n\n\nNote\n\n\n\nIn the meanwhile I learned from (kruschke2014?) that the calculation of different forms of the beta distribution is very important to model your prior beliefs. I think there are several R packages and Kruschke is also offering some scripts for this task. It also important to get a general impression how \\(\\alpha\\) and \\(\\beta\\) work together to form very different beta distribution.\n\n\n\n\nFigure 14.3: Comparing different possible prior probabilities\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe lower the combined \\(\\alpha + \\beta\\), the wider our distribution.\n\n\n\nThe problem now is that even the most liberal option we have, Beta(1,41), seems a little too pessimistic, as it puts a lot of our probability density in very low values. We’ll stick with this distribution nonetheless, since it is based on the 2.4 percent conversion rate in the data from the email provider, and is the weakest of our priors.\n\nWhy not use Beta(2, 80)? It is not so weak but still not very commiting. In my opinion it seems better providing the 2.4 percent conversion rate.\n\nwe can calculate our posterior distribution (the combination of our likelihood and our prior) by simply adding together the parameters for the two beta distributions:\n\n\\[\n\\begin{align*}\nBeta(\\alpha_{posterior}, \\beta_{posterior}) = Beta(\\alpha_{likelihood} + \\alpha_{prior}, \\beta_{likelihood} + \\beta_{prior})\n\\end{align*}\n\\tag{14.1}\\]\n\n\nFigure 14.4: Comparing our likelihood (no prior) to our posterior (with prior)\n\n\n\n\n\nThis is a big surprise!\n\nEven though we’re working with a relatively weak prior, we can see that it has made a huge impact on what we believe are realistic conversion rates. Notice that for the likelihood with no prior, we have some belief that our conversion rate could be as high as 80 percent. … Adding a prior to our likelihood adjusts our beliefs so that they become much more reasonable. But I still think our updated beliefs are a bit pessimistic.\n\n\nWe wait a few hours to gather more results and now find that out of 100 people who opened your email, 25 have clicked the link!\n\n\n\nFigure 14.5: Updating our beliefs with more data\n\n\n\n\n\n\nIn the morning we find that 300 subscribers have opened their email, and 86 of those have clicked through. Figure 14.6 shows our updated beliefs.\n\n\n\nFigure 14.6: Our posterior beliefs with even more data added\n\n\n\n\n\nNow the two curves are side by side. The likelihood curve is still more optimistic but the difference to the posterior probability is relatively small by visual inspection (about 30% versus 25%).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html#prior-as-a-means-of-quantifying-experience",
    "href": "14-prior-probabilities.html#prior-as-a-means-of-quantifying-experience",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "\n14.3 Prior as a Means of Quantifying Experience",
    "text": "14.3 Prior as a Means of Quantifying Experience\n\n14.3.1 Is There a Fair Prior to Use When We Know Nothing?\nWill Kurt’s answer is: No!\n\nIn the absence of sufficient data and any prior information, your only honest option is to throw your hands in the air and tell your friend, “I have no clue how to even reason about that question!”\n\nIn the literature there is much talk about a **non-informative prior (GLOSSARY) with \\(Beta(1,1)\\)\n\n\nFigure 14.7: The noninformative prior Beta(1,1)\n\n\n\n\n\n\nAs you can see, this is a perfectly straight line, so that all outcomes are then equally likely and the mean likelihood is 0.5.\n\n\\[\\text{mean of likelihood} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{1}{1 + 1} = \\frac{1}{2} = 0.5 \\tag{14.2}\\]\n\n\n\n\n\n\nNote\n\n\n\nThere is much discussion on this topic. People arguing that there is not such thing as a non-informative prior. I want not to go into further details here.\n\n\n\nA Beta(1,1) prior is sometimes used in practice, but you should use it only when you earnestly believe that the two possible outcomes are, as far as you know, equally likely.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html#wrapping-up",
    "href": "14-prior-probabilities.html#wrapping-up",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "\n14.4 Wrapping Up",
    "text": "14.4 Wrapping Up\n\nWhenever possible, it’s best to use a prior probability distribution based on actual data. However, often we won’t have data to support our problem, but we either have personal experience or can turn to experts who do. In these cases, it’s perfectly fine to estimate a probability distribution that corresponds to your intuition. Even if you’re wrong, you’ll be wrong in a way that is recorded quantitatively. Most important, even if your prior is wrong, it will eventually be overruled by data as you collect more observations.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html#exercises",
    "href": "14-prior-probabilities.html#exercises",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "\n14.5 Exercises",
    "text": "14.5 Exercises\nTry answering the following questions to see how well you understand priors. The solutions can be found at https://nostarch.com/learnbayes/.\n\n14.5.1 Exercise 14-1\nSuppose you’re playing air hockey with some friends and flip a coin to see who starts with the puck. After playing 12 times, you realize that the friend who brings the coin almost always seems to go first: 9 out of 12 times. Some of your other friends start to get suspicious. Define prior probability distributions for the following beliefs: - One person who weakly believes that the friend is cheating and the true rate of coming up heads is closer to 70 percent. - One person who very strongly trusts that the coin is fair and provided a 50 percent chance of coming up heads. - One person who strongly believes the coin is biased to come up heads 70 percent of the time.\n\n14.5.2 Exercise 14-2\nTo test the coin, you flip it 20 more times and get 9 heads and 11 tails. Using the priors you calculated in the previous question, what are the updated posterior beliefs in the true rate of flipping a heads in terms of the 95 percent confidence interval?",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "14-prior-probabilities.html#experiments",
    "href": "14-prior-probabilities.html#experiments",
    "title": "\n14  Parameter Estimation with Prior Probabilities\n",
    "section": "\n14.6 Experiments",
    "text": "14.6 Experiments\n\n14.6.1 Replicate Figure 14-1\nHover the cursor over Figure 14.1 to compare both plots!\n\n\n\nListing 14.1: Draw beta distribution for our observations so far\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y = dbeta(x, 2, 3)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Beta(2, 3) likelihood for possible conversion rates\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.8: The beta distribution for our observations so far\n\n\n\n\n\n\n\n\n14.6.2 Replicate Figure 14-2\nHover the cursor over Figure 14.2 to compare both plots!\n\n\n\nListing 14.2: Draw CDF with 95 percent credible interval\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y = pbeta(x, 2, 3)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::geom_segment(\n          ggplot2::aes(x = 0, y = 0.025, xend = 1, yend = 0.025),\n              linewidth = 0.4, linetype = \"dashed\", color = \"steelblue\") +\n    ggplot2::geom_segment(\n      ggplot2::aes(x = 0, y = 0.975, xend = 1, yend = 0.975),\n          linewidth = 0.4, linetype = \"dashed\", color = \"steelblue\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"CDF for Beta(2, 3)\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0, y = 0.025, xend = 1, : All aesthetics have length 1, but the data has 10001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in ggplot2::geom_segment(ggplot2::aes(x = 0, y = 0.975, xend = 1, : All aesthetics have length 1, but the data has 10001 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\nFigure 14.9: CDF for our observation\n\n\n\n\n\n\n\n\n14.6.3 Replicate Figure 14-3\nHover the cursor over Figure 14.3 to compare both plots!\n\n\n\nListing 14.3: Draw different possible prior probabilities\n\ntibble::tibble(x = seq(0, 0.15, .0001),\n               y1 = dbeta(x, 1, 41),\n               y2 = dbeta(x, 2, 80),\n               y3 = dbeta(x, 5, 200)) |&gt; \n    ggplot2::ggplot() +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y1, color = \"Beta(1, 41)\"),  linewidth = 1.0) +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y2, color = \"Beta(2, 80)\"),  linewidth = 1.0) +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y3, color = \"Beta(5, 200)\"), linewidth = 1.0) +\n    ggplot2::theme_bw() +\n    ggplot2::theme(legend.position = \"top\") +\n    ggplot2::scale_color_manual(name = \"Distributions:\", \n             values = c(\"Beta(1, 41)\" = \"red\",\n                        \"Beta(2, 80)\" = \"blue\",\n                        \"Beta(5, 200)\" = \"black\")) +\n    ggplot2::labs(\n        title = \"Possible priors for email conversion rate\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.10: Comparing different possible prior probabilities\n\n\n\n\n\n\n\n\n14.6.4 Replicate Figure 14-4\nWe need to calculate the posterior distribution (the combination of our likelihood and our prior) by simply adding together the parameters for the two beta distributions. Remember: We started with five people that opened the email, where two of them click the link we provided.\nWe are going to use Equation 14.1 to compute the posterior distribution.\n\\[\n\\begin{align*}\nBeta(\\alpha_{posterior}, \\beta_{posterior}) = Beta(\\alpha_{likelihood} + \\alpha_{prior}, \\beta_{likelihood} + \\beta_{prior}) \\\\\nBeta(\\alpha_{posterior}, \\beta_{posterior}) = Beta(2 + 1, 3 + 41) = Beta(3, 44) \\\\\nBeta(\\alpha_{likelihood} + \\beta_{likelihood}) = Beta(2, 3)\n\\end{align*}\n\\tag{14.3}\\]\nSummarized we got:\n\nPrior: Beta(1,41)\nLikelihood: Beta(2, 3)\nPosterior: Beta(2 + 1, 3 + 41) = Beta(3, 44)\n\nHover the cursor over Figure 14.4 to compare both plots!\n\n\n\nListing 14.4: Draw likelihood (no prior) and posterior (with prior)\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y1 = dbeta(x, 2, 3),\n               y2 = dbeta(x, 3, 44)) |&gt; \n    ggplot2::ggplot() +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y1, color = \"No prior\"),  linewidth = 1.0) +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y2, color = \"With prior\"),  linewidth = 1.0) +\n    ggplot2::theme_bw() +\n    ggplot2::theme(legend.position = \"top\") +\n    ggplot2::scale_color_manual(name = \"Distributions:\", \n             values = c(\"With prior\" = \"black\",\n                        \"No prior\" = \"red\")) +\n    ggplot2::guides(colour = ggplot2::guide_legend(reverse = TRUE)) +\n    ggplot2::labs(\n        title = \"Estimates of conversion rate with and without prior\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.11: Comparing our likelihood (no prior) to our posterior (with prior)\n\n\n\n\n\n\n\n\n14.6.5 Replicate Figure 14-5\n\nWe wait a few hours to gather more results and now find that out of 100 people who opened your email, 25 have clicked the link!\n\nI interpret these figures as the total of people, e.g, including the 5 people from the first count.\nThis time our new prior is the previous posterior and we are have to add the new prior to the new likelihood:\n\nNew prior is the previous posterior: Beta(3, 44)\nNew Likelihood: Beta(25, 75)\nNew Posterior: Beta(25 + 3, 75 + 44) = Beta(28, 119)\n\nHover the cursor over Figure 14.5 to compare both plots!\n\n\n\nListing 14.5: Update likelihood (no prior) and posterior (with prior)\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y1 = dbeta(x, 25, 75),\n               y2 = dbeta(x, 28, 119)) |&gt; \n    ggplot2::ggplot() +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y1, color = \"No prior\"),  linewidth = 1.0) +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y2, color = \"With prior\"),  linewidth = 1.0) +\n    ggplot2::theme_bw() +\n    ggplot2::theme(legend.position = \"top\") +\n    ggplot2::scale_color_manual(name = \"Distributions:\", \n             values = c(\"With prior\" = \"black\",\n                        \"No prior\" = \"red\")) +\n    ggplot2::guides(colour = ggplot2::guide_legend(reverse = TRUE)) +\n    ggplot2::labs(\n        title = \"Estimates of conversion rate with and without prior\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.12: Updating our beliefs with more data\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe red beta distribution without prior does not conform to Figure 14.5. The spike should be around 0.30 and should be just under density 8. But as far as I understand my calculation is correct. I would get a similar distribution with Beta around (25, 57), but I do not know how to get this result. My relation is \\(25 / 75 = 0.33\\) but should have a relation of about \\(25 / 57 = 0.44\\). I do not know how to produce this relation with an arguable calculation. Even a total of 105 people with a Beta(27, 78) would not change much (0.35)\n\n\n\n14.6.6 Replicate Figure 14-6\nIn the morning we find that 300 subscribers have opened their email, and 86 of those have clicked through.\nI will stick with my calculation procedure, even if I do not get exact the same result as in the book.\n\nNew prior is the previous posterior: Beta(28, 119)\nNew Likelihood: Beta(86, 214)\nNew Posterior: Beta(86 + 28, 214 + 119) = Beta(114, 333)\n\nHover the cursor over Figure 14.6 to compare both plots!\n\n\n\nListing 14.6: Draw beta distribution for our observations so far\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y1 = dbeta(x, 86, 214),\n               y2 = dbeta(x, 114, 333)) |&gt; \n    ggplot2::ggplot() +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y1, color = \"No prior\"),  linewidth = 1.0) +\n    ggplot2::geom_line(ggplot2::aes(x = x, y = y2, color = \"Width prior\"),  linewidth = 1.0) +\n    ggplot2::theme_bw() +\n    ggplot2::theme(legend.position = \"top\") +\n    ggplot2::scale_color_manual(name = \"Distributions:\", \n             values = c(\"Width prior\" = \"black\",\n                        \"No prior\" = \"red\")) +\n    ggplot2::guides(colour = ggplot2::guide_legend(reverse = TRUE)) +\n    ggplot2::labs(\n        title = \"Estimates of conversion rate with and without prior\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.13: The beta distribution for our observations so far\n\n\n\n\n\n\n\nThis time my graph looks pretty similar as Figure 14.6!\n\n14.6.7 Replicate Figure 14-7\nHover the cursor over Figure 14.7 to compare both plots!\n\n\n\nListing 14.7: Draw non-informative prior Beta(1,1)\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y = dbeta(x, 1, 1)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Non-inforamtive prior Beta(1, 1)\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.14: The noninformative prior Beta(1,1)\n\n\n\n\n\n\n\nDrawing a straight line is also done with dunif(x, min = 0, max = 1) (= the uniform distribution). As min = 0, max = 1are the default values you just can say dunif(x) as Figure 14.15 demonstrates:\n\n\n\nListing 14.8: Draw non-informative with the uniform distribution\n\ntibble::tibble(x = seq(0, 1, .0001),\n               y = dunif(x)) |&gt; \n    ggplot2::ggplot(ggplot2::aes(x = x, y = y)) +\n    ggplot2::geom_line() +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Non-inforamtive prior with dunif(x, min = 0, max = 1)\",\n        x = \"Conversion rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 14.15: The noninformative with the uniform distribution",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Parameter Estimation with Prior Probabilities</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html",
    "href": "15-bayesian-a-b-test.html",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "",
    "text": "15.1 Setting Up a Bayesian A/B Test",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html#setting-up-a-bayesian-ab-test",
    "href": "15-bayesian-a-b-test.html#setting-up-a-bayesian-ab-test",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "",
    "text": "For our test we’re going to send one variant with images like usual, and another without images. The test is called an A/B test because we are comparing variant A (with image) and variant B (without) to determine which one performs better.\n\n\nThe 300 people we’re going to test will be split up into two groups, A and B. Group A will receive the usual email with a big picture at the top, and group B will receive an email with no picture. The hope is that a simpler email will feel less “spammy” and encourage users to click through to the content.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html#finding-our-prior-probability",
    "href": "15-bayesian-a-b-test.html#finding-our-prior-probability",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "\n15.2 Finding Our Prior Probability",
    "text": "15.2 Finding Our Prior Probability\n\nWe’ve run an email campaign every week, so from that data we have a reasonable expectation that the probability of clicking the link to the blog on any given email should be around 30 percent. … We’ll settle on Beta(3,7) for our prior probability distribution. This distribution allows us to represent a beta distribution where 0.3 is the mean, but a wide range of possible alternative rates are considered.\n\n\n\nFigure 15.1: Visualizing our prior probability distribution\n\n\n\n\n\n\n15.2.1 Collecting Data\n\n\nTable 15.1: Email Click-through Rates\n\n\n\n\nClicked\nNot clicked\nObserved conversion rate\n\n\n\nVariant A\n36\n114\n0.24\n\n\nVariant B\n50\n100\n0.33\n\n\n\n\n\n\nWe are going to add beta and likelihood probabilities using Equation 14.1:\nPrior: Beta(3,7) Likelihood Variant A (with picture): Beta(3 + 36, 7 + 114) = Beta(39, 121) Likelihood Variant B:(without picture) Beta(3 + 50, 7 + 100) = Beta(53, 107)\n\n\nFigure 15.2: Beta distributions for our estimates for both variants of our email\n\n\n\n\n\nVariant B looks better, but there is an overlap.\n\nhow sure can we be that B is the better variant? This is where the Monte Carlo simulation comes in.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html#monte-carlo-simulations",
    "href": "15-bayesian-a-b-test.html#monte-carlo-simulations",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "\n15.3 Monte Carlo Simulations",
    "text": "15.3 Monte Carlo Simulations\n\nA MCMC,Monte Carlo simulation (GLOSSARY) is any technique that makes use of random sampling to solve a problem. In this case, we’re going to randomly sample from the two distributions, where each sample is chosen based on its probability in the distribution so that samples in a high-probability region will appear more frequently.\n\n\nWe can imagine that the posterior distribution represents all the worlds that could exist based on our current state of beliefs regarding each conversion rate.\n\n\n15.3.1 In How Many Worlds Is B the Better Variant?\n\n\n\nListing 15.1: Monte Carlo simulation from scratch\n\nn.trials = 1e5\nprior.alpha = 3\nprior.beta = 7\n\na.samples &lt;- rbeta(n.trials, 36 + prior.alpha, 114 + prior.beta)\nb.samples &lt;- rbeta(n.trials, 50 + prior.alpha, 100 + prior.beta)\n\np.b_superior &lt;- sum(b.samples &gt; a.samples)/n.trials\n\np.b_superior\n\n\n\n\n[1] 0.95985\n\n\n\nWhat we see here is that in 96 percent of the 100,000 trials, variant B was superior. We can imagine this as looking at 100,000 possible worlds.\n\n\n\n\n\n\n\nCaution\n\n\n\nWill Kurt remarks that this calculation was like a single t-test with a flat prior Beta(1,1) resulting in a p-value of 0.4, often considered “statistically significant”. But it seems that the Monte Carlo simulation has to advantages:\n\nWe built this test from scratch (as Will argued)\nWe do not only know how sure we can be that B is the better variant, but also exactly how much better the B variant is (as Will argued in the next section)\nThe MCMC simulation shows with the posterior distribution all possible worlds, instead of just retaining or rejecting a hypothesis (my additional argument).\n\nI want to look into the details and learn how to do this. There is a wonderful vignette Tidy t-Test with {infer} that I could read as a starter.\n\n\n\n15.3.2 How Much Better Is Each Variant B Than Each Variant A?\n\nNow we can say precisely how certain we are that B is the superior variant. … We can take the exact results from our last simulation and test how much better variant B is likely to be by looking at how many times greater the B samples are than the A samples.\n\n\\[\\frac{\\text{B Samples}}{\\text{A Samples}}\\]\n\nIn R, if we take the a.samples and b.samples from before, we can compute b.samples/a.samples. This will give us a distribution of the relative improvements from variant A to variant B. When we plot out this distribution as a histogram, as shown in Figure 15.3, we can see how much we expect variant B to improve our click-through rate.\n\n\n\nFigure 15.3: A histogram of possible improvements we might see\n\n\n\n\n\n\nFrom this histogram we can see that variant B will most likely be about a 40 percent improvement (ratio of 1.4) over A, although there is an entire range of possible values.\n\nAs we discussed in Chapter 13, the cumulative distribution function, (CDF) is much more useful than a histogram for reasoning about our results. Since we’re working with data rather than a mathematical function, we’ll compute the ECDF, empirical cumulative distribution function”) (GLOSSARY) with R’s ecdf() function. The eCDF is illustrated in Figure 15.4.\n\n\nFigure 15.4: A distribution of possible improvements we might see\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn my experiments I will use the ggplot2::stat_ecdf() function as demonstrated already in Listing 13.21.\n\n\n\nNow we can see our results more clearly. There is really just a small, small chance that A is better, and even if it is better, it’s not going to be by much. We can also see that there’s about a 25 percent chance that variant B is a 50 percent or more improvement over A, and even a reasonable chance it could be more than double the conversion rate! Now, in choosing B over A, we can actually reason about our risk by saying, “The chance that B is 20 percent worse is roughly the same that it’s 100 percent better.” Sounds like a good bet to me, and a much better statement of our knowledge than, “There is a statistically significant difference between B and A.”",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html#wrapping-up",
    "href": "15-bayesian-a-b-test.html#wrapping-up",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "\n15.4 Wrapping Up",
    "text": "15.4 Wrapping Up\nIn this chapter we saw how parameter estimation naturally extends to a form of hypothesis testing.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html#exercises",
    "href": "15-bayesian-a-b-test.html#exercises",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "\n15.5 Exercises",
    "text": "15.5 Exercises\nTry answering the following questions to see how well you understand running A/B tests. The solutions can be found at https://nostarch.com/learnbayes/.\n\n15.5.1 Exercise 15-1\nSuppose a director of marketing with many years of experience tells you he believes very strongly that the variant without images (B) won’t perform any differently than the original variant. How could you account for this in our model? Implement this change and see how your final conclusions change as well.\n\n15.5.2 Exercises 15-2\nThe lead designer sees your results and insists that there’s no way that variant B should perform better with no images. She feels that you should assume the conversion rate for variant B is closer to 20 percent than 30 percent. Implement a solution for this and again review the results of our analysis.\n\n15.5.3 Exercises 15-3\nAssume that being 95 percent certain means that you’re more or less “convinced” of a hypothesis. Also assume that there’s no longer any limit to the number of emails you can send in your test. If the true conversion for A is 0.25 and for B is 0.3, explore how many samples it would take to convince the director of marketing that B was in fact superior. Explore the same for the lead designer. You can generate samples of conversions with the following snippet of R:\n\ntrue.rate &lt;- 0.25\nnumber.of.samples &lt;- 100\nresults &lt;- runif(number.of.samples) &lt;= true.rate",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "15-bayesian-a-b-test.html#experiments",
    "href": "15-bayesian-a-b-test.html#experiments",
    "title": "15  From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test",
    "section": "\n15.6 Experiments",
    "text": "15.6 Experiments\n\n15.6.1 Replicate Figure 15-1\nHover the cursor over Figure 15.1 to compare both plots!\n\n\n\nListing 15.2: Draw Beta(3,7) for our prior probability distribution\n\nggplot2::ggplot() +\n    ggplot2::xlim(0, 1) +\n    ggplot2::geom_function(fun = dbeta, args = list(shape1 = 3, shape2 = 7)) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"Weak Prior Belief in Conversion Rate with Beta(3, 7)\",\n        x = \"Conversion Rate\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\nFigure 15.5: Visualizing our prior probability distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI learned here an essential simplification: Instead of providing a data frame with a grid approximation of many raster points — as I have done all the previous chapters — I just called the function with its parameters via ggplot2::geom_function(). But I have additonaly to add the range for the x-axis. See Draw a function as a continuous curve.\n\n\n\n15.6.2 Replicate Figure 15-2\nHover the cursor over Figure 15.2 to compare both plots!\n\n\n\nListing 15.3: Show the estimates for each parameter side by side.\n\nggplot2::ggplot() +\n    ggplot2::xlim(0, 0.5) +\n    ggplot2::geom_function(ggplot2::aes(color = \"Variant A: Beta(39, 121)\"),\n        fun = dbeta, args = list(shape1 = 39, shape2 = 121)) +\n        ggplot2::geom_function(ggplot2::aes(color = \"Variant B: Beta(53, 107)\"),\n        fun = dbeta, args = list(shape1 = 53, shape2 = 107)) +\n    ggplot2::theme_bw() +\n    ggplot2::scale_colour_manual(\"Distribution:\", values = c(\"red\", \"blue\")) + \n    ggplot2::theme(legend.position = c(.2,.85), legend.direction = \"vertical\") + \n    ggplot2::labs(\n        title = \"Weak Prior Belief in Conversion Rate with Beta(3, 7)\",\n        x = \"Conversion Rate\",\n        y = \"Density\"\n    )\n\n\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\nFigure 15.6: Beta distributions for our estimates for both variants of our email\n\n\n\n\n\n\n\n\n15.6.3 Replicate Figure 15-3\nHover the cursor over Figure 15.3 to compare both plots!\n\n\n\nListing 15.4: Distribution of the relative improvements from variant A to variant B\n\ntibble::tibble(x = seq(1, 1e5, 1),\n               y = b.samples / a.samples) |&gt; \n    ggplot2::ggplot(ggplot2::aes(y)) +\n    ggplot2::geom_histogram(bins = 12, color = \"black\", fill = \"grey\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        x = \"b.samples / a.samples\",\n        y = \"Frequeny\"\n    ) +\n    ggplot2::scale_x_continuous(breaks = scales::pretty_breaks(n = 10))\n\n\n\n\n\n\nFigure 15.7: A histogram of possible improvements we might see\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere I learned about the {scales} package (Main author is Hadley Wickham, the developer of {ggplot2})\n\nGraphical scales map data to aesthetics, and provide methods for automatically determining breaks and labels for axes and legends.\n\n{ggplot2} imports {scales} but not its functions. So you must always — not only in my case, where I did not use the library() directive — write scales::pretty_breaks().\n\n\n\n15.6.4 Replicate Figure 15-4\nHover the cursor over Figure 15.4 to compare both plots!\n\n\n\nListing 15.5: Compute the empirical cumulative distribution function\n\ntibble::tibble(x = seq(1, 1e5, 1),\n               y = b.samples / a.samples) |&gt;\n    ggplot2::ggplot(ggplot2::aes(y)) +\n    ggplot2::stat_ecdf(geom = \"step\") +\n    ggplot2::geom_hline(yintercept = 0.25, color = \"steelblue\",\n                    linetype = \"dashed\") +\n    ggplot2::geom_hline(yintercept = 0.50, color = \"orange\",\n        linetype = \"solid\") +\n    ggplot2::geom_hline(yintercept = 0.75, color = \"steelblue\",\n            linetype = \"dashed\") +\n    ggplot2::theme_bw() +\n    ggplot2::labs(\n        title = \"ggplot2::stat_ecdf(geom = 'step')\",\n        x = \"Improvement\",\n        y = \"Cumulative Probability\"\n    ) +\n    ggplot2::scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +\n    ggplot2::scale_y_continuous(breaks = scales::pretty_breaks(n = 5))\n\n\n\n\n\n\nFigure 15.8: A distribution of possible improvements we might see",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>From Parameter Estimation to Hypothesis Testing: Building a Bayesian A/B Test</span>"
    ]
  },
  {
    "objectID": "16-bayes-factor-posterior-odds.html",
    "href": "16-bayes-factor-posterior-odds.html",
    "title": "\n16  Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas\n",
    "section": "",
    "text": "16.1 Revisiting Bayes’ Theorem\n\\[\nP(H \\mid D) = \\frac{{P(H)} \\times  P(D \\mid H) }{P(D)}\n\\tag{16.1}\\]\n\\[P(H \\mid D) \\propto P(H) \\times P(D \\mid H) \\tag{16.2}\\]\n\\[\\frac{P(H_{1}) \\times P(D \\mid H_{1})}{P(H_{2}) \\times P(D \\mid H_{2})} \\tag{16.3}\\]",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas</span>"
    ]
  },
  {
    "objectID": "16-bayes-factor-posterior-odds.html#revisiting-bayes-theorem",
    "href": "16-bayes-factor-posterior-odds.html#revisiting-bayes-theorem",
    "title": "\n16  Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas\n",
    "section": "",
    "text": "\\(P(H \\mid D)\\): Posterior Probability (GLOSSARY), which tells us how strongly we should believe in our hypothesis, given our data.\n\n\\(P(H)\\): Prior Probability or Prior Belief (GLOSSARY), the probability of our hypothesis prior to looking at the data.\n\n\\(P(D \\mid H)\\): Likelihood (GLOSSARY) of getting the existing data if our hypothesis were true.\n\n\\(P(D)\\) is the probability of the data observed independent of the hypothesis. We need P(D) in order to make sure that our posterior probability is correctly placed somewhere between 0 and 1.\n\n\n\\(P(D)\\) is … totally unnecessary if all we care about is comparing the relative strength of two different hypotheses. … For these reasons, we often use the proportional form of Bayes’ theorem (GLOSSARY).\n\n\n\nthe posterior probability of our hypothesis is proportional to the prior multiplied by the likelihood. We can use this to compare two hypotheses by examining the ratio of the prior belief multiplied by the likelihood for each hypothesis using the ratio of posteriors formula:\n\n\n\nif the ratio is 2, then \\(H_{1}\\) explains the observed data twice as well as \\(H_{2}\\), and if the ratio is \\(\\frac{1}{2}\\), then \\(H_{2}\\) explains the data twice as well as \\(H_{1}\\).",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas</span>"
    ]
  },
  {
    "objectID": "16-bayes-factor-posterior-odds.html#building-a-hypothesis-test-using-the-ratio-of-posteriors",
    "href": "16-bayes-factor-posterior-odds.html#building-a-hypothesis-test-using-the-ratio-of-posteriors",
    "title": "\n16  Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas\n",
    "section": "\n16.2 Building a Hypothesis Test Using the Ratio of Posteriors",
    "text": "16.2 Building a Hypothesis Test Using the Ratio of Posteriors\n\nThe ratio of posteriors formula gives us the posterior odds, which allows us to test hypotheses or beliefs we have about data.\n\n\nTo better understand the posterior odds, we’ll break down the ratio of posteriors formula into two parts: the likelihood ratio, or the Bayes factor, and the ratio of prior probabilities.\n\n\n16.2.1 The Bayes Factor\n\\[\\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})} \\tag{16.4}\\]\n\nWhat this ratio tells us is the likelihood of what we’ve seen given what we believe to be true compared to what someone else believes to be true.\n\n\nThe key here is that in Bayesian reasoning, we don’t worry about supporting our beliefs—we are focused on how well our beliefs support the data we observe. In the end, data can either confirm our ideas or lead us to change our minds.\n\n\n16.2.2 Prior Odds\n\nSo far we have assumed that the prior probability of each hypothesis is the same. This is clearly not always the case: a hypothesis may explain the data well even if it is very unlikely.\n\n\\[\\frac{P(H_{1})}{P(H_{2})}\\]\n\nThis ratio compares the probability of two hypotheses before we look at the data. When used in relation to the Bayes factor, this ratio is called the prior odds in our \\(H_{1}\\) and written as \\(O(H_{1})\\). This representation is helpful because it lets us easily note how strongly (or weakly) we believe in the hypothesis we’re testing. When this number is greater than 1, it means the prior odds favor our hypothesis, and when it is a fraction less than 1, it means they’re against our hypothesis. For example, \\(O(H_{1}) = 100\\)$ means that, without any other information, we believe \\(H_{1}\\) is 100 times more likely than the alternative hypothesis.\n\n\n16.2.3 Posterior Odds\n\\[\\text{posterior odds} = O(H_{1})\\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})} \\tag{16.5}\\]\n\n\nTable 16.1: Guidelines for Evaluating Posterior Odds\n\n\n\nPosterior odds\nStrength of evidence\n\n\n\n1 to 3\nInteresting, but nothing conclusive\n\n\n3 to 20\nLooks like we’re on to something\n\n\n20 to 150\nStrong evidence in favor of \\(H_{1}\\)\n\n\n\n&gt; 150\nOverwhelming evidence\n\n\n\n\n\n\n\n16.2.4 Empty: Guidelines for Evaluating Posterior Odds\n\n16.2.5 Empty: Self-Diagnosing Rare Diseases Online",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas</span>"
    ]
  },
  {
    "objectID": "16-bayes-factor-posterior-odds.html#wrapping-up",
    "href": "16-bayes-factor-posterior-odds.html#wrapping-up",
    "title": "\n16  Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas\n",
    "section": "\n16.3 Wrapping Up",
    "text": "16.3 Wrapping Up\n\nIn this chapter, you learned how to use the Bayes factor and posterior odds to compare two hypotheses.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas</span>"
    ]
  },
  {
    "objectID": "16-bayes-factor-posterior-odds.html#exercises",
    "href": "16-bayes-factor-posterior-odds.html#exercises",
    "title": "\n16  Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas\n",
    "section": "\n16.4 Exercises",
    "text": "16.4 Exercises\n\nTry answering the following questions to see how well you understand the Bayes factor and posterior odds. The solutions can be found at https://nostarch.com/learnbayes/.\n\n\n16.4.1 Exercise 16-1\n\nReturning to the dice problem, assume that your friend made a mistake and suddenly realized that there were, in fact, two loaded dice and only one fair die. How does this change the prior, and therefore the posterior odds, for our problem? Are you more willing to believe that the die being rolled is the loaded die?\n\nLet’s recapitulate:\n\nSuppose your friend has a bag with three six-sided dice in it, and one die is weighted so that it lands on 6 half the time. The other two are traditional dice whose probability of rolling a 6 is ⅙. Your friend pulls out a die and rolls 10 times, with the following results: \\(6, 1, 3, 6, 4, 5, 6, 1, 2, 6\\)\n\n\nDefinition 16.1 (Bayes Factor) \\[\\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})}\\]\n\nIt turned out that \\(H_{1}\\) — the loaded dice — explain the data 3.77 times better than the fair dice with \\(H_{2}\\).\n\nHowever, this is true only if \\(H_{1}\\) and \\(H_{2}\\) are both just as likely to be true in the first place.\n\nBut we know now for this exercise that there are two loaded dice in the bag and only one fair die, which means that each hypothesis was not equally likely. Based on the distribution of the dice in the bag, we know that these are the prior probabilities for each hypothesis:\n\\[P(H_{1} = \\frac{2}{3}); P(H_{2} = \\frac{1}{3})\\] &gt; From these, we can calculate the prior odds for \\(H_{1}\\):\n\\[\\text{prior odds} = O(H_{1}) = \\frac{P(H_{1})}{P(H_{2})} = \\frac{\\frac{2}{3}}{\\frac{1}{3}} = \\frac{6}{3} = 2\\]\n\nWith our prior odds for H1, we can now compute our full posterior odds:\n\n\\[\\text{posterior odds} = O(H_{1}) = \\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})} = 2 \\times 3.77 = 7.54\\]\n\n\nSolution 16.1 Yes, I am now more willing to believe that the die being rolled is the loaded die!\n\n\n16.4.2 Exercise 16-2\n\nReturning to the rare diseases example, suppose you go to the doctor, and after having your ears cleaned you notice that your symptoms persist. Even worse, you have a new symptom: vertigo. The doctor proposes another possible explanation, labyrinthitis, which is a viral infection of the inner ear in which 98 percent of cases involve vertigo. However, hearing loss and tinnitus are less common in this disease; hearing loss occurs only 30 percent of the time, and tinnitus occurs only 28 percent of the time. Vertigo is also a possible symptom of vestibular schwannoma, but occurs in only 49 percent of cases. In the general population, 35 people per million contract labyrinthitis annually. What is the posterior odds when you compare the hypothesis that you have labyrinthitis against the hypothesis that you have vestibular schwannoma?\n\nLabyrinthitis:\n\\[P(D \\mid H_{1}) = 0.98 (\\text{vertigo}) \\times 0.30 (\\text{hearing loss}) \\times 0.28 (\\text{tinnitus}) = 0.082\\]\nVestibular schwannoma\n\\[P(D \\mid H_{2}) = 0.49 (\\text{vertigo}) \\times 0.94 (\\text{hearing loss}) \\times 0.89 (\\text{tinnitus}) = 0.41\\]\nBayes factor:\n\\[\\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})} = \\frac{0.08}{0.48} = 0.17\\]\nIncluding prior odds:\n\\[\\text{prior odds} = O(H_{1}) = \\frac{P(H_{1})}{P(H_{2})} = \\frac{\\frac{35}{1,000,000}}{\\frac{11}{1,000,000}} = \\frac{35}{11} = 3.18\\] Based on prior information alone, a given person is about only about 3 times more likely to have labyrinthitis than vestibular schwannoma. Now let’s compute the full posterior odds to see if the situation gets better:\n\\[\\text{prior odds} = O(H_{1}) = \\frac{P(H_{1})}{P(H_{2})} = \\frac{35}{11} \\times 6 = 19,09\\]\n\n\nSolution 16.2 The probability of having labyrinthitis is 19 times higher than vestibular schwannoma.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWill Kurt has another result because he is calculating the labyrinthitis against the earwax impaction!",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Introduction to the Bayes Factor and Posterior Odds: The Competition of Ideas</span>"
    ]
  },
  {
    "objectID": "18-data-convince.html",
    "href": "18-data-convince.html",
    "title": "\n18  When Data Doesn’t Convince\n",
    "section": "",
    "text": "18.1 A Psychic Friend Rolling Dice",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>When Data Doesn't Convince</span>"
    ]
  },
  {
    "objectID": "18-data-convince.html#a-psychic-friend-rolling-dice",
    "href": "18-data-convince.html#a-psychic-friend-rolling-dice",
    "title": "\n18  When Data Doesn’t Convince\n",
    "section": "",
    "text": "18.1.1 Comparing Likelihoods\n\nwe’ll start by looking at the Bayes factor** (GLOSSARY), assuming for now that the ´r glossary(“prior odds”)` for each hypothesis are equal.\n\n\n18.1.2 Incorporating Prior Odds\n\nIn most cases in this book where the likelihood alone gives us strange results, we can solve the problem by including our Prior probability, prior probabilities (GLOSSARY).\n\n\nIn most of our previous problems, we’ve corrected nonintuitive posterior results by adding a sane prior. We’ve added a pretty extreme prior against your friend being psychic, but our posterior odds are still strongly in favor of the hypothesis that they’re psychic.\n\n\n18.1.3 Considering Alternative Hypotheses\n\nThe issue here is that we don’t want to believe your friend is psychic. If you found yourself in this situation in real life, it’s likely you would quickly come to some alternative conclusion. You might come to believe that your friend is using a loaded die that rolls a certain value about 90 percent of the time, for example. This represents a third hypothesis.\n\n\nIt’s important to understand that a hypothesis test compares only two explanations for an event, but very often there are countless possible explanations. If the winning hypothesis doesn’t convince you, you could always consider a third one.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>When Data Doesn't Convince</span>"
    ]
  },
  {
    "objectID": "18-data-convince.html#arguing-with-relatives-and-conspiracy-theorists",
    "href": "18-data-convince.html#arguing-with-relatives-and-conspiracy-theorists",
    "title": "\n18  When Data Doesn’t Convince\n",
    "section": "\n18.2 Arguing with Relatives and Conspiracy Theorists",
    "text": "18.2 Arguing with Relatives and Conspiracy Theorists\n\nHow can we change someone else’s (or our own) beliefs even when more data doesn’t change anything?\n\n\nThe danger of nonfalsifiable beliefs in Bayesian reasoning isn’t just that they can’t be proved wrong—it’s that they are strengthened even by evidence that seems to contradict them. Rather than persisting in trying to convince you, your friend should have first asked, “What can I show you that would change your mind?” If your reply had been that nothing could change your mind, then your friend would be better off not presenting you with more evidence.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>When Data Doesn't Convince</span>"
    ]
  },
  {
    "objectID": "18-data-convince.html#wrapping-up",
    "href": "18-data-convince.html#wrapping-up",
    "title": "\n18  When Data Doesn’t Convince\n",
    "section": "\n18.3 Wrapping Up",
    "text": "18.3 Wrapping Up\n\nAlthough the Bayes factor is a competition between two ideas, it’s quite possible that there are other, equally valid, hypotheses worth testing out.\n\n\nOther times, we find that two hypotheses explain the data equally well; … When this is the case, only the prior odds ratio for each hypothesis matters. This also means that acquiring more data in those situations will never change our beliefs, because it will never give either hypothesis an edge over the other. In these cases, it’s best to consider how you can alter the prior beliefs that are affecting the results.\n\n\nIn more extreme cases, we might have a hypothesis that simply refuses to be changed. This is like having a conspiracy theory about the data. When this is the case, not only will more data never convince us to change our beliefs, but it will actually have the opposite effect. If a hypothesis is not falsifiable, more data will only serve to make us more certain of the conspiracy.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>When Data Doesn't Convince</span>"
    ]
  },
  {
    "objectID": "18-data-convince.html#exercises",
    "href": "18-data-convince.html#exercises",
    "title": "\n18  When Data Doesn’t Convince\n",
    "section": "\n18.4 Exercises",
    "text": "18.4 Exercises\n\nTry answering the following questions to see how well you understand how to deal with extreme cases in Bayesian reasoning. The solutions can be found at https://nostarch.com/learnbayes/.\n\n\n18.4.1 Exercise 18-1\n\nWhen two hypotheses explain the data equally well, one way to change our minds is to see if we can attack the prior probability. What are some factors that might increase your prior belief in your friend’s psychic powers?\n\n\n\nSolution 18.1 I would change the rules for my friend to demonstrate his/her psychic power to me. For instance: - Instead of tossing his coin I want it to do with a coin of my own. - Instead of tossing the coin on a table I will catch the coin in the air. (I read that then it is much more difficult to control the coin.) - Or I will ask him other things like what figure I am thinking about, etc.\n\n\n18.4.2 Exercise 18-2\n\nAn experiment claims that when people hear the word Florida, they think of the elderly and this has an impact on their walking speed. To test this, we have two groups of 15 students walk across a room; one group hears the word Florida and one does not. Assume \\(H_{1}\\) = the groups don’t move at different speeds, and \\(H_{2}\\) = the Florida group is slower because of hearing the word Florida. Also assume the Bayes factor from Equation 16.4:\n\n\\[BF = \\frac{P(D \\mid H_{1})}{P(D \\mid H_{2})}\\]\n\nThe experiment shows that \\(H_{2}\\) has a Bayes factor of 19. Suppose someone is unconvinced by this experiment because \\(H_{2}\\) had a lower prior odds. What prior odds would explain someone being unconvinced and what would the BF need to be to bring the posterior odds to 50 for this unconvinced person?\n\n\n\n\n\n\n\nWarning\n\n\n\nThis time my answer of 25 to 50 was completely wrong. I calculated wrongly the unconvincing prior odds between 1 to 3 taking erroneously values of Table 16.1 and did not take into account to equalize the fraction \\(\\frac{1}{19}\\)\n\n\nSolution 18.2 \\[50 = \\frac{1}{19} \\times x = 50 \\times 19 = 950\\]\n\n\n\n\n\nNow suppose the prior odds do not change the skeptic’s mind. Think of an alternate \\(H_{3}\\) that explains the observation that the Florida group is slower. Remember if \\(H_{2}\\) and \\(H_{3}\\) both explain the data equally well, only prior odds in favor of \\(H_{3}\\) would lead someone to claim \\(H_{3}\\) is true over \\(H_{2}\\), so we need to rethink the experiment so that these odds are decreased. Come up with an experiment that could change the prior odds in \\(H_{3}\\) over \\(H_{2}\\)\n\n\n\nSolution 18.3 The majority of the Florida group members might be older (adult students) and therefore walking slower. Or they have some handicapped people in it, so that the average of the walking speed of the whole group is reduced.\nThe books solution was shorter people walking more slowly.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>When Data Doesn't Convince</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html",
    "href": "19-hypothesis-testing-parameter-estimation.html",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "",
    "text": "19.1 Is the Carnival Game Really Fair?\nN: 100, Success: 24 H1: p = 0.5 H2: p = 0.05\n\\[\n\\frac{P(D \\mid H_{2}) = (0.05)^{24} \\times (1 - 0.05)^{76}}{P(D \\mid H_{1}) = (0.5)^{24} \\times (1 - 0.5)^{76}}\n\\tag{19.1}\\]\nListing 19.1: Compute Bayes Factor for Duck Game\n\n(0.5^24 * 0.5^76) / (0.05^24 * 0.95^76)\n\n\n\n\n[1] 652.7191\nThis seems strange, because we got only 24 prices in 100 draws, which definitely is not near to 0.5.\nLets check with the pbinom() function (introduced in Chapter 13) to calculate the binomial distribution:\nListing 19.2: Compute probability of seeing 24 or fewer prizes, assuming that the probability of getting a prize is really 0.5\n\npbinom(24, 100, 0.5)\n\n\n\n\n[1] 9.050013e-08\nThis is an extremely low value!",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html#is-the-carnival-game-really-fair",
    "href": "19-hypothesis-testing-parameter-estimation.html#is-the-carnival-game-really-fair",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "",
    "text": "To get our Bayes factor, we need to compute P(D | H) for each hypothesis:\n\n\n\n\nOur Bayes factor tells us that \\(H_{1}\\), the attendant’s hypothesis, explains the data 653 times as well as \\(H_{2}\\).\n\n\n\n\n\n\nIn the past, we’ve often found that the prior probability usually matters a lot when the Bayes factor alone doesn’t give us an answer that makes sense. … [But] there must be some problem here other than the prior.\n\n\n19.1.1 Considering Multiple Hypotheses\n\nOne obvious problem is that, while it seems intuitively clear that the attendant is wrong in his hypothesis, the customer’s alternative hypothesis is just too extreme to be right, either, so we have two wrong hypotheses. What if the customer thought the probability of winning was 0.2, rather than 0.05? We’ll call this hypothesis \\(H_{3}\\). Testing \\(H_{3}\\) against the attendant’s hypothesis radically changes the results of our likelihood ratio:\n\n\\[\n\\frac{P(D \\mid H_{3}) = (0.2)^{24} \\times (1 - 0.2)^{76}}{P(D \\mid H_{1}) = (0.5)^{24} \\times (1 - 0.5)^{76}}\n\\tag{19.2}\\]\n\n\n\nListing 19.3: Compute Bayes Factor for Duck Game\n\n(0.2^24 * 0.8^76) / (0.5^24 * 0.5^76)\n\n\n\n\n[1] 917399.4\n\n\n\nThe trouble we had in our first hypothesis test was that the customer’s belief was a far worse description of the event than the attendant’s belief.\n\n\nOf course, we haven’t really solved our problem. What if there’s an even better hypothesis out there?\n\n\n19.1.2 Searching for More Hypotheses with R\n\nWe’ll consider every increment of 0.01 between 0 and 1 as a possible hypothesis.\n\n\n\n\nListing 19.4: Search with increment of 0.01 for als hypothesises between 0 and 1\n\nbayes.factor &lt;- function(h_top, h_bottom) {\n    ((h_top) ^ 24 * (1 - h_top) ^ 76) / \n        ((h_bottom) ^ 24 * (1 - h_bottom) ^ 76)\n}\n\ndx &lt;- 0.01\nhypotheses &lt;- seq(0, 1, by = dx)\nbfs &lt;- bayes.factor(hypotheses, 0.5)\nplot(hypotheses, bfs, type = 'l')\n\n\n\n\n\n\nFigure 19.1: Plotting the Bayes factor for each of our hypotheses\n\n\n\n\n\n\n\n1.478776^{6} is the largest Bayes factor in our vector bfs. 0.24 is the highest likelihood ratio, telling us which hypothesis we should believe in the most.\n\n\n\n\n\n\nCaution\n\n\n\nI want to try this calculation with appropriate R packages. Maybe {BayesFactor} could be helpful?\n\n\n\n19.1.3 Adding Priors to Our Likelihood Ratios\n\n“I used to make games like these, and I can tell you that for some strange industry reason, the people who design these duck games never put the prize rate between 0.2 and 0.3. I’d bet you the odds are 1,000 to 1 that the real prize rate is not in this range. Other than that, I have no clue.”\n\n\n\n\nListing 19.5: Visualize the prior that the duck games never put a prize rate between 0.2 and 0.3\n\npriors &lt;- ifelse(hypotheses &gt;= 0.2 & hypotheses &lt;= 0.3, 1/1000,1)\nplot(hypotheses, priors, type = 'l')\n\n\n\n\n\n\nFigure 19.2: Visualizing our prior odds ratios\n\n\n\n\n\n\n\n\n\n\nListing 19.6: Plot new posterior distribution inlcuding the prior\n\nposteriors &lt;- priors * bfs\nplot(hypotheses, posteriors, type = 'l')\n\n\n\n\n\n\nFigure 19.3: Plotting our distribution of Bayes factors",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html#building-a-probability-distribution",
    "href": "19-hypothesis-testing-parameter-estimation.html#building-a-probability-distribution",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "\n19.2 Building a Probability Distribution",
    "text": "19.2 Building a Probability Distribution\nThe posterior odds for our hypotheses is sum(posteriors) = 3.1406875^{6}, e.g. it does not sum to 1. So we need to normalize it by dividing each value in our posteriors vector by the sum of all the values: p.posteriors &lt;- posteriors/sum(posteriors) = . Now sum(p.posteriors) adds to 1.\n\n\n\nListing 19.7: Plot the normalized posterior odds\n\nplot(hypotheses, p.posteriors, type = 'l')\n\n\n\n\n\n\nFigure 19.4: Our normalized posterior odds (note the scale on the y-axis)\n\n\n\n\n\n\n\n\nWe can also use our p.posteriors to answer some common questions we might have about our data. For example, we can now calculate the probability that the true rate of getting a prize is less than what the attendant claims. We just add up all the probabilities for values less than 0.5:\n\nsum(p.posteriors[which(hypotheses &lt; 0.5)]) = 0.9999995\n\nwe can be almost certain that the attendant is overstating the true prize rate.\n\n\nWe can also calculate the expectation of our distribution and use this result as our estimate for the true probability. Recall that the expectation is just the sum of the estimates weighted by their value:\n\nsum(p.posteriors * hypotheses) = 0.2402704\n\nOf course, we can see our distribution is a bit atypical, with a big gap in the middle, so we might want to simply choose the most likely estimate, as follows:\n\nhypotheses[which.max(p.posteriors)] = 0.19\n\nNow we’ve used the Bayes factor to come up with a range of probabilistic estimates for the true possible rate of winning a prize in the duck game. This means that we’ve used the Bayes factor as a form of parameter estimation!",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html#from-the-bayes-factor-to-parameter-estimation",
    "href": "19-hypothesis-testing-parameter-estimation.html#from-the-bayes-factor-to-parameter-estimation",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "\n19.3 From the Bayes Factor to Parameter Estimation",
    "text": "19.3 From the Bayes Factor to Parameter Estimation\n\nAs we’ve discussed many times since Chapter 5, if we want to estimate the rate of some event, we can always use the beta distribution.\n\n\n\nFigure 19.5: The beta distribution with an alpha of 24 and a beta of 76\n\n\n\n\n\n\nExcept for the scale of the y-axis, the plot looks nearly identical to the original plot of our likelihood ratios! In fact, if we do a few simple tricks, we can get these two plots to line up perfectly. If we scale our beta distribution by the size of our dx and normalize our bfs, we can see that these two distributions get quite close:\n\n\n\nFigure 19.6: Our initial distribution of likelihood ratios maps pretty closely to Beta(24,76)\n\n\n\n\n\n\nThere seems to be only a slight difference now. We can fix it by using the weakest prior that indicates that getting a prize and not getting a prize are equally likely—that is, by adding 1 to both the alpha and beta parameters\n\n\n\nFigure 19.7: Our likelihood ratios map perfectly to a Beta(24+1,76+1) distribution\n\n\n\n\n\n\nby using the Bayes factor, we’ve been able to empirically re-create a modified version of it that assumes a prior of Beta(1,1). And we did it without any fancy mathematics! All we had to do was:\n\nDefine the probability of the evidence given a hypothesis.\nConsider all possible hypotheses.\nNormalize these values to create a probability distribution.\n\n\n\nNot only is the Bayes factor a great tool for setting up hypothesis tests, but, as it turns out, it’s also all we need to create any probability distribution we might want to use to solve our problem, whether that’s hypothesis testing or parameter estimation. We just need to be able to define the basic comparison between two hypotheses, and we’re on our way.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html#wrapping-up",
    "href": "19-hypothesis-testing-parameter-estimation.html#wrapping-up",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "\n19.4 Wrapping Up",
    "text": "19.4 Wrapping Up\n\nFrom the basic rules of probability, we can derive Bayes’ theorem, which lets us convert evidence into a statement expressing the strength of our beliefs. From Bayes’ theorem, we can derive the Bayes factor, a tool for comparing how well two hypotheses explain the data we’ve observed. By iterating through possible hypotheses and normalizing the results, we can use the Bayes factor to create a parameter estimate for an unknown value. This, in turn, allows us to perform countless other hypothesis tests by comparing our estimates. And all we need to do to unlock all this power is use the basic rules of probability to define our likelihood, \\(P(D \\mid H)\\)!",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html#exercises",
    "href": "19-hypothesis-testing-parameter-estimation.html#exercises",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "\n19.5 Exercises",
    "text": "19.5 Exercises\nTry answering the following questions to see how well you understand using the Bayes factor and posterior odds to do parameter estimation. The solutions can be found at https://nostarch.com/learnbayes/.\n\n19.5.1 Exercise 19-1\nOur Bayes factor assumed that we were looking at \\(H_{1}: P(prize) = 0.5\\). This allowed us to derive a version of the beta distribution with an alpha of 1 and a beta of 1. Would it matter if we chose a different probability for H1? Assume \\(H_{1}: P(prize) = 0.24\\), then see if the resulting distribution, once normalized to sum to 1, is any different than the original hypothesis.\n\n19.5.2 Exercise 19-2\nWrite a prior for the distribution in which each hypothesis is 1.05 times more likely than the previous hypothesis (assume our dx remains the same).\n\n19.5.3 Exercise 19-3\nSuppose you observed another duck game that included 34 ducks with prizes and 66 ducks without prizes. How would you set up a test to answer “What is the probability that you have a better chance of winning a prize in this game than in the game we used in our example?” Implementing this requires a bit more sophistication than the R used in this book, but see if you can learn this on your own to kick off your adventures in more advanced Bayesian statistics!",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  },
  {
    "objectID": "19-hypothesis-testing-parameter-estimation.html#experiments",
    "href": "19-hypothesis-testing-parameter-estimation.html#experiments",
    "title": "19  From Hypothesis Testing to Parameter Estimation",
    "section": "\n19.6 Experiments",
    "text": "19.6 Experiments",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>From Hypothesis Testing to Parameter Estimation</span>"
    ]
  }
]